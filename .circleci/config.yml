# Copyright 2023 Ant Group Co., Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
parameters:
  GHA_Actor:
    type: string
    default: ""
  GHA_Action:
    type: string
    default: ""
  GHA_Event:
    type: string
    default: ""
  GHA_Meta:
    type: string
    default: ""
  run-schedule:
    type: boolean
    default: false

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:
  nn_benchmark:
    # Use machine executor for convenient data sharing between the host and docker-compose cluster
    machine:
      image: ubuntu-2004:2022.07.1
    resource_class: 2xlarge
    steps:
      - checkout
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-linuxVM-
      - run:
          name: Build SPU
          command: |
            set +e 
            declare -i build_status
            sed -i "s/tensorflow /tensorflow-cpu /g" ./requirements-dev.txt
            docker run --name spu-build --mount type=bind,source="$(pwd)",target=/home/admin/dev/ secretflow/spu-ci:0.4 \
                sh -c "cd /home/admin/dev && \
                        python3 -m pip install -U pip && \
                        python3 -m pip install -r requirements.txt && \
                        python3 -m pip install -r requirements-dev.txt && \
                        bazel build //examples/python/... -c opt --ui_event_filters=-info,-debug,-warning --jobs=16 --disk_cache=/home/admin/dev/.cache/spu_build_cache" | tee build_results.log; build_status=${PIPESTATUS[0]}
            exit ${build_status}
      - run:
          name: Save image
          command: docker commit spu-build spu-build:v1
      - run:
          name: Launch docker-compose cluster
          command: docker-compose -f .circleci/benchmark.yml up -d
      - run:
          name: Launch benchmark task
          no_output_timeout: 30m
          command: |
            set +e
            declare -i benchmark_status
            sleep 60
            # TODO: run all stax_nn models with different optimizers
            docker run --rm --mount type=bind,source="$(pwd)",target=/home/admin/dev/ --network nn-benchmark spu-build:v1 \
                sh -c "cd /home/admin/dev && bash .circleci/run-nn.sh" | tee benchmark_results.log; benchmark_status=${PIPESTATUS[0]}
            exit ${benchmark_status}
      - run:
          name: Shutdown docker-compose cluster
          command: docker-compose -f .circleci/benchmark.yml down
      - save_cache:
          key: spu-build-linuxVM-{{ .Environment.CIRCLE_BUILD_NUM }}
          paths:
            - .cache/spu_build_cache
      - store_artifacts:
          path: build_results.log
      - store_artifacts:
          path: benchmark_results.log
  linux_ut:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    docker:
      - image: registry.hub.docker.com/secretflow/spu-ci:0.4
    resource_class: 2xlarge
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      # Kill the whole ci after 1hr
      - run:
          name: Cancel build after set time
          background: true
          command: |
            sleep 3600
            echo "Canceling workflow as too much time has elapsed"
            curl -X POST --header "Content-Type: application/json" "https://circleci.com/api/v2/workflow/${CIRCLE_WORKFLOW_ID}/cancel?circle-token=${BUILD_TIMER_TOKEN}"
      - checkout
      - restore_cache:
          name: "Restore pip cache"
          key: &pip-cache pip-{{ checksum "requirements.txt" }}-{{ checksum "requirements-dev.txt" }}
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-comp-{{ arch }}-
      - run:
          name: Decompress cache
          command: sh .ci/decompress-build-cache.sh
      - run:
          name: "Install dependencies"
          command: |
            python3 -m pip install -U pip
            python3 -m pip install -r requirements.txt
            sed -i "s/tensorflow /tensorflow-cpu /g" ./requirements-dev.txt
            python3 -m pip install -r requirements-dev.txt
      - run:
          name: "build"
          command: bazel build //spu/... -c opt --ui_event_filters=-info,-debug,-warning --jobs=16 --disk_cache=~/.cache/spu_build_cache
      - run:
          name: "test"
          command: |
            set +e
            declare -i test_status
            bazel test //spu/... -c opt --ui_event_filters=-info,-debug,-warning --jobs=16 --test_output=errors --disk_cache=~/.cache/spu_build_cache | tee test_result.log; test_status=${PIPESTATUS[0]}
            sh .ci/rename-junit-xml.sh
            find bazel-bin/ -executable -type f -name "*_test"  -print0 | xargs -0 tar -cvzf test_binary.tar.gz
            find bazel-testlogs/ -type f -name "test.log"  -print0 | xargs -0 tar -cvzf test_logs.tar.gz
            exit ${test_status}
      - save_cache:
          key: *pip-cache
          paths:
            - /usr/local/lib64/python3.8/site-packages
      - run:
          name: Cleanup and compress cache
          command: |
            sh .ci/clean_disk_cache.sh
            sh .ci/compress-build-cache.sh
      - save_cache:
          key: spu-build-comp-{{ arch }}-{{ .Environment.CIRCLE_BUILD_NUM }}
          paths:
            - /root/.cache/spu_build_cache.tar.gz
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test_binary.tar.gz
      - store_artifacts:
          path: test_logs.tar.gz
  macOS_ut:
    macos:
      xcode: 14.2
    environment:
      HOMEBREW_NO_AUTO_UPDATE: 1
    resource_class: macos.m1.large.gen1
    steps:
      - checkout
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-comp-{{ arch }}-
      - run:
          name: Decompress cache
          command: sh .ci/decompress-build-cache.sh
      - run:
          name: "Install homebrew dependencies"
          command: |
            brew install bazel cmake ninja libomp wget go md5sha1sum
            (cd /opt/homebrew/Cellar/bazel/*.*.*/libexec/bin && curl -fLO https://github.com/bazelbuild/bazel/releases/download/5.4.0/bazel-5.4.0-darwin-arm64 && chmod +x bazel-5.4.0-darwin-arm64)
      - run:
          name: "Install Miniconda"
          command: |
            wget https://repo.anaconda.com/miniconda/Miniconda3-py38_23.1.0-1-MacOSX-arm64.sh -O ~/miniconda.sh
            bash ~/miniconda.sh -b -p $HOME/miniconda
            source $HOME/miniconda/bin/activate
            conda init bash zsh
            pip install -r requirements.txt
            pip install -r requirements-dev.txt
      - run:
          name: "build"
          command: bazel build //spu/... -c opt --ui_event_filters=-info,-debug,-warning --disk_cache=~/.cache/spu_build_cache
      - run:
          name: "test"
          command: |
            set +e
            declare -i test_status
            bazel test //spu/... -c opt --ui_event_filters=-info,-debug,-warning --test_output=errors --disk_cache=~/.cache/spu_build_cache --jobs=4 | tee test_result.log; test_status=${PIPESTATUS[0]}
            sh .ci/rename-junit-xml.sh
            find bazel-bin/ -perm +111 -type f -name "*_test"  -print0 | xargs -0 tar -cvzf test_binary.tar.gz
            find bazel-testlogs/ -type f -name "test.log"  -print0 | xargs -0 tar -cvzf test_logs.tar.gz
            exit ${test_status}
      - run:
          name: Cleanup and compress cache
          command: |
            sh .ci/clean_disk_cache.sh
            sh .ci/compress-build-cache.sh
      - save_cache:
          key: spu-build-comp-{{ arch }}-{{ .Environment.CIRCLE_BUILD_NUM }}
          paths:
            - ~/.cache/spu_build_cache.tar.gz
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test_binary.tar.gz
      - store_artifacts:
          path: test_logs.tar.gz
  macOS_x64_publish:
    macos:
      xcode: 13.4.1
    environment:
      HOMEBREW_NO_AUTO_UPDATE: 1
    resource_class: large
    steps:
      - checkout
      - run:
          name: "Install homebrew dependencies"
          command: |
            brew install bazel cmake ninja nasm libomp wget go
            (cd "/usr/local/Cellar/bazel/5.1.1/libexec/bin" && curl -fLO https://releases.bazel.build/5.4.0/release/bazel-5.4.0-darwin-x86_64 && chmod +x bazel-5.4.0-darwin-x86_64)
      - run:
          name: "Install Miniconda"
          command: |
            wget https://repo.anaconda.com/miniconda/Miniconda3-py38_22.11.1-1-MacOSX-x86_64.sh -O ~/miniconda.sh
            bash ~/miniconda.sh -b -p $HOME/miniconda
            source $HOME/miniconda/bin/activate
            conda init zsh bash
            conda install -y grpcio
            pip install -r requirements.txt
      - run:
          name: "build package and publish"
          command: |
            set +e
            sh ./build_wheel_entrypoint.sh
            spu_wheel_name=$(<./spu_wheel.name)
            spu_wheel_path="./${spu_wheel_name//sf-spu/sf_spu}"
            python3 -m pip install twine
            python3 -m twine upload -r pypi -u __token__ -p ${PYPI_TWINE_TOKEN} $spu_wheel_path
  macOS_arm64_publish:
    macos:
      xcode: 14.2
    environment:
      HOMEBREW_NO_AUTO_UPDATE: 1
    resource_class: macos.m1.large.gen1
    steps:
      - checkout
      - run:
          name: "Install homebrew dependencies"
          command: |
            brew install bazel cmake ninja libomp wget go
            (cd /opt/homebrew/Cellar/bazel/*.*.*/libexec/bin && curl -fLO https://github.com/bazelbuild/bazel/releases/download/5.4.0/bazel-5.4.0-darwin-arm64 && chmod +x bazel-5.4.0-darwin-arm64)
      - run:
          name: "Install Miniconda"
          command: |
            wget https://repo.anaconda.com/miniconda/Miniconda3-py38_23.1.0-1-MacOSX-arm64.sh -O ~/miniconda.sh
            source $HOME/miniconda/bin/activate
            conda init zsh bash
            pip install -r requirements.txt
      - run:
          name: "build package and publish"
          command: |
            set +e
            sh ./build_wheel_entrypoint.sh
            spu_wheel_name=$(<./spu_wheel.name)
            spu_wheel_path="./${spu_wheel_name//sf-spu/sf_spu}"
            python3 -m pip install twine
            python3 -m twine upload -r pypi -u __token__ -p ${PYPI_TWINE_TOKEN} $spu_wheel_path
  linux_publish:
    docker:
      - image: registry.hub.docker.com/secretflow/release-ci:0.2
    resource_class: xlarge
    steps:
      - checkout
      - run:
          name: "build package and publish"
          command: |
            set +e
            pip install numpy
            env BAZEL_MAX_JOBS=16 sh ./build_wheel_entrypoint.sh
            spu_wheel_name=$(<./spu_wheel.name)
            spu_wheel_path="./${spu_wheel_name//sf-spu/sf_spu}"
            python3 -m pip install twine
            python3 -m twine upload -r pypi -u __token__ -p ${PYPI_TWINE_TOKEN} $spu_wheel_path

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  benchmark:
    when: << pipeline.parameters.run-schedule >>
    jobs:
      - nn_benchmark
  ut:
    when:
      not: << pipeline.parameters.run-schedule >>
    jobs:
      - linux_ut
      - macOS_ut
  publish:
    when: << pipeline.parameters.GHA_Action >>
    jobs:
      - linux_publish
      - macOS_x64_publish
      - macOS_arm64_publish
