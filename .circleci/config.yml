# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
parameters:
  GHA_Actor:
    type: string
    default: ""
  GHA_Action:
    type: string
    default: ""
  GHA_Event:
    type: string
    default: ""
  GHA_Meta:
    type: string
    default: ""
  run-schedule:
    type: boolean
    default: false

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:
  nn_benchmark:
    # Use machine executor for convenient data sharing between the host and docker-compose cluster
    machine:
      image: ubuntu-2004:2022.07.1
    resource_class: 2xlarge
    steps:
    - checkout
    - restore_cache:
        name: "Restore build cache"
        key: spu-build-linuxVM-
    - run:
        name: Build SPU
        command: |
          set +e 
          declare -i build_status
          sed -i "s/tensorflow /tensorflow-cpu /g" ./requirements-dev.txt
          docker run --name spu-build --mount type=bind,source="$(pwd)",target=/home/admin/dev/ secretflow/spu-ci:0.2 \
              sh -c "cd /home/admin/dev && \
                      python3 -m pip install -U pip && \
                      python3 -m pip install -r requirements.txt && \
                      python3 -m pip install -r requirements-dev.txt && \
                      bazel build //examples/python/... -c opt --ui_event_filters=-info,-debug,-warning --jobs=16 --disk_cache=/home/admin/dev/.cache/spu_build_cache" | tee build_results.log; build_status=${PIPESTATUS[0]}
          exit ${build_status} 
    - run:
        name: Save image
        command: docker commit spu-build spu-build:v1 
    - run:
        name: Launch docker-compose cluster
        command: |
          cp .circleci/benchmark.json examples/python/conf/3pc.json
          docker-compose -f .circleci/benchmark.yml up -d
    - run:
        name: Launch benchmark task
        command: |
          set +e
          declare -i benchmark_status
          sleep 60
          # TODO: run all stax_nn models with different optimizers
          docker run --rm --mount type=bind,source="$(pwd)",target=/home/admin/dev/ --network nn-benchmark spu-build:v1 \
              sh -c "cd /home/admin/dev && \
                      bazel run -c opt //examples/python/ml/stax_nn" | tee benchmark_results.log; benchmark_status=${PIPESTATUS[0]}
          exit ${benchmark_status}
    - run:
        name: Shutdown docker-compose cluster
        command: docker-compose -f .circleci/benchmark.yml down
    - save_cache:
        key: spu-build-linuxVM-{{ .Environment.CIRCLE_BUILD_NUM }}
        paths:
          - .cache/spu_build_cache
    - store_artifacts:
        path: build_results.log
    - store_artifacts:
        path: benchmark_results.log
  linux_ut:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    docker:
      - image: registry.hub.docker.com/secretflow/spu-ci:0.2
    resource_class: 2xlarge
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      # Kill the whole ci after 1hr
      - run:
          name: Cancel build after set time
          background: true
          command: |
            sleep 3600
            echo "Canceling workflow as too much time has elapsed"
            curl -X POST --header "Content-Type: application/json" "https://circleci.com/api/v2/workflow/${CIRCLE_WORKFLOW_ID}/cancel?circle-token=${BUILD_TIMER_TOKEN}"
      - checkout
      - restore_cache:
          name: "Restore pip cache"
          key: &pip-cache pip-{{ checksum "requirements.txt" }}-{{ checksum "requirements-dev.txt" }}
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-{{ arch }}-
      - run:
          name: "Install dependencies"
          command: |
            python3 -m pip install -U pip
            python3 -m pip install -r requirements.txt
            sed -i "s/tensorflow /tensorflow-cpu /g" ./requirements-dev.txt
            python3 -m pip install -r requirements-dev.txt
      - run:
          name: "build"
          command: bazel build //spu/... -c opt --ui_event_filters=-info,-debug,-warning --jobs=16 --disk_cache=~/.cache/spu_build_cache
      - run:
          name: "test"
          command: |
            set +e
            declare -i test_status
            bazel test //spu/... -c opt --ui_event_filters=-info,-debug,-warning --jobs=16 --test_output=errors --disk_cache=~/.cache/spu_build_cache | tee test_result.log; test_status=${PIPESTATUS[0]}
            sh .ci/rename-junit-xml.sh
            find bazel-bin/ -executable -type f -name "*_test"  -print0 | xargs -0 tar -cvzf test_binary.tar.gz
            find bazel-testlogs/ -type f -name "test.log"  -print0 | xargs -0 tar -cvzf test_logs.tar.gz
            exit ${test_status}
      - save_cache:
          key: *pip-cache
          paths:
            - /usr/local/lib64/python3.8/site-packages
      - save_cache:
          key: spu-build-{{ arch }}-{{ .Environment.CIRCLE_BUILD_NUM }}
          paths:
            - /root/.cache/spu_build_cache
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test_binary.tar.gz
      - store_artifacts:
          path: test_logs.tar.gz
  macOS_ut:
    macos:
      xcode: 13.4.1
    environment:
      HOMEBREW_NO_AUTO_UPDATE: 1
    resource_class: large
    steps:
      - checkout
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-{{ arch }}-
      - run:
          name: "Install homebrew dependencies"
          command: |
            brew install bazel cmake ninja nasm libomp wget go md5sha1sum
            (cd "/usr/local/Cellar/bazel/5.1.1/libexec/bin" && curl -fLO https://releases.bazel.build/5.4.0/release/bazel-5.4.0-darwin-x86_64 && chmod +x bazel-5.4.0-darwin-x86_64)
      - run:
          name: "Install Miniconda"
          command: |
            wget https://repo.anaconda.com/miniconda/Miniconda3-py38_22.11.1-1-MacOSX-x86_64.sh -O ~/miniconda.sh
            bash ~/miniconda.sh -b -p $HOME/miniconda
            source $HOME/miniconda/bin/activate
            conda init bash zsh
            conda install -y grpcio
            pip install -r requirements.txt
      - run:
          name: "build"
          command: bazel build //spu/... -c opt --ui_event_filters=-info,-debug,-warning --disk_cache=~/.cache/spu_build_cache
      - run:
          name: "test"
          command: |
            set +e
            brew install coreutils
            declare -i test_status
            bazel test //spu/... -c opt --ui_event_filters=-info,-debug,-warning --test_output=errors --disk_cache=~/.cache/spu_build_cache --jobs=4 | tee test_result.log; test_status=${PIPESTATUS[0]}
            sh .ci/rename-junit-xml.sh
            find bazel-bin/ -perm +111 -type f -name "*_test"  -print0 | xargs -0 tar -cvzf test_binary.tar.gz
            find bazel-testlogs/ -type f -name "test.log"  -print0 | xargs -0 tar -cvzf test_logs.tar.gz
            # mac test somehow is really unstable on CI machines, make it always pass for now
            exit 0
      - save_cache:
          key: spu-build-{{ arch }}-{{ .Environment.CIRCLE_BUILD_NUM }}
          paths:
            - ~/.cache/spu_build_cache
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test_binary.tar.gz
      - store_artifacts:
          path: test_logs.tar.gz
  macOS_publish:
    macos:
      xcode: 13.4.1
    environment:
      HOMEBREW_NO_AUTO_UPDATE: 1
    resource_class: large
    steps:
      - checkout
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-{{ arch }}-
      - run:
          name: "Install homebrew dependencies"
          command: |
            brew install bazel cmake ninja nasm libomp wget go
            (cd "/usr/local/Cellar/bazel/5.1.1/libexec/bin" && curl -fLO https://releases.bazel.build/5.4.0/release/bazel-5.4.0-darwin-x86_64 && chmod +x bazel-5.4.0-darwin-x86_64)
      - run:
          name: "Install Miniconda"
          command: |
            wget https://repo.anaconda.com/miniconda/Miniconda3-py38_22.11.1-1-MacOSX-x86_64.sh -O ~/miniconda.sh
            bash ~/miniconda.sh -b -p $HOME/miniconda
            source $HOME/miniconda/bin/activate
            conda init zsh bash
            conda install -y grpcio
            pip install -r requirements.txt
      - run:
          name: "build package and publish"
          command: |
            set +e
            sh ./build_wheel_entrypoint.sh
            spu_wheel_name=$(<./spu_wheel.name)
            spu_wheel_path="./${spu_wheel_name//sf-spu/sf_spu}"
            python3 -m pip install twine
            python3 -m twine upload -r pypi -u __token__ -p ${PYPI_TWINE_TOKEN} $spu_wheel_path

  linux_publish:
    docker:
      - image: registry.hub.docker.com/secretflow/secretflow-gcc11-centos7-release:0.1
    resource_class: xlarge
    steps:
      - checkout
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-{{ arch }}-
      - run:
          name: "build package and publish"
          command: |
            set +e
            env BAZEL_MAX_JOBS=16 sh ./build_wheel_entrypoint.sh
            spu_wheel_name=$(<./spu_wheel.name)
            spu_wheel_path="./${spu_wheel_name//sf-spu/sf_spu}"
            python3 -m pip install twine
            python3 -m twine upload -r pypi -u __token__ -p ${PYPI_TWINE_TOKEN} $spu_wheel_path

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  benchmark:
    when: << pipeline.parameters.run-schedule >>
    jobs:
      - nn_benchmark
  ut:
    when:
      not: << pipeline.parameters.run-schedule >>
    jobs:
      - linux_ut
      - macOS_ut
  publish:
    when: << pipeline.parameters.GHA_Action >>
    jobs:
      - linux_publish
      - macOS_publish
