# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
parameters:
  GHA_Actor:
    type: string
    default: ""
  GHA_Action:
    type: string
    default: ""
  GHA_Event:
    type: string
    default: ""
  GHA_Meta:
    type: string
    default: ""

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:
  linux_ut:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    docker:
      - image: registry.hub.docker.com/secretflow/secretflow-gcc11-anolis-dev:0.3
    resource_class: 2xlarge
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      - checkout
      - restore_cache:
          name: "Restore pip cache"
          key: &pip-cache pip-{{ checksum "requirements.txt" }}
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-{{ arch }}-
      - run:
          name: "Install dependencies"
          command: pip install -r requirements.txt
      - run:
          name: "build"
          command: bazel build //spu/... -c opt --ui_event_filters=-info,-debug,-warning --jobs=16 --disk_cache=~/.cache/spu_build_cache
      - run:
          name: "test"
          command: |
            set +e
            declare -i test_status
            bazel test //spu/... -c opt --ui_event_filters=-info,-debug,-warning --jobs=16 --test_output=errors --disk_cache=~/.cache/spu_build_cache | tee test_result.log; test_status=${PIPESTATUS[0]}
            sh .ci/rename-junit-xml.sh
            find bazel-bin/ -executable -type f -name "*_test"  -print0 | xargs -0 tar -cvzf test_binary.tar.gz
            find bazel-testlogs/ -type f -name "test.log"  -print0 | xargs -0 tar -cvzf test_logs.tar.gz
            exit ${test_status}
      - save_cache:
          key: *pip-cache
          paths:
            - /usr/local/lib64/python3.8/site-packages
      - save_cache:
          key: spu-build-{{ arch }}-{{ .Environment.CIRCLE_BUILD_NUM }}
          paths:
            - /root/.cache/spu_build_cache
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test_binary.tar.gz
      - store_artifacts:
          path: test_logs.tar.gz
  macOS_ut:
    macos:
      xcode: 13.4.1
    environment:
      HOMEBREW_NO_AUTO_UPDATE: 1
    resource_class: large
    steps:
      - checkout
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-{{ arch }}-
      - run:
          name: "Install homebrew dependencies"
          command: brew install bazel cmake ninja nasm libomp wget
      - run:
          name: "Install Miniconda"
          command: |
            wget https://repo.anaconda.com/miniconda/Miniconda3-py38_22.11.1-1-MacOSX-x86_64.sh -O ~/miniconda.sh
            bash ~/miniconda.sh -b -p $HOME/miniconda
            source $HOME/miniconda/bin/activate
            conda init bash zsh
            conda install -y grpcio
            pip install -r requirements.txt
      - run:
          name: "build"
          command: bazel build //spu/... -c opt --ui_event_filters=-info,-debug,-warning --disk_cache=~/.cache/spu_build_cache
      - run:
          name: "test"
          command: |
            set +e
            brew install coreutils
            declare -i test_status
            bazel test //spu/... -c opt --ui_event_filters=-info,-debug,-warning --test_output=errors --disk_cache=~/.cache/spu_build_cache --jobs=4 | tee test_result.log; test_status=${PIPESTATUS[0]}
            sh .ci/rename-junit-xml.sh
            find bazel-bin/ -perm +111 -type f -name "*_test"  -print0 | xargs -0 tar -cvzf test_binary.tar.gz
            find bazel-testlogs/ -type f -name "test.log"  -print0 | xargs -0 tar -cvzf test_logs.tar.gz
            # mac test somehow is really unstable on CI machines, make it always pass for now
            exit 0
      - save_cache:
          key: spu-build-{{ arch }}-{{ .Environment.CIRCLE_BUILD_NUM }}
          paths:
            - ~/.cache/spu_build_cache
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test_binary.tar.gz
      - store_artifacts:
          path: test_logs.tar.gz
  macOS_publish:
    macos:
      xcode: 13.4.1
    environment:
      HOMEBREW_NO_AUTO_UPDATE: 1
    resource_class: large
    steps:
      - checkout
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-{{ arch }}-
      - run:
          name: "Install homebrew dependencies"
          command: brew install bazel cmake ninja nasm libomp wget
      - run:
          name: "Install Miniconda"
          command: |
            wget https://repo.anaconda.com/miniconda/Miniconda3-py38_22.11.1-1-MacOSX-x86_64.sh -O ~/miniconda.sh
            bash ~/miniconda.sh -b -p $HOME/miniconda
            source $HOME/miniconda/bin/activate
            conda init zsh bash
            conda install -y grpcio
            pip install -r requirements.txt
      - run:
          name: "build package and publish"
          command: |
            set +e
            sh ./build_wheel_entrypoint.sh
            spu_wheel_name=$(<./spu_wheel.name)
            spu_wheel_path="./${spu_wheel_name//sf-spu/sf_spu}"
            python3 -m pip install twine
            python3 -m twine upload -r pypi -u __token__ -p ${PYPI_TWINE_TOKEN} $spu_wheel_path

  linux_publish:
    docker:
      - image: registry.hub.docker.com/secretflow/secretflow-gcc11-centos7-release:0.3
    resource_class: xlarge
    steps:
      - checkout
      - restore_cache:
          name: "Restore build cache"
          key: spu-build-{{ arch }}-
      - run:
          name: "build package and publish"
          command: |
            set +e
            env BAZEL_MAX_JOBS=16 sh ./build_wheel_entrypoint.sh
            spu_wheel_name=$(<./spu_wheel.name)
            spu_wheel_path="./${spu_wheel_name//sf-spu/sf_spu}"
            python3 -m pip install twine
            python3 -m twine upload -r pypi -u __token__ -p ${PYPI_TWINE_TOKEN} $spu_wheel_path

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  ut:
    jobs:
      - linux_ut
      - macOS_ut
  linux_publish:
    when: << pipeline.parameters.GHA_Action >>
    jobs:
      - linux_publish
  macOS_publish:
    when: << pipeline.parameters.GHA_Action >>
    jobs:
      - macOS_publish
