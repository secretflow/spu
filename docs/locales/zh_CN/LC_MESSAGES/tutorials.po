# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021 Ant Group Co., Ltd.
# This file is distributed under the same license as the SPU package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SPU \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-08 14:16+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../tutorials/cpp_lr_example.rst:2
msgid "C++ Example: Logistic Regression"
msgstr ""

#: ../../tutorials/cpp_lr_example.rst:4
msgid ""
"To use SPU C++ API, we have to first :ref:`getting_started/install:From "
"Source`, this document shows how to write a privacy preserving logistic "
"regression program with SPU C++ API."
msgstr ""

#: ../../tutorials/cpp_lr_example.rst:8
msgid "Logistic Regression"
msgstr ""

#: ../../tutorials/cpp_lr_example.rst:15
msgid "Run it"
msgstr ""

#: ../../tutorials/cpp_lr_example.rst:17
msgid "Start two terminals."
msgstr ""

#: ../../tutorials/cpp_lr_example.rst:19
msgid "In the first terminal."
msgstr ""

#: ../../tutorials/cpp_lr_example.rst:25
msgid "In the second terminal."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9
msgid "Develop Your First MPC-Application"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:20
msgid ""
"The following codes are demos only. Itâ€™s NOT for production due to system"
" security concerns, please DO NOT use it directly in production."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:31
msgid "This is an introductory secretflow tutorial that contains:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:33
msgid "Implement a simple algorithm and run it in plaintext as baseline."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:34
msgid "Use simulator to check the **precision loss** and try to fix it."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:35
msgid ""
"Run elaborated emulations to give reports on both **efficiency and "
"correctness**."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:37
msgid ""
"We **highly recommend** the reader to read `spu-quickstart "
"<../tutorials/quick_start.ipynb>`__ before continuing read this tutorial,"
" which you can learn some basic usage of Device, DeviceObject and how to "
"run program in secret."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:49
msgid "Part 0: Prepare the environment and dataset"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:51
msgid ""
"Environment: To run this tutorial, you should have spu installed in your "
"environment(if not, you can refer to `this "
"<https://www.secretflow.org.cn/docs/spu/en/getting_started/install.html>`__)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:52
msgid ""
"Dataset: We use the breast cancer wisconsin dataset, which can be "
"obtained from sklearn. And we just do simple minmax transform for "
"preprocessing"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:409
msgid "Part 1: Implement algorithm in plaintext"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:411
msgid ""
"`SGD <https://en.wikipedia.org/wiki/Stochastic_gradient_descent>`__\\ "
"(Stochastic Gradient Descent) is a simple but effective optimization "
"algorithm, so in MPC settings, it's common to use it to optimize the "
"model."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:413
msgid ""
"`LR <https://en.wikipedia.org/wiki/Logistic_regression>`__\\ (Logistic "
"Regression) is a widely used linear model especially in financial "
"industry. So in this tutorial, as an example, we will implement LR with a"
" modified SGD, called `policy-sgd "
"<../development/policy_sgd_insight.rst>`__, which can accelerate the "
"speeds of training in most scenery."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:424
msgid "Here, we just list some important equations used in policy-sgd:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:426
msgid "LR compute gradient with(``n`` is batch_size):"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:428
#: ../../tutorials/develop_your_first_mpc_application.ipynb:2420
#, python-brace-format
msgid ""
"grad = \\frac{1}{n} \\sum_{i} (sigmoid(w^T x_i) - y_i) x_i\n"
"\n"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:429
msgid "Policy-sgd compute dk in first epoch with(``p`` is number of features):"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:431
msgid ""
"d_k = \\frac{1}{\\sqrt{\\sum_j^{p} grad_j^2} + \\epsilon}\n"
"\n"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:432
msgid "Then, update weights with(``i`` means i-th epoch, ``k`` means k-th iter):"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:434
#, python-brace-format
msgid ""
"w_{i,k} = w_{i, k-1} -  d_k * \\alpha *  grad\n"
"\n"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:445
msgid ""
"In this part, we first forget the MPC setting(data split, protocol...) "
"and implement the algorithm in plaintext. Secretflow recommends user to "
"do this with `Jax <https://jax.readthedocs.io/en/latest/>`__, which "
"``jax.numpy`` provides a familiar NumPy-style API for ease of adoption. "
"If you are familiar with Numpy, you can go through `this blog "
"<https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html>`__"
" and gets some caveats and then write jax-code just like numpy-code."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:472
msgid ""
"The original response function for LR is sigmoid function, which contains"
" time-consuming ops like exp and division in MPC. So it's common to "
"approximate sigmoid function with other MPC-friendly function. Here we "
"give two method, i.e. first-order Taylor and square root approximation."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:522
msgid "policy-sgd needs scale learning rate in first epoch."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:550
msgid ""
"Then, we give a brief implementation of LR with policy-sgd, and have "
"similar interface(but less) with sklearn."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:552
msgid ""
"**Note**: for simplicity, we will always fit intercept in LR model and "
"omit regularization and other techniques. For full version of SSLR, can "
"refer to ``SSRegression`` in secretflow."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:712
msgid "Now, let's try this algorithm in plaintext!"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:770
msgid "Things seem go well, try to predict the dataset and compute auc."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:829
msgid "Part 2: Run algorithm with simulator"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:831
msgid ""
"Normally, you can just do something like `LR with spu "
"<https://www.secretflow.org.cn/docs/secretflow/en/tutorial/lr_with_spu.html>`__"
" to run your program within a secure context: move you dataset to PYU or "
"SPU, run program with SPU you declare and reveal some information you "
"need(``reveal`` is a **very dangerous** op, and you should use it very "
"carefully in real application)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:833
msgid ""
"However, we will see later that you may come across large **metric "
"gap**\\ (like auc in LR) between plaintext and secret. It will be a "
"better choice that developer can run MPC program simpler with high "
"flexibility to adjust hyper-parameters like the size of ring, fxp or "
"underlying MPC protocol etc."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:835
msgid ""
"So in this part, we will show how to use simulator to run our algorithm "
"just like running normal MPC program, and do minimum experiments to focus"
" and verify the pitfall of the program. To use simulator but not running "
"program with SPU Device directly has two advantages:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:837
msgid ""
"**Fewer Code**: No need to deal with tons of ``DeviceObject`` and move "
"data from PYU between SPU."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:838
msgid ""
"**Quicker Experiment**: No ray cluster connected, run experiments end-to-"
"end."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:861
msgid ""
"Here, to simulate , we first define a simple simulator with CHEETAH "
"protocol and 64 bits ring in 2pc settings. We will talk about 3pc later."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2284
msgid "Then, we try it in 3pc setting, i.e. use ABY3 protocol."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2387
msgid ""
"When the program runs in secret without any modification, the auc may "
"drop dramatically after training 3 epochs(from 0.990 to 0.490 for "
"cheetah)!"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2389
msgid ""
"We will give some analysis and try to fix it first from application "
"perspective and think deeper in MPC perspective."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2401
msgid "Application Perspective"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2403
msgid ""
"Before we dive into this question, we can first summarize the differences"
" of policy-sgd between naive-sgd are:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2405
msgid "Using approximation function to compute sigmoid(default is t1)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2407
msgid ""
"The scale of learning rate, which contains the computation of dk as "
"defined in ``compute_dk_func``."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2418
msgid ""
"Doing some simple math, we can notice that t1 approximation will force "
"the pred to 0 when inner product is less than -2 and to 1 when inner "
"product is large than 2. So when we compute gradient with:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2422
msgid ""
"If coincidentally, we can get all elements of grad very near to 0(may "
"have little error in MPC), then the ``dk`` computed in first epoch "
"becomes very large, and may result in the failure of training. We can "
"verify this by simply enlarge the ``batch_size`` to 64 which can decrease"
" the probability of all-zero problem."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2673
msgid ""
"Restricting large batch_size is not an appropriate way, the key is to "
"make the scale factor smaller, we can also fix the question by enlarging "
"the ``eps``, e.g. change ``eps`` from 1e-6 to 1e-2."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:2675
msgid ""
"**Note**: ``eps`` in policy-sgd indeed has two affects, one is to prevent"
" the zero-division error, the other is to restrict the maximum scale "
"factor in warm-start phase(first epoch)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:4056
msgid ""
"The above analyses are based on t1 sigmoid, which leads to 0 in grad. So "
"we can switch the t1 approximation to other non-truncate but costly "
"form(e.g. sr approximation)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5437
msgid ""
"So, if we just consider it on app layer, we can get three rules for "
"fixing:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5439
msgid "enlarge ``batch_size``."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5441
msgid "enlarge ``eps``."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5443
msgid "use non-truncate sigmoid approximation(e.g. sr approximation)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5455
msgid "MPC Perspective"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5457
msgid ""
"In this part, we concentrate more on why huge error occurs. To achieve "
"this goal, we will talk according to underlying protocol and use "
"simulator to do some **experiments** to confirm our hypothesis. Readers "
"can do the similar things when you develop your own secure application."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5459
msgid ""
"Before diving into the problem deeper, we highly recommend the reader to "
"read:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5461
msgid ""
"`spu_inside <https://www.secretflow.org.cn/docs/spu/latest/en-"
"US/tutorials/spu_inside#Tracing>`__: gives some introductions how spu "
"works inside for float-point operations."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5463
msgid ""
"`pitfall <https://www.secretflow.org.cn/docs/spu/latest/en-"
"US/development/fxp>`__: spu implements math function(like ``reciprocal``,"
" ``log`` and so on) with approximation algorithm, so some precision issue"
" will occur when inputs fall into some intervals. We list some known "
"issue about this."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5465
msgid ""
"`protocols <https://www.secretflow.org.cn/docs/spu/latest/en-"
"US/reference/mpc_status>`__: list all protocols spu implements now. "
"Generally speaking, for 2pc, it's safe to use cheetah, while for 3pc, "
"ABY3 is the only choice."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5467
msgid "First define a function just like ``fit_and_predict`` to get dk_arr."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5508
msgid "2PC: Cheetah Protocol"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5510
msgid "Recap:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5512
msgid ""
"`cheetah <https://eprint.iacr.org/2022/207>`__ is a fast 2pc semi-honest "
"protocol which uses FHE to accelerate the computation. But it will have "
"0-2 bits error when do ``mul`` or ``dot``."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5514
msgid ""
"If 64-bits ring, about 18 bitwidth fixed-point number will be used. So "
"the minimum positive float spu can represent is "
":math:`\\frac{1}{2^{18}}`."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:5525
msgid "We first check the output of dk_arr and try to find the caveat."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:6005
msgid ""
"Surprisingly, we get a very **small negative number** which makes that "
"weight update wrong!(the opposite direction and large scale factor for "
"sgd)"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:6051
msgid "However, if we use a bigger ring, then everything is ok."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:7947
msgid ""
"From the above outputs, we can guess if input is near "
":math:`\\frac{1}{2^{18}}` and use cheetah protocol, when doing ``square``"
" and ``sum``, the bit error may be significant and not negligible(``mul``"
" and ``dot`` have 0-2 bit errors)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8109
msgid ""
"So if ``eps=1e-6``, the two norm of grad may be a negative number when "
"each element of grad is near to :math:`\\frac{1}{2^{18}}`, then we get a "
"very small negative dk."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8111
msgid "This explains the claims we get from app layer:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8113
msgid ""
"Enlarging ``batch_size``: the probability of all elements of grad is zero"
" becomes small."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8115
msgid "Enlarging ``eps``: force the denominator to be positive number."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8127
msgid "3PC: ABY3 Protocol"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8129
msgid "We still check the dk_arr first."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8150
msgid "emmmmmm, strange value occurs again, we find **0** in dk_arr!"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8196
msgid ""
"Comparing with small negative number, 0 is a mild error for our update "
"procedure. It just does nothing in that iter, so the final auc may drop a"
" little(from 0.99 to 0.97, users can test yourself that if you set eps to"
" 1e-2, then the result will be very stable)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8207
msgid "Likewise, We always check the computation of 2-norm."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8290
msgid "Then, check the reciprocal op."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8349
msgid "Something More"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8351
msgid ""
"Indeed, there are some other interesting things in SSLR. Here, due to "
"length limitations, we just give some hints, and readers can do more "
"simulations yourself!"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8363
msgid "Rsqrt v.s. Norm"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8365
msgid ""
"We can recall that the ``compute_dk_func`` function defined in Part 1 "
"contains a ``method`` arg, and we just ignore this arg before. Indeed, we"
" can tell simulator to print more information like `spu_inside "
"<https://www.secretflow.org.cn/docs/spu/latest/en-"
"US/tutorials/spu_inside#Tracing>`__ do: enable **hlo**\\ (High Level "
"Operations) trace and profile on. Then we can figure out which op has "
"been invoked and its time cost."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8367
msgid ""
"Here, we list some advantages of using ``jax.lax.rsqrt`` rather than "
"``jnp.linalg.norm``:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8369
msgid ""
"Fewer bytes and few send actions: which leads to smaller running time(See"
" the following comments and notes for details)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8371
msgid ""
"More stable when given same ``eps``: if we regard ``f(x)`` as "
"``compute_dk_func`` with ``method=norm``, and ``g(x)`` with "
"``method=rsqrt``, then the users can do simulation yourself, and find "
"``f(x)`` has higher relative error than ``g(x)``."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:8625
msgid "If directly invoking rsqrt, you can find send actions have obvious drop!"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9075
msgid ""
"When using aby3, you can find both the send actions and send bytes drop "
"large if using rsqrt!"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9297
msgid "Computing Loss"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9299
msgid ""
"Many ML frameworks will show validation loss during training procedure "
"when using a validation dataset. It's straight to compute the loss in LR "
"as follows:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9301
#, python-brace-format
msgid ""
"loss = -\\frac{1}{N} \\sum_{i=1}^N [y_i log(p_i) + (1-y_i) log(1-p_i)] "
"\\quad  (1)\n"
"\n"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9303
msgid ""
"But when you use t1 approximation for sigmoid, then you may come across "
":math:`log(0)` problem. Here, we list two potential recipes to alleviate "
"it."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9305
msgid ""
"**Costly but accurate**: we plug in :math:`p_i = "
"\\frac{1}{1+e^{-w^Tx_i}}` to (1), then we can get:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9307
#, python-brace-format
msgid ""
"loss = -\\frac{1}{N} \\sum_{i=1}^N [y_i w^Tx_i - log(1+e^{w^Tx_i})] "
"\\quad  (2)\n"
"\n"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9309
#, python-brace-format
msgid ""
"this formula solve the :math:`log(0)` problem, but if :math:`w^Tx_i` gets"
" too large, as we already know in `pitfall "
"<https://www.secretflow.org.cn/docs/spu/en/reference/fxp.html>`__, this "
"gets **huge errors**! To get stable and accurate formula to compute loss,"
" we notice :math:`log(1+e^{w^T x_i})` is well-known *Softplus* function, "
"so we can use the equation of Softplus: :math:`log(1+e^{x}) = log(1 + "
"e^{-|x|}) + max(0, x)`, then we can get:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9311
#, python-brace-format
msgid ""
"loss = -\\frac{1}{N} \\sum_{i=1}^N [y_i w^Tx_i - log(1+e^{-|w^Tx_i|}) - "
"max(w^T x_i, 0)] \\quad (3)\n"
"\n"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9313
msgid ""
"**Cheap but approximate** :Equation (3) can give accurate result, but it "
"contains time-consuming ops(:math:`log`, :math:`exp`), which cost a lot! "
"If you just want to compute an approximation of loss(e.g. maybe you want "
"to do early stop with loss), you can try Taylor expansion, which gives:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9315
#, python-brace-format
msgid ""
"loss = \\frac{1}{N} \\sum_{i=1}^N [log(2) - (y-0.5)w^T x_i + 0.125 * (w^T"
" x_i)^2]\n"
"\n"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9327
msgid "Part 3: Run elaborated emulations"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9329
msgid ""
"Emulations is an **experimental** feature for now, and is under rapid "
"development, so we do not package the code of sml into spu. Users can try"
" this feature from **source code** and run with bazel .Till now, we only "
"have support for LAN setting(``MULTIPROCESS`` mode). ``Docker`` mode, "
"which runs program like under WAN setting, will be posted in future "
"version."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9331
msgid ""
"Finally, we talk about how to do emulations. Comparing to simulator, "
"emulator runs with a simple scheduler like Secretflow does, and offers "
"some facility(e.g. generate mock data) to make benchmark simpler. So spu "
"provides an ``Emulator`` class and gives an easy-to-use interface."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9342
msgid ""
"Usually, the emulation will be done with larger dataset, so we won't run "
"directly in this tutorial notebook. Instead, we will show a big picture "
"on how to design and run emulations for MPC application step by step."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9354
msgid "Setup: define running function"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9356
msgid ""
"Just like what we do in secretflow, we should first define a python "
"function, which will be run in spu. Here, as an example, we just define a"
" very simple function that accepts data from two parties and return the "
"predicted probability after the model trained(you can also split data "
"into training & validation parts, and return the probs of validation "
"dataset.)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9358
msgid ""
"Taking ``SSLRSGDClassifier`` as an example, we mainly want to argue that "
"policy-sgd is better than naive-sgd in MPC setting, so we can design the "
"following experiments:"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9360
msgid ""
"Find best ``dk_method`` and ``eps`` for policy-sgd: for all datasets, "
"compare the accuracy and efficiency."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9362
msgid ""
"Compare the accuracy and efficiency when switching ``sig_type`` for both "
"policy-sgd and naive-sgd."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9364
msgid ""
"To compare policy-sgd and naive-sgd, we fix ``epochs`` and test the "
"influence of ``learning_rate`` and ``batch_size``."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9420
msgid "Define running config"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9422
msgid ""
"After designing all the experiments, we can prepare our running config. "
"Currently, we only support ``MULTIPROCESS`` mode, which uses multiprocess"
" to emulate multi-party and just like running in LAN(``DOCKER`` mode "
"which can set ``bandwidth`` and ``latency`` to simulate the different WAN"
" settings will be supported in future version)."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9424
msgid ""
"For now, our goal is to compare the accuracy/efficiency diff when "
"switching hyper-param, running program in LAN can be a good choice. "
"Besides, in order to simulate diverse node deployment ways, users can "
"flexibly configure the number of nodes and device situations yourself. "
"You can get some examples of config in ``examples/python/conf/``."
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9888
msgid "Put them together"
msgstr ""

#: ../../tutorials/develop_your_first_mpc_application.ipynb:9890
msgid "Now we put all these together, we can get a simple paradigm of emulation."
msgstr ""

#: ../../tutorials/index.rst:2
msgid "Tutorials"
msgstr ""

#: ../../tutorials/index.rst:5
msgid ""
"We will add more tutorials here! At this moment, please check `examples "
"<https://github.com/secretflow/spu/tree/main/examples>`_ folder of source"
" code on you own."
msgstr ""

#: ../../tutorials/quick_start.ipynb:9
msgid "SPU Quickstart"
msgstr ""

#: ../../tutorials/quick_start.ipynb:12
msgid "Program with JAX"
msgstr ""

#: ../../tutorials/quick_start.ipynb:14
msgid ""
"SPU, as an `XLA <https://www.tensorflow.org/xla>`__ backend, does not "
"provide a high-level programming API by itself, instead, we can use any "
"API that supports the XLA backend to program. In this tutorial, we use "
"`JAX <https://github.com/google/jax>`__ as the programming API and "
"demonstrate how to run a JAX program on SPU."
msgstr ""

#: ../../tutorials/quick_start.ipynb:16
msgid ""
"JAX is an AI framework from Google. Users can write the program in NumPy "
"syntax, and let JAX translate it to GPU/TPU for acceleration, please read"
" the following pages before you start:"
msgstr ""

#: ../../tutorials/quick_start.ipynb:18
msgid ""
"`JAX Quickstart "
"<https://jax.readthedocs.io/en/latest/notebooks/quickstart.html>`__"
msgstr ""

#: ../../tutorials/quick_start.ipynb:19
msgid ""
"`How to Think in JAX "
"<https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html>`__"
msgstr ""

#: ../../tutorials/quick_start.ipynb:20
msgid ""
"`JAX - The Sharp Bits "
"<https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html>`__"
msgstr ""

#: ../../tutorials/quick_start.ipynb:22
msgid "Now we start to write some simple JAX code."
msgstr ""

#: ../../tutorials/quick_start.ipynb:92
msgid ""
"The above code snippet creates two random variables and compares which "
"one is greater. Yes, the code snippet is not interesting yet~"
msgstr ""

#: ../../tutorials/quick_start.ipynb:104
msgid "Program with SPU"
msgstr ""

#: ../../tutorials/quick_start.ipynb:106
msgid "Now, let's convert the above code to an SPU program."
msgstr ""

#: ../../tutorials/quick_start.ipynb:109
msgid "A Quick introduction to device system"
msgstr ""

#: ../../tutorials/quick_start.ipynb:111
msgid ""
"MPC programs are \"designed\" to be used in distributed way. In this "
"tutorial, we use SPU builtin distributed framework for demonstration."
msgstr ""

#: ../../tutorials/quick_start.ipynb:113
msgid ""
"Warn: it's for demonstration purpose only, you should use an industrial "
"framework like SecretFlow in production."
msgstr ""

#: ../../tutorials/quick_start.ipynb:115
msgid "To start the ppd cluster. In a separate terminal, run"
msgstr ""

#: ../../tutorials/quick_start.ipynb:121
msgid ""
"This command starts multi-processes to simulate parties that do not trust"
" each other. Please keep the terminal alive."
msgstr ""

#: ../../tutorials/quick_start.ipynb:227
msgid "``ppd.init`` initialize the SPU device system on the given cluster."
msgstr ""

#: ../../tutorials/quick_start.ipynb:229
msgid ""
"The cluster has three nodes, each node is a process that listens on a "
"given port."
msgstr ""

#: ../../tutorials/quick_start.ipynb:231
msgid "The 3 physical nodes construct 3 virtual devices."
msgstr ""

#: ../../tutorials/quick_start.ipynb:233
msgid ""
"``P1`` and ``P2`` are so called ``PYU Device``, which is just a simple "
"Python device that can run a python program."
msgstr ""

#: ../../tutorials/quick_start.ipynb:234
msgid ""
"``SPU`` is a virtual device hosted by all 3-nodes, which use MPC "
"protocols to compute securely."
msgstr ""

#: ../../tutorials/quick_start.ipynb:236
msgid "Virtually, it looks like below picture."
msgstr ""

#: ../../tutorials/quick_start.ipynb:238
msgid "|alt text|"
msgstr ""

#: ../../tutorials/quick_start.ipynb:245
msgid "alt text"
msgstr ""

#: ../../tutorials/quick_start.ipynb:240
msgid ""
"On the left side, there are three physical nodes, a circle means the node"
" runs a ``PYU Device`` and a triangle means the node runs a ``SPU Device "
"Slice``."
msgstr ""

#: ../../tutorials/quick_start.ipynb:241
msgid ""
"On the right side, its virtual device layout is constructed by the left "
"physical node."
msgstr ""

#: ../../tutorials/quick_start.ipynb:243
msgid "We can also check the detail of ``SPU device``."
msgstr ""

#: ../../tutorials/quick_start.ipynb:308
msgid ""
"The ``SPU`` device uses ``ABY3`` as the its backend protocol and runs on "
"``Ring128`` field."
msgstr ""

#: ../../tutorials/quick_start.ipynb:311
msgid "Move JAX program to SPU"
msgstr ""

#: ../../tutorials/quick_start.ipynb:313
msgid "Now, let's move the JAX program from CPU to SPU."
msgstr ""

#: ../../tutorials/quick_start.ipynb:341
msgid ""
"``ppd.device(\"P1\")(make_rand)`` convert a python function to a "
"``DeviceFunction`` which will be called on ``P1`` device."
msgstr ""

#: ../../tutorials/quick_start.ipynb:343
msgid ""
"The terminal that starts the cluster will print log like this, which "
"means the ``make_rand`` function is relocated to another node and "
"executed there."
msgstr ""

#: ../../tutorials/quick_start.ipynb:359
msgid ""
"The result of ``make_rand`` is also stored on ``P1`` and invisible for "
"other device/node. For example, when printing them, all the above objects"
" are ``DeviceObject``, the plaintext object is invisible."
msgstr ""

#: ../../tutorials/quick_start.ipynb:411
msgid ""
"And finally, we can reveal the result via ``ppd.get``, which will fetch "
"the plaintext from devices to this host(notebook)."
msgstr ""

#: ../../tutorials/quick_start.ipynb:457
msgid ""
"The result shows that the random variable ``x`` from ``P1`` is greater "
"than ``y`` from ``P2``, we can check the result by revealing origin "
"inputs."
msgstr ""

#: ../../tutorials/quick_start.ipynb:505
#, python-format
msgid ""
"With above code, we implements the classic `Yao's millionares' problem "
"<https://en.wikipedia.org/wiki/Yao%27s_Millionaires%27_problem>`__ on "
"SPU. Note:"
msgstr ""

#: ../../tutorials/quick_start.ipynb:507
msgid ""
"SPU re-uses ``jax`` api, and translates it to SPU executable, there is no"
" ``import spu.jax as jax`` stuffs."
msgstr ""

#: ../../tutorials/quick_start.ipynb:508
msgid ""
"SPU hides secure semantic, to compute a function *securely*, just simply "
"mark it on SPU."
msgstr ""

#: ../../tutorials/quick_start.ipynb:520
msgid "Logistic regression"
msgstr ""

#: ../../tutorials/quick_start.ipynb:522
msgid ""
"Now, let's check a more complicated example, privacy-preserving logistic "
"regression."
msgstr ""

#: ../../tutorials/quick_start.ipynb:524
msgid "First, write the raw JAX program."
msgstr ""

#: ../../tutorials/quick_start.ipynb:593
msgid "Run the program on CPU, the result (AUC) works as expected."
msgstr ""

#: ../../tutorials/quick_start.ipynb:641
msgid "Now, use ``ppd.device`` to make the above code run on SPU."
msgstr ""

#: ../../tutorials/quick_start.ipynb:669
msgid ""
"``P1`` loads the features(X) only, ``P2`` loads the labels(Y) only, and "
"for convenience, P1/P2 uses the same dataset, but only loads partial "
"(either feature or label). Now ``P1 and P2`` want to train the model "
"without telling each other the privacy data, so they use SPU to run the "
"``train`` function."
msgstr ""

#: ../../tutorials/quick_start.ipynb:671
msgid ""
"It takes a little while to run the above program since privacy preserving"
" program runs much slower than plaintext version."
msgstr ""

#: ../../tutorials/quick_start.ipynb:673
msgid ""
"The parameters W and bias B are also located at SPU (no one knows the "
"result). Finally, let's reveal the parameters to check correctness."
msgstr ""

#: ../../tutorials/quick_start.ipynb:721
msgid ""
"For this simple dataset, AUC metric shows exactly the same, but since SPU"
" uses fixed point arithmetic, which is not as accurate as IEEE floating "
"point arithmetic, the trained parameters are not exactly the same."
msgstr ""

#: ../../tutorials/quick_start.ipynb:843
msgid "Visibility inference"
msgstr ""

#: ../../tutorials/quick_start.ipynb:845
msgid ""
"SPU compiler/runtime pipeline works together to protect privacy "
"information."
msgstr ""

#: ../../tutorials/quick_start.ipynb:847
msgid ""
"When an object is transferred from PYU to SPU device, the data is first "
"encrypted (secret shared) and then sent to SPU hosts."
msgstr ""

#: ../../tutorials/quick_start.ipynb:849
msgid ""
"The SPU compiler deduces the visibility of the entire program, including "
"all nodes in the compute DAG, from the input's visibility with a very "
"simple rule: for each SPU instruction, when any input is a secret, the "
"output is a secret. In this way, the ``secure semantic`` is propagated "
"through the entire DAG."
msgstr ""

#: ../../tutorials/quick_start.ipynb:851
msgid "For example,"
msgstr ""

#: ../../tutorials/quick_start.ipynb:901
msgid ""
"It shows that ``ppd.device`` decorated ``sigmoid`` is a "
"``DeviceFunction`` which could be launched by SPU."
msgstr ""

#: ../../tutorials/quick_start.ipynb:903
msgid "We can print the SPU bytecode via"
msgstr ""

#: ../../tutorials/quick_start.ipynb:990
msgid "It shows that the function type signature is:"
msgstr ""

#: ../../tutorials/quick_start.ipynb:996
msgid ""
"Note, since the input is random from the driver (this notebook), which is"
" not privacy information by default, so the input is ``tensor<3x3xf32>``,"
" which means it accepts a ``3x3 public f32 tensor``."
msgstr ""

#: ../../tutorials/quick_start.ipynb:998
msgid ""
"The compiler deduces the whole program's visibility type, and finds "
"output should be ``tensor<3x3xf32>``, which means a ``3x3 public f32 "
"tensor``."
msgstr ""

#: ../../tutorials/quick_start.ipynb:1000
msgid "Now let's generate input from ``P1`` and run the program again."
msgstr ""

#: ../../tutorials/quick_start.ipynb:1095
msgid ""
"Since the input comes from ``P1``, which is private, so the function "
"signature becomes:"
msgstr ""

#: ../../tutorials/quick_start.ipynb:1101
msgid ""
"This means accepts ``1 secret i32`` data and outputs ``1 secret f32`` "
"data, inside the compiled function, all internal instruction's visibility"
" type is also correctly deduced."
msgstr ""

#: ../../tutorials/quick_start.ipynb:1103
msgid ""
"With the JIT(just in time) type deduction, SPU protects the clients' "
"privacy."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:9
msgid "SPU Inside"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:20
msgid ""
"SPU is a virtual device backed by an MPC engine, which provides an "
"*arithmetic black box* abstraction to front-end users. Just like other "
"*black boxes*, it's not easy to understand what happened inside it."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:22
msgid ""
"For this reason, SPU provides some features to show what happened inside "
"it, this document demonstrates these features."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:25
msgid "Simulation"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:27
msgid ""
"As the name suggests, *multi-party computation* is born to be distributed"
" system with multiple participants, which makes it harder to setup, debug"
" and inspect. So SPU provides a *simulation module* that uses threads to "
"simulate multi-parties in a single process. All parties acts exactly the "
"same as in production environment, so we can use it as a playground to "
"inspect the internals of SPU."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:29
msgid "To use the simulation module, we can simple do"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:55
msgid "Now we can create SPU simulator and run program on it."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:119
msgid "In the above code."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:121
msgid ""
"First, we create an SPU simulator backed by *ABY3* protocol with *FM64* "
"field."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:122
msgid ""
"Then we decorates a jax function ``jax.add`` to make it a SPU simulated "
"function."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:123
msgid "Then we can use the simulated function just like normal python functions."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:125
msgid ""
"As the result suggests, it behaves like a python function, we can also "
"print the compiled pphlo program with"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:188
msgid ""
"The above code is a pphlo dialect in `MLIR <https://mlir.llvm.org/>`__ "
"format, which defines a ``main`` function that accepts two arguments and "
"returns the sum as result."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:190
msgid ""
"Besides single ``jax.numpy`` op, we can simulate any jax function on SPU,"
" i.e."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:284
msgid "The above code is ``spu function`` which is composed of spu builtin ops."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:286
msgid ""
"Note: since spu use `JIT <https://en.wikipedia.org/wiki/Just-in-"
"time_compilation>`__ compilation, so we have to execute the function "
"before printing the compiled bytecode."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:298
msgid "Profling"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:300
msgid ""
"Besides simple simulation, we can profile the simulated program, although"
" the profiling result could NOT be used as a reference of SPU perf, it "
"still gives some information of what happened."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:302
msgid "To use profiling, we have enabled some feature flags."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:325
msgid ""
"``enable_pphlo_profile`` tells SPU runtime to print information about "
"pphlo, now, let's run the function on this new runtime."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:395
msgid ""
"The above log tells the total execution time and the detailed statistics "
"of each builtin function."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:397
msgid ""
"Besides the ``enable_pphlo_profile`` feature flag, SPU has other flags "
"like ``enable_hal_profile`` to dump runtime information in different "
"levels of instructions."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:400
msgid "Tracing"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:402
msgid ""
"*Profiling* can only tell the statistics of SPU instructions, it's still "
"hard to understand what happened inside it. *Tracing* is a feature that "
"used to print verbose ``call stack``, which helps to understand/inspect "
"what exactly happened."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:404
msgid ""
"To enable tracing features, just set ``enable_action_trace`` in the "
"runtime config."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:427
msgid "Now, let's run another function on this ``tracing enabled`` simulator."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:548
msgid ""
"At the first glance, the trace log is a bit of frustrating, so it worth a"
" little while to explain it."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:550
msgid "At the very begining, is the entry point of ``multiply`` function."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:552
msgid "Each line follows the format as below:"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:558
msgid ""
"For example, the second line ``[timestamp] [TR] [B]   "
"hal.mul(Value<2x2xSFXP,s=2,1>, Value<2x2xSFXP,s=2,1>)`` means:"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:560
msgid "this is a tracing log indicated by ``[TR]``"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:561
msgid "the function begins/ends ``[B/E]``"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:562
msgid "the module is ``hal``"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:563
msgid "the operator is ``mul``"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:564
msgid "the two args are both ``Value<2x2xSFXP,s=2,1>``"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:566
msgid ""
"Note, ``hlo`` is short for ``High Level Operations``, ``hal`` is short "
"for ``Hardware Abstraction Layer``, ``mpc`` is short for ``Multi-Party "
"Computation``."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:568
msgid ""
"The ``Value<2x2xSFXP,s=2,1>`` means it's a **S**\\ ecret **F**\\ i\\ "
"**X**\\ ed **P**\\ ointed tensor with shape(**2x2**) and "
"strides(**2,1**)."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:570
msgid ""
"the runtime dispatches the function according parameters datatype (in "
"this case *fxp*), then calls the corresponding fixed point handle "
"function ``hal.f_mul``, the prefix ``f_`` means its for fixed point."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:571
msgid ""
"the runtime dispatches ``hal.f_mul`` to the untyped version ``hal._mul`` "
"which operates on ``rings``."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:572
msgid ""
"the runtime dispatches ``hal._mul`` according to the *visibility* type, "
"since both parameters are **secret**, so ``hal._mul_ss`` is called, the "
"postfix ``_ss`` indicates that it operates on two secrets."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:574
msgid ""
"Then the function ``hal._mul_ss`` is dispatched to the MPC layer, the "
"signature becomes more complicated."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:580
msgid ""
"The signature of this operation is the same as above, ``mpc.mul_ss`` "
"indicates the module is ``mpc`` and the operation is ``mul_ss``."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:582
msgid "The type ``ArrayRef<4xaby3.AShr<FM64>>`` has two notable differences:"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:584
msgid ""
"unlike hal ops, mpc ops operates on 1D-array instead of tensor, which "
"makes it a more standard SIMD instruction."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:585
msgid ""
"the type ``aby3.AShr<FM64>`` is protocol-dependent, in this case, it's an"
" *ABY3* arithmetic share in FM64."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:587
msgid ""
"Finally, it's dispatched to ``mpc.mul_aa``, the postfix ``_aa`` indicates"
" both parameters are arithmetic shares, then the ABY3 share addition "
"protocol is performed."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:589
msgid ""
"But ``f_mul`` could not be done with ring multiplication only, we have to"
" ``truncate`` the result to make the fixed point legal, in the following "
"lines, ``hal._trunc`` is called and finally dispatched to ``mpc.trunc_a``"
" protocol."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:600
msgid "The above example is pretty straight forward, now let's make it harder."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:602
msgid ""
"Fixed point reciprocal is done with `Goldschmidt "
"<https://en.wikipedia.org/wiki/Division_algorithm#Goldschmidt_division>`__"
" approximation algorithm, the algorithm itself is not that simple, and "
"when it's executed on MPC, things become more complicated."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:604
msgid ""
"It takes a lot of effort to understand how it works, let's directly see "
"the tracing result."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3515
msgid "Surprise, it's really a lot of ops!"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3517
msgid ""
"Yes, that's why MPC is still relatively slow and why SPU wants to "
"optimize it :P"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3519
msgid ""
"The ``reciprocal`` is still a relative simple operator, you can try more "
"complicated op like ``convolution``."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3531
msgid "Misc"
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3533
msgid ""
"Simulation could be used to inspect other parts of SPU, i.e. the *fixed "
"point arithmetic* accuracy."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3535
msgid ""
"As the above example indicates, non-linear functions like ``reciprocal`` "
"and ``exp`` are approximated with some numeric methods, so the result is "
"not as accurate as floating point arithmetic."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3537
msgid "For example."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3653
msgid ""
"As we can see, the SPU version of ``exp`` (blue line) diverges with the "
"standard version when input is larger."
msgstr ""

#: ../../tutorials/spu_inside.ipynb:3664
msgid ""
"Finally, SPU, as a secure computation, behaves very differently from CPU,"
" both in accuracy and cost model, when you are not sure about how it "
"works, simulate on it!"
msgstr ""

