# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021 Ant Group Co., Ltd.
# This file is distributed under the same license as the SPU package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SPU \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-02-25 19:46+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../development/add_protocols.rst:2
msgid "Adding New MPC Protocols"
msgstr ""

#: ../../development/add_protocols.rst:5
msgid ""
"SecretFlow SPU currently is under active development and the APIs "
"provided to protocol developers may be unstable at this moment."
msgstr ""

#: ../../development/add_protocols.rst:8 ../../development/ir_dump.rst:8
msgid "Introduction"
msgstr ""

#: ../../development/add_protocols.rst:9
msgid ""
"This document is mainly for developers who want to add custom MPC "
"protocols in SPU. Before reading this document, we recommend that "
"developers have a basic understanding of the SPU system architecture "
"(i.e., :ref:`/development/compiler.rst`, "
":ref:`/development/type_system.rst` and :ref:`/development/runtime.rst`) "
"and the `layout "
"<https://github.com/secretflow/spu/blob/main/REPO_LAYOUT.md>`_ of the SPU"
" code repository. In short, SPU translates the high-level applications "
"(such as machine learning model training) written in JAX to an MPC-"
"specific intermediate representation named PPHLO and then dispatches "
"PPHLO operations to the low-level MPC protocols. In theory, protocol "
"developers only need to implement a basic set of MPC operation APIs to "
"fully use the SPU infrastructure to run machine learning or data analysis"
" programs. That is to say, for most MPC protocol development, it only "
"needs to add some source code files into the libspu/mpc folder. At "
"present, SPU has integrated several protocols such as ABY3 and Cheetah, "
"which can be regarded as a guide for protocol implementation."
msgstr ""

#: ../../development/add_protocols.rst:22
msgid "A walk-through guide"
msgstr ""

#: ../../development/add_protocols.rst:23
msgid ""
"We further illustrate the procedures of adding protocols step by step in "
"a **top-down** manner."
msgstr ""

#: ../../development/add_protocols.rst:26
msgid "Add a new protocol kind"
msgstr ""

#: ../../development/add_protocols.rst:27
msgid ""
"When users launch the SPU backend runtime, they will specify the running "
"MPC protocol kind through the runtime config. The protocol kinds "
"supported by SPU are enumerations defined in `spu.proto "
"<https://github.com/secretflow/spu/blob/main/libspu/spu.proto>`_. Thus, "
"developers must add their protocol kinds in this protobuf file to enable "
"SPU to be aware of the new protocols."
msgstr ""

#: ../../development/add_protocols.rst:33
msgid "ProtocolKind enumerations"
msgstr ""

#: ../../development/add_protocols.rst:49
msgid "Register protocol"
msgstr ""

#: ../../development/add_protocols.rst:50
msgid ""
"Each MPC protocol execution environment is abstracted as a C++ instance "
"of an `Object "
"<https://github.com/secretflow/spu/blob/main/libspu/core/object.h>`_ "
"class in SPU. SPU constructs an MPC object when creating an "
"**SPUContext**. Then, SPU registers a concrete protocol implementation "
"through a factory function named `RegisterProtocol "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/factory.cc>`_ "
"according to the runtime config. Therefore, protocol developers need to "
"add their functions in **RegisterProtocol** to implement protocols."
msgstr ""

#: ../../development/add_protocols.rst:55
msgid "RegisterProtocol function"
msgstr ""

#: ../../development/add_protocols.rst:77
msgid "Implement protocol IO interface"
msgstr ""

#: ../../development/add_protocols.rst:78
msgid ""
"Another function called by the factory class is the **CreateIO** "
"function. As different protocols use different secret sharing schemas, "
"which means SPU has to use different ways to input/output secret data "
"from plaintext data. As a results, developers have to implement these "
"protocol-specific APIs defined in `io_interface.h "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/io_interface.h>`_."
" Developers can check the `ABY3 implementation "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/io.cc>`_ as "
"a reference."
msgstr ""

#: ../../development/add_protocols.rst:84
msgid "Understand protocol object"
msgstr ""

#: ../../development/add_protocols.rst:85
msgid ""
"SPU protocol `Object "
"<https://github.com/secretflow/spu/blob/main/libspu/core/object.h>`_ may "
"be the key concept for adding new protocols. Let's take a closer look at "
"its design. The goal of **Object** class is to realize the generalization"
" and flexibility of developing MPC protocols through dynamic binding. An "
"Object instance has a series of kernels and states. A kernel and a state "
"can be regarded as a member function and a member variable of an Object, "
"respectively."
msgstr ""

#: ../../development/add_protocols.rst:91
msgid "SPU protocol Object class"
msgstr ""

#: ../../development/add_protocols.rst:127
msgid "Construct protocol object"
msgstr ""

#: ../../development/add_protocols.rst:128
msgid ""
"We take the ABY3 implementation as a specific example to further explain "
"the description above."
msgstr ""

#: ../../development/add_protocols.rst:130
msgid ""
"First of all, we can see that there is an independent aby3 directory "
"under the `libspu/mpc "
"<https://github.com/secretflow/spu/tree/main/libspu/mpc>`_ directory in "
"SPU's repository layout. The aby3 directory includes the C++ source files"
" and header files required by the ABY3 protocol implementation. These "
"files may be confusing at first glance. The key to know its code "
"organization is to open the `protocol "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/protocol.cc>`_"
" file, which defines the **regAby3Protocol** function for registering "
"kernels and states. This function will be called by the factory class "
"described in previous step."
msgstr ""

#: ../../development/add_protocols.rst:137
msgid "ABY3 protocol registration"
msgstr ""

#: ../../development/add_protocols.rst:164
msgid "Inside the **regAby3Protocol** function, it does three things."
msgstr ""

#: ../../development/add_protocols.rst:166
msgid ""
"The first is to register the protocol types. These types are defined in "
"the `type.h "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/type.h>`_ "
"header file, \\ representing an arithmetic secret share and a boolean "
"secret share, respectively."
msgstr ""

#: ../../development/add_protocols.rst:169
msgid ""
"The second is to register protocol states (variables), specifically "
"including the three states of Z2kState, \\ Communicator, and PrgState, "
"which are used to store the ring information, communication facilities, "
"and \\ pseudorandom number generator for protocol implementation."
msgstr ""

#: ../../development/add_protocols.rst:173
msgid ""
"The third is to register the protocol kernels (functions). We can see "
"that two types of kernels are registered. \\ The first type is the common"
" kernels implemented in the `pv2k.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/common/pv2k.cc>`_"
" \\ file. The second type is implemented in `arithmetic.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/arithmetic.cc>`_,"
" \\ `boolean.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/boolean.cc>`_"
" and other files under the aby3 directory."
msgstr ""

#: ../../development/add_protocols.rst:179
msgid "Implement protocol kernels"
msgstr ""

#: ../../development/add_protocols.rst:180
msgid ""
"In this section, we further explain why the ABY3 developer registers "
"these two types of kernels. In SPU, the interfaces between MPC and HAL "
"layers are defined in the `api.h "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/api.h>`_ file, "
"which consists of a set of operations with public or secret operands "
"(referred as **basic APIs** for the rest of this document). As long as a "
"protocol developer implements basic APIs, he/she can use the SPU full-"
"stack infrastructure to run high-level applications, e.g., training "
"complex neural network models."
msgstr ""

#: ../../development/add_protocols.rst:186
msgid "Some SPU MPC basic APIs"
msgstr ""

#: ../../development/add_protocols.rst:198
msgid ""
"Among the basic APIs, some protocols working on Rings share the same "
"logic on some operations processing public operands, so SPU developers "
"pre-implement these APIs as kernels and place them in the common "
"directory. As a result, the ABY3 developer can directly register these "
"kernels through the **regPV2kKernels** function."
msgstr ""

#: ../../development/add_protocols.rst:202
msgid "Pre-implemented *and_pp* kernel"
msgstr ""

#: ../../development/add_protocols.rst:224
msgid "Register *and_pp* kernel in regPV2kKernels function"
msgstr ""

#: ../../development/add_protocols.rst:235
msgid ""
"Besides, ABY3 protocol-specific operations need to be implemented by "
"developers as kernels to register. For example, the multiplication of two"
" arithmetic secret shares of ABY3 is implemented as the **MulAA** kernel "
"located in the `arithmetic.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/arithmetic.cc>`_"
" source file. When kernels are implemented and registered, a new protocol"
" is finally added."
msgstr ""

#: ../../development/add_protocols.rst:240
msgid "ABY3 *mul_aa* kernel for arithmetic share multiplication"
msgstr ""

#: ../../development/add_protocols.rst:258
msgid "Testing"
msgstr ""

#: ../../development/add_protocols.rst:259
msgid ""
"After a protocol is added, the developer usually wants to test whether "
"the protocol works as expected. There are two ways to test the protocol "
"functionality in SPU. The first way is to run python examples. SPU has "
"provided users with a series of application `examples "
"<https://github.com/secretflow/spu/tree/main/examples/python>`_. If a "
"protocol fully implements SPU's basic APIs, the developer can run these "
"high-level examples to verify whether the low-level protocol development "
"is correct."
msgstr ""

#: ../../development/add_protocols.rst:265
msgid ""
"The second way is to write and run unittest. Some protocols do not cover "
"all the basic APIs and cannot run examples, or developers only want to "
"test the functionalities of some specific MPC operations (such as "
"addition and multiplication). In these cases it is more practical to run "
"unittest. SPU developers have construct a general test frameworks in "
"`api_test.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/api_test.cc>`_ "
"and `ab_api_test.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/ab_api_test.cc>`_."
" Developers of new protocols need to instantiate these frameworks to test"
" their own protocol functionalities. Developers can refer to the "
"`protocol_test.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/protocol_test.cc>`_"
" file in the aby3 directory to learn how to write their own protocol test"
" files."
msgstr ""

#: ../../development/basic_concepts.rst:2
msgid "Basic concepts"
msgstr ""

#: ../../development/basic_concepts.rst:4
msgid ""
"SPU has quite a different programming model than CPU/GPU, this guide "
"introduces the basic concepts."
msgstr ""

#: ../../development/basic_concepts.rst:7
msgid "Machine model"
msgstr ""

#: ../../development/basic_concepts.rst:9
msgid ""
"In normal CPU model, we could treat the machine as an *arithmetic "
"blackbox*, which accepts user's *code* and *data*, runs the computation, "
"and returns result *data* to user. If we draw a picture to show the "
"relationship between user and machine, it's something like this."
msgstr ""

#: ../../development/basic_concepts.rst:13
msgid "user and CPU"
msgstr ""

#: ../../development/basic_concepts.rst:16
msgid ""
"In SPU, the first notable difference is that, *input* is not provided by "
"a single user, it's from **multiple parties**, and the *code* could be "
"provided by a separate party, finally, the output could be received by "
"another party. So **SPU is born to be used in a distributed context**. It"
" looks like:"
msgstr ""

#: ../../development/basic_concepts.rst:20
msgid "multi-user and SPU"
msgstr ""

#: ../../development/basic_concepts.rst:23
msgid ""
"If we take a closer look, SPU itself is not a physical machine, it is "
"hosted by multiple parties that don't trust on each other. For example, "
"in the following picture, we have three parties (red, blue and green) "
"that work together with some MPC protocols, and provide computation "
"service as a **virtual machine**."
msgstr ""

#: ../../development/basic_concepts.rst:27
msgid "inside SPU"
msgstr ""

#: ../../development/basic_concepts.rst:30
msgid ""
"So we have treated SPU as a (multi-party visualized) **secure arithmetic "
"blackbox**, which can evaluate computations securely."
msgstr ""

#: ../../development/basic_concepts.rst:33
msgid "Programming model"
msgstr ""

#: ../../development/basic_concepts.rst:35
msgid "With the above VM model, the next question is **how to program on it**?"
msgstr ""

#: ../../development/basic_concepts.rst:37
msgid ""
"Inside SPU, each physical node behaves differently for the same progress,"
" i.e. some nodes act as senders, while others act as receivers."
msgstr ""

#: ../../development/basic_concepts.rst:39
msgid ""
"But from the users' (of SPU) perspective, SPU behaves as one single VM. "
"One important responsibility of SPU compiler/runtime pipeline is to "
"translate **homogeneous** program to another for **heterogeneous** "
"runtime engines."
msgstr ""

#: ../../development/basic_concepts.rst:41
msgid ""
"For example, in the following computation graph, given `x`, `y`, we want "
"to compute `f(x, y)`, and the big circle represent a compute node which "
"can evaluate f."
msgstr ""

#: ../../development/basic_concepts.rst:45
msgid ""
"In SPU, a group of nodes work together to provide functionality of `f`, "
"as shown blow."
msgstr ""

#: ../../development/basic_concepts.rst:49
msgid "With the above abstraction, SPU can:"
msgstr ""

#: ../../development/basic_concepts.rst:51
msgid "Hide the underline protocols, *write once, run on all protocols*."
msgstr ""

#: ../../development/basic_concepts.rst:52
msgid ""
"Hide the number of parties, *write once, run for a variable number of "
"parties*."
msgstr ""

#: ../../development/basic_concepts.rst:56
msgid "API level"
msgstr ""

#: ../../development/basic_concepts.rst:58
msgid ""
"With the above programming model, the next question is **which language "
"is supported**? SPU provides multi-level API, from upper to lower:"
msgstr ""

#: ../../development/basic_concepts.rst:60
msgid ""
"**Frontend API** (like TensorFlow/JAX), SPU compiles them into SPU IR "
"before running."
msgstr ""

#: ../../development/basic_concepts.rst:61
msgid ""
"**SPU IR**, an Intermediate Representation format defined by SPU, which "
"is not quite readable but easier for computers to understand."
msgstr ""

#: ../../development/basic_concepts.rst:62
msgid "**C++ API**, which could directly access the underline MPC protocols."
msgstr ""

#: ../../development/basic_concepts.rst:64
msgid "The API hierarchy looks like:"
msgstr ""

#: ../../development/basic_concepts.rst:69
msgid "SPU API hierarchy"
msgstr ""

#: ../../development/basic_concepts.rst:72
msgid ""
"An important goal of SPU is to allow people to write secure programs with"
" their familiar frameworks they are familiar with, so it's recommended to"
" use Frontend API."
msgstr ""

#: ../../development/basic_concepts.rst:74
msgid ""
"Currently, only JAX frontend is supported for now. Please check :doc:`JAX"
" on SPU <../tutorials/quick_start>`."
msgstr ""

#: ../../development/compiler.rst:2
msgid "SPU Compiler"
msgstr ""

#: ../../development/compiler.rst:4
msgid ""
"The SPU compiler aims to provide first-party compiler support from the "
"different ML frameworks to SPU runtime."
msgstr ""

#: ../../development/compiler.rst:7
msgid ""
"`MLIR <https://mlir.llvm.org/>`_ The MLIR project is a novel approach to "
"building reusable and extensible compiler infrastructure. MLIR aims to "
"address software fragmentation, improve compilation for heterogeneous "
"hardware, significantly reduce the cost of building domain specific "
"compilers, and aid in connecting existing compilers together."
msgstr ""

#: ../../development/compiler.rst:9
msgid ""
"`XLA <https://www.tensorflow.org/xla/architecture>`_ Multiple Vendors use"
" XLA as the middle layer, mapping from platform frameworks like PyTorch, "
"JAX, and TensorFlow into XLA and then progressively lowering down to "
"their target hardware."
msgstr ""

#: ../../development/compiler.rst:11
msgid ""
"`MLIR-HLO <https://github.com/tensorflow/mlir-hlo>`_ MLIR-HLO project "
"connects XLA into MLIR world."
msgstr ""

#: ../../development/compiler.rst:13
msgid ""
"Having canonical lowerings from different frontend frameworks to the MLIR"
" ecosystem would provide much needed relief to hardware vendors to focus "
"on their unique value rather than implementing yet another frontend for "
"SPU. For current hardware vendors, they just need to add LLVM target "
"support instead of implementing separate Clang/C++ frontends. MLIR-HLO is"
" achieving similar goal."
msgstr ""

#: ../../development/compiler.rst:17
msgid "All the roads from ML frameworks to SPU"
msgstr ""

#: ../../development/design_device.rst:2
msgid "Design: generic device"
msgstr ""

#: ../../development/design_device.rst:5
msgid ""
"This is a design draft for using SPU from SecretFlow, not an accurate "
"document for SPU itself. It could be treated as a reference to integrate "
"SPU from other systems."
msgstr ""

#: ../../development/design_device.rst:8 ../../development/pipeline.rst:14
#: ../../development/type_system.rst:5
#: ../../development/visibility_inference_rule.rst:5
msgid "Overview"
msgstr ""

#: ../../development/design_device.rst:10
msgid ""
"This document discusses the design of a trust chain under an universal "
"device concept."
msgstr ""

#: ../../development/design_device.rst:13
msgid "Concept"
msgstr ""

#: ../../development/design_device.rst:15
msgid ""
"**Device**, a virtual concept which can evaluate a piece of code, "
"normally a specific device provides some specific abilities, i.e. CPU is "
"a device for general computation, GPU is a device for parallel "
"computation, HE/MPC evaluator are devices for security computation. "
"Formally, a device is a set of ops :math:`\\left \\{  OP_{i} \\right "
"\\}`."
msgstr ""

#: ../../development/design_device.rst:17
msgid ""
"*DeviceObject* an object which could be operated by the device, formally,"
" it's a set of data :math:`\\left \\{  D_{i} \\right \\}`."
msgstr ""

#: ../../development/design_device.rst:18
msgid ""
"*Consistency property* is `if type(Di) == type(Dj) and OP works for Di, "
"it also works for Dj`"
msgstr ""

#: ../../development/design_device.rst:19
msgid ""
"*Complete property* is that :math:`\\left \\{  OP_{i} \\right \\}` is "
"*turing complete*"
msgstr ""

#: ../../development/design_device.rst:21
msgid ""
"**Node**, a physical node which provides general computing environment, "
"it could host devices."
msgstr ""

#: ../../development/design_device.rst:23
msgid ""
"**Computation** or DAG, is a form to represent logic function, with "
"*node* as operator and *edge* as data."
msgstr ""

#: ../../development/design_device.rst:25
msgid ""
"**SecretFlow**, is a framework that could schedule a *Computation* to a "
"list of *Device*, with respect that:"
msgstr ""

#: ../../development/design_device.rst:27
msgid ""
"**Securely data transferred** across devices, unless the client "
"explicitly makes an unsafe transfer."
msgstr ""

#: ../../development/design_device.rst:28
msgid ""
"Each op runs on exactly on one device, **there is no cross-device "
"function**."
msgstr ""

#: ../../development/design_device.rst:32
msgid "Notations"
msgstr ""

#: ../../development/design_device.rst:38
msgid "*empty shape* stands for **Node**"
msgstr ""

#: ../../development/design_device.rst:39
msgid "*colored shape* stands for **Device**"
msgstr ""

#: ../../development/design_device.rst:40
msgid "*dotted line* stands for **no trust** relation between devices."
msgstr ""

#: ../../development/design_device.rst:41
msgid ""
"*dotted line with arrow* stands for **weak trust** relation, one device "
"could send its encrypted data to another without data loss."
msgstr ""

#: ../../development/design_device.rst:42
msgid ""
"*solid line with arrow* stands for **strong trust** relation, one device "
"could send its raw data to another without data loss."
msgstr ""

#: ../../development/design_device.rst:47
msgid "Device layout"
msgstr ""

#: ../../development/design_device.rst:50
msgid "Outsourcing (MPC)"
msgstr ""

#: ../../development/design_device.rst:54
msgid ""
"In above deployment, we use 6 nodes to construct 4 devices, where circle "
"devices have weak trust to the triangle device."
msgstr ""

#: ../../development/design_device.rst:57
msgid "Colocated (MPC)"
msgstr ""

#: ../../development/design_device.rst:61
msgid ""
"In above deployment, we use 3 nodes to construct 4 devices, where circle "
"devices have weak trust to the triangle device."
msgstr ""

#: ../../development/design_device.rst:63
msgid ""
"Note, in this configuration, we use 3 nodes to build exactly the same "
"device layout as the 6 node out-sourcing mode, the client code could run "
"exactly the same without any changes. That is **write once, run "
"anywhere**."
msgstr ""

#: ../../development/design_device.rst:66
msgid "Server-aided (MPC)"
msgstr ""

#: ../../development/design_device.rst:70
msgid ""
"In this configuration, one server does not provide data but participates "
"in the computation, it's so called a `server-aided`."
msgstr ""

#: ../../development/design_device.rst:73
msgid "HE device"
msgstr ""

#: ../../development/design_device.rst:77
msgid "In this mode, we use 2 nodes to virtualize 3 devices, with that:"
msgstr ""

#: ../../development/design_device.rst:79
msgid ""
"The *magenta device* colocated with *yellow CPU device*, with a *strong "
"trust* relationship."
msgstr ""

#: ../../development/design_device.rst:80
msgid ""
"The *red CPU device* and the *magenta HE device* forms a *weak trust* "
"relationship."
msgstr ""

#: ../../development/design_device.rst:84
msgid "In this configuration, we use 2 nodes to virtualize 4 devices, with that:"
msgstr ""

#: ../../development/design_device.rst:86
msgid ""
"each *circle device* has one *strong trust* with one *diamond device* "
"while a *weak trust* to another *diamond device*."
msgstr ""

#: ../../development/design_device.rst:90
msgid ""
"In this configuration, we have 3 nodes. For clarity, we name upper one as"
" Alice, lower-left as Bob, lower-right as Charlie."
msgstr ""

#: ../../development/design_device.rst:92
#, python-brace-format
msgid ""
"Both {Bob, Charlie} would encrypt their data and send it to Alice, we "
"have to do possible device abstractions."
msgstr ""

#: ../../development/design_device.rst:94
msgid ""
"In the middle, there is only one *HE device*, which could be used to "
"compute all cipher-texts."
msgstr ""

#: ../../development/design_device.rst:96
msgid ""
"pros: there is only one HE device per-node, which means if we have N "
"parties, we have at most N HE-devices."
msgstr ""

#: ../../development/design_device.rst:97
msgid ""
"cons: it breaks the *Consistency property*, i.e. `add::([x], [y])` add "
"two cipher-texts could not be done if two cipher-texts come from "
"different parties. Another example: when doing output, Bob may get a "
"cipher-text from the *HE-device*, but he can not decrypt it, since he "
"does not have the right key. @jint, IMHO, *Consistency* is the key-point "
"to guide programmers, **it's confusing if an op sometime work, sometimes "
"not**."
msgstr ""

#: ../../development/design_device.rst:99
msgid ""
"In the right configuration, there are 2 *HE device*, both reside on "
"Alice, but one for Bob and one for Charlie."
msgstr ""

#: ../../development/design_device.rst:101
msgid "pros: Consistency, the device concept is exactly the same as MPC/TEE."
msgstr ""

#: ../../development/design_device.rst:102
msgid ""
"cons: there will be at most :math:`N^2` HE devices for N nodes. This "
"might not be a problem since it depicts the 2PC property of HE (@jint)."
msgstr ""

#: ../../development/design_device.rst:106
msgid "Device and Node"
msgstr ""

#: ../../development/design_device.rst:108
msgid ""
"A device is composed by one or more nodes, this section covers the common"
" used device/node pattern in SecretFlow."
msgstr ""

#: ../../development/design_device.rst:110
msgid "For CPU and MPC, it's easy."
msgstr ""

#: ../../development/design_device.rst:112
msgid "A CPU device is composed by only one node."
msgstr ""

#: ../../development/design_device.rst:113
msgid "An MPC device is composed by a list of nodes (unordered)."
msgstr ""

#: ../../development/design_device.rst:115
msgid ""
"For HE device, it's a bit of complicated, it's composed by a pair of "
"nodes `(location, key-owner)`"
msgstr ""

#: ../../development/design_device.rst:117
msgid "**Location node** is the node that the evaluator located on."
msgstr ""

#: ../../development/design_device.rst:118
#, python-brace-format
msgid "**KeyOwner node** is the node that provides `{PK, SK}`"
msgstr ""

#: ../../development/design_device.rst:120
msgid "Formally, we can define devices via a configuration file."
msgstr ""

#: ../../development/design_device.rst:131
msgid "For example:"
msgstr ""

#: ../../development/design_device.rst:156
msgid "Let's ignore the SPU device for a moment, the CPU and HEU looks like this:"
msgstr ""

#: ../../development/design_device.rst:160
msgid ""
"In this example, `HEU` computation part is strait-forward, the non-"
"trivial part is the IO (device-to-device transfer). Let's consider "
"several IO cases."
msgstr ""

#: ../../development/design_device.rst:162
msgid ""
"First, transfer data from `P1` to `HEU`, in this case, from device "
"concept level, `P1` **strong trust** on `HEU`, so it can send plaintext "
"directly to `HEU`. In implementation, `P1` is colocated with `HEU`, so it"
" makes sense for a plaintext transfer."
msgstr ""

#: ../../development/design_device.rst:163
msgid ""
"Second, transfer data from `P2` to `HEU`, in device concept, `P2` **weak "
"trust** `HEU`, so it has to encrypt the data with SK, then sends it to "
"`HEU`. From implementation point of view, `P2` has the private key, so it"
" can do the encryption."
msgstr ""

#: ../../development/design_device.rst:164
msgid ""
"Third case, transfer data devices other than `P1` and `P2` to `HEU`, in "
"this case, it's neither colocated with `HEU` nor key-provider of `HEU`, "
"it's just a participant, which has a `weak trust` relationship with "
"`HEU`, and will request `PK` from the `HEU`."
msgstr ""

#: ../../development/design_device.rst:190
msgid "As said before, when the IO is ready, it's trivial to fire jobs on it."
msgstr ""

#: ../../development/design_device.rst:192
msgid ""
"For output, a notable part of `HEU` is that, it could only reveal the "
"result to the `key-owner` node. If you want to output to a node other "
"than `key-owner node`, you have to ask key-owner node for help. This "
"depicts the fact that HE is indeed a 2PC device, so more than 2PC cases "
"should be handled specially."
msgstr ""

#: ../../development/design_workflow.rst:2
msgid "Design: workflow"
msgstr ""

#: ../../development/design_workflow.rst:5
msgid ""
"This is an early stage design document, the concepts may not match the "
"implementation."
msgstr ""

#: ../../development/design_workflow.rst:8
msgid "Concepts"
msgstr ""

#: ../../development/design_workflow.rst:11
msgid "Components"
msgstr ""

#: ../../development/design_workflow.rst:13
msgid ""
"Before formal definition of SPU components, we define kinds of entities "
"first."
msgstr ""

#: ../../development/design_workflow.rst:15
msgid ""
"*Entity*: an entity is a lib/process/service which could be deployed to "
"provide some functionalities."
msgstr ""

#: ../../development/design_workflow.rst:16
msgid ""
"*Virtual entity*: a virtual entity is a group of entities which "
"cooperates to provide some functionalities."
msgstr ""

#: ../../development/design_workflow.rst:18
msgid "SPU component is an entity or virtual entity."
msgstr ""

#: ../../development/design_workflow.rst:20
msgid ""
"**Compiler**: is an entity which translates/optimizes a XLA DAG to a SPU "
"DAG."
msgstr ""

#: ../../development/design_workflow.rst:21
msgid ""
"**(Compute) Engine**: is an entity that cooperates with other engines to "
"do secure evaluation."
msgstr ""

#: ../../development/design_workflow.rst:22
msgid ""
"**Virtual Machine**: is a virtual entity which consists of a group of "
"engines, and can launch a SPU computation."
msgstr ""

#: ../../development/design_workflow.rst:23
msgid ""
"**Storage Engine**: is an entity which provides input data (data "
"provider) or receives output data (data sink)."
msgstr ""

#: ../../development/design_workflow.rst:24
msgid ""
"**Virtual Storage**: is a virtual entity which contains a group of "
"storage engines."
msgstr ""

#: ../../development/design_workflow.rst:25
msgid ""
"**Driver**: is an entity which drives all entities/virtual engines to "
"jointly complete a secure evaluation."
msgstr ""

#: ../../development/design_workflow.rst:28
msgid ""
"SPU components are typically hosted by several parties which do not trust"
" each other. We usually assign different roles to these parties."
msgstr ""

#: ../../development/design_workflow.rst:30
msgid "Kind of roles:"
msgstr ""

#: ../../development/design_workflow.rst:32
msgid "**Data provider**: which hosts storage engine."
msgstr ""

#: ../../development/design_workflow.rst:33
msgid "**Algorithm provider**: which provides the algorithm."
msgstr ""

#: ../../development/design_workflow.rst:34
msgid "**Computing provider**: which hosts one or more compute engines."
msgstr ""

#: ../../development/design_workflow.rst:36
msgid "Note, one party may have multiple roles, for example:"
msgstr ""

#: ../../development/design_workflow.rst:38
msgid "one party could provide data while also participate in the computation."
msgstr ""

#: ../../development/design_workflow.rst:39
msgid ""
"one party could host all compute engines and claim that engines do not "
"collude with each other, that is the 'out-sourcing mode'."
msgstr ""

#: ../../development/design_workflow.rst:42
msgid "Compare to classic architecture"
msgstr ""

#: ../../development/design_workflow.rst:44
msgid "comparison to classic architecture."
msgstr ""

#: ../../development/design_workflow.rst:48
msgid "SPU"
msgstr ""

#: ../../development/design_workflow.rst:49
msgid "Classic"
msgstr ""

#: ../../development/design_workflow.rst:50
msgid "Difference"
msgstr ""

#: ../../development/design_workflow.rst:51
msgid "SPU VM"
msgstr ""

#: ../../development/design_workflow.rst:52
msgid "CPU"
msgstr ""

#: ../../development/design_workflow.rst:53
msgid "SPU VM composed by multiple engines who follows MPC protocol"
msgstr ""

#: ../../development/design_workflow.rst:54
msgid "SPU VS"
msgstr ""

#: ../../development/design_workflow.rst:55
msgid "Disks"
msgstr ""

#: ../../development/design_workflow.rst:56
msgid "SPU storage composed by multiple participants who do not trust each other"
msgstr ""

#: ../../development/design_workflow.rst:57
#: ../../development/design_workflow.rst:228
msgid "Data infeed"
msgstr ""

#: ../../development/design_workflow.rst:58
msgid "Disk read"
msgstr ""

#: ../../development/design_workflow.rst:59
msgid "SPU data infeed will make data invisible to engines."
msgstr ""

#: ../../development/design_workflow.rst:60
#: ../../development/design_workflow.rst:309
msgid "Data outfeed"
msgstr ""

#: ../../development/design_workflow.rst:61
msgid "Disk write"
msgstr ""

#: ../../development/design_workflow.rst:62
msgid "SPU data output will reveal value from engines."
msgstr ""

#: ../../development/design_workflow.rst:66
msgid "Deployment"
msgstr ""

#: ../../development/design_workflow.rst:68
msgid "A SPU component can be deployed:"
msgstr ""

#: ../../development/design_workflow.rst:70
msgid "**As a lib**: used by other applications, (i.e. python runtime)"
msgstr ""

#: ../../development/design_workflow.rst:71
msgid "**As a binary**: that could be used as a standalone program."
msgstr ""

#: ../../development/design_workflow.rst:72
msgid "**As a service**: that could be called remotely."
msgstr ""

#: ../../development/design_workflow.rst:74
msgid "Component deployment method."
msgstr ""

#: ../../development/design_workflow.rst:78
msgid "Component"
msgstr ""

#: ../../development/design_workflow.rst:79
msgid "As a lib"
msgstr ""

#: ../../development/design_workflow.rst:80
msgid "As a binary"
msgstr ""

#: ../../development/design_workflow.rst:81
msgid "As a service"
msgstr ""

#: ../../development/design_workflow.rst:82
msgid "Compiler/C++"
msgstr ""

#: ../../development/design_workflow.rst:83
#: ../../development/design_workflow.rst:95
msgid "expose pybind"
msgstr ""

#: ../../development/design_workflow.rst:84
msgid "standalone compiler"
msgstr ""

#: ../../development/design_workflow.rst:85
msgid "close-source, focus on optimization"
msgstr ""

#: ../../development/design_workflow.rst:86
msgid "Engine/C++"
msgstr ""

#: ../../development/design_workflow.rst:87
#: ../../development/design_workflow.rst:88
#: ../../development/design_workflow.rst:91
#: ../../development/design_workflow.rst:92
#: ../../development/design_workflow.rst:96
#: ../../development/design_workflow.rst:97
msgid "N/A"
msgstr ""

#: ../../development/design_workflow.rst:89
#: ../../development/design_workflow.rst:93
msgid "standalone service program"
msgstr ""

#: ../../development/design_workflow.rst:90
msgid "Storage Engine/C++"
msgstr ""

#: ../../development/design_workflow.rst:94
msgid "Driver/python"
msgstr ""

#: ../../development/design_workflow.rst:100
msgid "Deployment unit."
msgstr ""

#: ../../development/design_workflow.rst:102
msgid ""
"**SPU Daemon**: is a program that serves *compute engine* or *storage "
"engine*"
msgstr ""

#: ../../development/design_workflow.rst:103
msgid "**SPU Compiler**: is a program that translates/optimizes XLA IR to SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:104
msgid "**driver**: is a lib which drives compile/data-placement/run pipeline."
msgstr ""

#: ../../development/design_workflow.rst:108
msgid "Workflow"
msgstr ""

#: ../../development/design_workflow.rst:110
msgid "The following diagram shows a typical control flow of SPU computation."
msgstr ""

#: ../../development/design_workflow.rst:115
msgid "The whole control flow is driven by the driver/controller."
msgstr ""

#: ../../development/design_workflow.rst:117
msgid "Ask ML framework to compile a model into XLA IR."
msgstr ""

#: ../../development/design_workflow.rst:118
msgid "Ask SPU Compiler to compile XLA IR into SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:119
msgid "Ask storage engines to infeed data to engine's symbol table."
msgstr ""

#: ../../development/design_workflow.rst:120
msgid "Ask compute engines to run SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:121
msgid "Ask storage engine to outfeed from engine's symbol table."
msgstr ""

#: ../../development/design_workflow.rst:126
msgid "Simple workflow"
msgstr ""

#: ../../development/design_workflow.rst:128
msgid "The following diagram shows detailed steps:"
msgstr ""

#: ../../development/design_workflow.rst:181
msgid ""
"**step 1**, driver writes a normal tensorflow program that could be "
"decorated with `tf.function`."
msgstr ""

#: ../../development/design_workflow.rst:182
msgid "**step 2-3** driver asks virtual storage to instantiate dataset."
msgstr ""

#: ../../development/design_workflow.rst:183
msgid ""
"**step 4-5** driver asks virtual storage to load next batch, get a "
"reference to remote tensor."
msgstr ""

#: ../../development/design_workflow.rst:184
msgid ""
"**step 6-7** driver asks tensorflow engine to compile the program into "
"XLA.HLO, with reference tensor."
msgstr ""

#: ../../development/design_workflow.rst:185
msgid "**step 8-9** driver asks SPU Compiler to compile the XLA.HLO into SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:186
msgid ""
"**step 10-13** driver asks virtual storage to infeed data into VM's "
"symbol table."
msgstr ""

#: ../../development/design_workflow.rst:187
msgid "**step 14-15** driver asks VM to run compiled SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:188
msgid ""
"**step 16-19** driver asks virtual storage to outfeed data from VM's "
"symbol table."
msgstr ""

#: ../../development/design_workflow.rst:190
msgid ""
"In the above steps, **step 4-5**, **step 10-19** are virtual steps, since"
" both virtual machine and virtual storage are *virtual object* that can "
"not be interacted directly."
msgstr ""

#: ../../development/design_workflow.rst:192
msgid ""
"The concrete steps is defined by the virtual machine and storage layout. "
"For example:"
msgstr ""

#: ../../development/design_workflow.rst:194
msgid ""
"suppose we have 2 data sources *Alice* and *Bob*, where *Alice* also acts"
" as a data sink."
msgstr ""

#: ../../development/design_workflow.rst:195
msgid "suppose we have 3 compute engines, which compose a 3-PC virtual machine."
msgstr ""

#: ../../development/design_workflow.rst:196
msgid ""
"suppose input `x` comes from *Alice*, `y` comes from *Bob*, and the "
"output `z` is revealed to *Alice*."
msgstr ""

#: ../../development/design_workflow.rst:199
msgid "Data load"
msgstr ""

#: ../../development/design_workflow.rst:223
msgid "**step 1-2** *Alice* loads symbol 'x' into it's local symbol table."
msgstr ""

#: ../../development/design_workflow.rst:224
msgid "**step 3-4** *Bob* loads symbol 'y' into it's local symbol table."
msgstr ""

#: ../../development/design_workflow.rst:230
msgid "The above **step 9-12** does data infeed, the concrete steps look like:"
msgstr ""

#: ../../development/design_workflow.rst:269
msgid ""
"**step 1-5** and **step 6-10** ask *Alice* and *Bob* to do infeed "
"simultaneously, and could be done in parallel."
msgstr ""

#: ../../development/design_workflow.rst:270
msgid ""
"**step 2**, *Alice* splits `x` into shares `(x1, x2, x3)`, note: this "
"progress is mpc-protocol dependent."
msgstr ""

#: ../../development/design_workflow.rst:271
msgid ""
"**step 3-5**, *Alice* sends slices of `xi` to each of the engines, could "
"be done in parallel."
msgstr ""

#: ../../development/design_workflow.rst:272
msgid "**step 6-10**, *Bob* does the same thing as *Alice*."
msgstr ""

#: ../../development/design_workflow.rst:276
msgid "Run"
msgstr ""

#: ../../development/design_workflow.rst:304
msgid ""
"**step 1-2**, driver asks Engine-0 to run the compiled program, note, the"
" input data is feed at this time."
msgstr ""

#: ../../development/design_workflow.rst:305
msgid "**step 3-4, 5-6** driver asks Engine-1 & 2 to do the same thing."
msgstr ""

#: ../../development/design_workflow.rst:311
msgid ""
"Note in this example, *Alice* also acts as the data sink, the output is "
"revealed to *Alice*."
msgstr ""

#: ../../development/design_workflow.rst:338
msgid ""
"**step 2-7** *Alice* gathers sharings of `z` from engines, note: this "
"progress is mpc-protocol dependent."
msgstr ""

#: ../../development/design_workflow.rst:339
msgid "**step 8** *Alice* reconstructs the result locally."
msgstr ""

#: ../../development/design_workflow.rst:343
msgid "Full workflow"
msgstr ""

#: ../../development/design_workflow.rst:345
msgid "The following diagram shows workflow with local VS local processing."
msgstr ""

#: ../../development/design_workflow.rst:405
msgid ""
"In the above picture, we can do local computation on *VS* side, which "
"makes it suitable for FL like application."
msgstr ""

#: ../../development/fxp.ipynb:9
msgid "Pitfalls - Fxp Arithmetic"
msgstr ""

#: ../../development/fxp.ipynb:11
msgid ""
"We have confirmed the precision issues or input limitations with the "
"following ops."
msgstr ""

#: ../../development/fxp.ipynb:13
msgid "We will update this part promptly."
msgstr ""

#: ../../development/fxp.ipynb:25
msgid "Simulation"
msgstr ""

#: ../../development/fxp.ipynb:27
msgid ""
"We will use SPU **simulation** tool to simulate multi-parties with "
"threads."
msgstr ""

#: ../../development/fxp.ipynb:57
msgid "Default Runtime Config Parameters"
msgstr ""

#: ../../development/fxp.ipynb:59
msgid ""
"We will use the following common settings in SPU Runtime config. Other "
"parameters may be modified however."
msgstr ""

#: ../../development/fxp.ipynb:83
msgid "Unary Operator"
msgstr ""

#: ../../development/fxp.ipynb:95
msgid "Reciprocal"
msgstr ""

#: ../../development/fxp.ipynb:97
msgid ""
"SPU uses Goldschmidt's method to calculate Reciprocal. Please refer to "
"`Secure Computation With Fixed-Point Numbers "
"<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.1305&rep=rep1&type=pdf>`__"
" for details."
msgstr ""

#: ../../development/fxp.ipynb:99
msgid ""
"Reciprocal is only correct if input belongs to **(-2**fxp_fraction_bits, "
"2**fxp_fraction_bits)**."
msgstr ""

#: ../../development/fxp.ipynb:101
msgid "First, let's have a look at the figure."
msgstr ""

#: ../../development/fxp.ipynb:191
msgid "Actually the precision is quite high."
msgstr ""

#: ../../development/fxp.ipynb:220
msgid ""
"Let's have an idea about what happens if input is not within the valid "
"range."
msgstr ""

#: ../../development/fxp.ipynb:282
msgid "Natural Logarithm"
msgstr ""

#: ../../development/fxp.ipynb:284
msgid ""
"SPU uses Pade approximation by default. Please check `Benchmarking "
"Privacy Preserving Scientific Operations "
"<https://www.esat.kuleuven.be/cosic/publications/article-3013.pdf>`__ for"
" details."
msgstr ""

#: ../../development/fxp.ipynb:286
msgid ""
"Logarithm is only correct if input belongs to **(0, "
"2**fxp_fraction_bits)**."
msgstr ""

#: ../../development/fxp.ipynb:288
msgid "**NOTE:** Similar conclusion also applies to **log1p**, **log2**."
msgstr ""

#: ../../development/fxp.ipynb:344
msgid "Again, let's see what happens if input is out of valid range."
msgstr ""

#: ../../development/fxp.ipynb:387
msgid "Another Choice: Newton Approximation"
msgstr ""

#: ../../development/fxp.ipynb:389
msgid ""
"If you would like to compute faster, you may switch to Newton "
"Approximation. But the precision is lower and valid input range is around"
" **(0, 250)**."
msgstr ""

#: ../../development/fxp.ipynb:436
msgid "While, if out of valid input..."
msgstr ""

#: ../../development/fxp.ipynb:475
msgid "Natural Exponential"
msgstr ""

#: ../../development/fxp.ipynb:477
msgid ""
"The current implementation is based on Taylor approximation. The valid "
"input range is around **(0, 10)**."
msgstr ""

#: ../../development/fxp.ipynb:479
msgid "**NOTE:** Similar conclusion also applies to **exp2**."
msgstr ""

#: ../../development/fxp.ipynb:525
msgid "If input not in valid range, then..."
msgstr ""

#: ../../development/fxp.ipynb:564
msgid "Another Choice: Pade Approximation"
msgstr ""

#: ../../development/fxp.ipynb:566
msgid ""
"SPU also implements Pade Approximation which has a larger valid input "
"range - **(0, 20)** but with slower computation speed."
msgstr ""

#: ../../development/fxp.ipynb:613
msgid "Let's check if input is larger than 20:"
msgstr ""

#: ../../development/fxp.ipynb:652
msgid "Hyperbolic Tangent"
msgstr ""

#: ../../development/fxp.ipynb:654
#, python-format
msgid ""
"SPU uses Pade Approximation for implementation. The parameters refer to "
"`Wolfram "
"<https://www.wolframalpha.com/input?i=Pade+approximation+tanh%28x%29+order+5%2C5>`__."
" The valid input range is about **(-5,5)**."
msgstr ""

#: ../../development/fxp.ipynb:701
msgid "Binary Operator"
msgstr ""

#: ../../development/fxp.ipynb:704
msgid "Div"
msgstr ""

#: ../../development/fxp.ipynb:706
msgid ""
"SPU uses Goldschmidt's method to calculate division. Please refer to "
"`Secure Computation With Fixed-Point Numbers "
"<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.1305&rep=rep1&type=pdf>`__"
" for details."
msgstr ""

#: ../../development/fxp.ipynb:708
msgid ""
"So we have a similar valid input range to **b**, which is "
"**(-2**fxp_fraction_bits, 2**fxp_fraction_bits)**. Please check details "
"at **reciprocal** part."
msgstr ""

#: ../../development/fxp.ipynb:719
msgid "Besides, We do find some subtle pitfalls in real applications:"
msgstr ""

#: ../../development/fxp.ipynb:721
msgid "Overflow when numerator is large."
msgstr ""

#: ../../development/fxp.ipynb:723
msgid "Some gap between numpy output."
msgstr ""

#: ../../development/fxp.ipynb:725
msgid "**Rule of thumb**"
msgstr ""

#: ../../development/fxp.ipynb:727
msgid ""
"We recommend users to try some actions if you come across \"strange\" "
"outputs:"
msgstr ""

#: ../../development/fxp.ipynb:729
msgid "If **huge error** occurs(maybe even **opposite sign**):"
msgstr ""

#: ../../development/fxp.ipynb:731
msgid "It's common that numerator is **too large**, which leads to overflow."
msgstr ""

#: ../../development/fxp.ipynb:732
msgid ""
"Try **Larger** field(``FM128``) first. Larger field can accommodate "
"larger number when fxp is fixed, so overflow can be avoided. But it will "
"drag down the efficiency of **nearly all op** dramatically."
msgstr ""

#: ../../development/fxp.ipynb:734
msgid ""
"Else, if the gap is not very significant, you can try to modify another "
"two parameters:"
msgstr ""

#: ../../development/fxp.ipynb:736
msgid ""
"Enlarging ``fxp_fraction_bits``: it is an essential parameters for fixed-"
"point arithmetic and will influence all the op associated with float-"
"point. For fixed field, larger fxp can support more bits for fraction "
"part which may give more precision. However, larger fxp will occupy the "
"bits for integer part, and makes **overflow** easier."
msgstr ""

#: ../../development/fxp.ipynb:738
msgid ""
"Enlarging ``fxp_div_goldschmidt_iters``: the precision of Goldschmidt's "
"method depends on iter numbers. So if you eager to more precise output, "
"you can enlarge this parameter. But it's worthy to note that:"
msgstr ""

#: ../../development/fxp.ipynb:740
msgid ""
"Larger this parameter, larger the cost of ``Div`` and all op containing "
"it(like ``Log`` and ``Tanh``)."
msgstr ""

#: ../../development/fxp.ipynb:741
msgid ""
"The final precision is also influenced by field, fxp and even method for "
"truncation. We only recommend to adjust this when you really care about "
"the **high precision**\\ (low absolute error) and other methods not work."
msgstr ""

#: ../../development/fxp.ipynb:803
#, python-brace-format
msgid ""
"When numerator is very large(:math:`>2^{28}` for ``FM64`` and "
"``fxp=18``), then the integer part may overflow under large probability, "
"and this brings huge error."
msgstr ""

#: ../../development/fxp.ipynb:873
msgid ""
"In this situation, **enlarging** field to ``FM128`` may be the only "
"remedy."
msgstr ""

#: ../../development/fxp.ipynb:943
msgid "Now, we try larger fxp."
msgstr ""

#: ../../development/fxp.ipynb:1012
msgid ""
"As we have mentioned at **reciprocal** part, SPU implements reciprocal "
"with Goldschmidt's method, so the final precision depends heavily on the "
"**iter numbers**."
msgstr ""

#: ../../development/fxp.ipynb:1014
msgid ""
"We first go through the algorithm quickly. let :math:`r_i` denote the "
"approximation of reciprocal, :math:`e_i` be the relative error, then in "
"one iter:"
msgstr ""

#: ../../development/fxp.ipynb:1016
#, python-brace-format
msgid ""
"r_i = r_{i-1}(1+e_i) \\\\\n"
"   e_{i+1} = e_i^2"
msgstr ""

#: ../../development/fxp.ipynb:1021
msgid "It's easy to prove that:"
msgstr ""

#: ../../development/fxp.ipynb:1023
msgid ""
"To compute ``Div(a, b)``, if we need :math:`|\\frac{a}{b} - r_i| \\le "
"2^{-l}`, then :math:`\\lceil {log(\\frac{l +log(a)}{\\tau})} \\rceil` "
"iterations should be done(we assume :math:`|\\frac{1}{b} - r_0| \\le "
"2^{-\\tau}`).In current implementation, we choose polynomial of degree 1 "
"as the initial guess of reciprocal, which leads to :math:`\\tau \\approx "
"3.5`."
msgstr ""

#: ../../development/fxp.ipynb:1025
#, python-brace-format
msgid "The relative error :math:`e_i = e_0^{2^i}`\\ (same as ``Div(a,b)``)."
msgstr ""

#: ../../development/fxp.ipynb:1027
msgid ""
"Although some other factors like fxp and truncation will also bring into "
"some errors, the above error analysis can still give readers some "
"recommendations when deciding ``fxp_div_goldschmidt_iters``."
msgstr ""

#: ../../development/index.rst:8
msgid "Pipeline"
msgstr ""

#: ../../development/index.rst:8
msgid "Compiler"
msgstr ""

#: ../../development/index.rst:8
msgid "Runtime"
msgstr ""

#: ../../development/index.rst:8
msgid "Design of SPU"
msgstr ""

#: ../../development/index.rst:18
msgid "Advanced Topics"
msgstr ""

#: ../../development/index.rst:26
msgid "Extending SPU"
msgstr ""

#: ../../development/index.rst:4
msgid "Development"
msgstr ""

#: ../../development/index.rst:6
msgid "This part contains design principles of SPU."
msgstr ""

#: ../../development/ir_dump.rst:2
msgid "Dump IR to DAG"
msgstr ""

#: ../../development/ir_dump.rst:5
msgid ""
"The configuration for dump IR to DAG maybe unstable. Please refer to the "
":spu_code_host:`spu.proto <spu/blob/main/libspu/spu.proto>` for latest "
"configurations."
msgstr ""

#: ../../development/ir_dump.rst:9
msgid ""
"This document provides the demo for how to dump the IR (Intermediate "
"Representation, generated by `XLA "
"<https://www.tensorflow.org/xla/architecture>`_) to a DAG. With the aid "
"of visualized DAG, the execution logic and required operators will be "
"more explicit."
msgstr ""

#: ../../development/ir_dump.rst:14
msgid ""
"Please refer to :ref:`/development/compiler.rst` for description of the "
"role of XLA in SPU."
msgstr ""

#: ../../development/ir_dump.rst:18
msgid "TL;DR"
msgstr ""

#: ../../development/ir_dump.rst:19
msgid ""
"In case you just want to have a try on obtaining the DAG for executed "
"code, we provide a :spu_code_host:`demo "
"<spu/blob/main/examples/python/ir_dump/ir_dump.py>` that demonstrates the"
" required code modifications to enable dumping the IR of executed code to"
" a custom path."
msgstr ""

#: ../../development/ir_dump.rst:21
msgid ""
"For those users who have designated requirements (e.g., dump to txt, dot,"
" html), we recommend to read the following detailed step-by-step "
"elaborations."
msgstr ""

#: ../../development/ir_dump.rst:25
msgid "Configuration"
msgstr ""

#: ../../development/ir_dump.rst:26
msgid ""
"Please first have a look at the :spu_code_host:`spu.proto "
"<spu/blob/main/libspu/spu.proto>` for SPU. To dump the IR, we should "
"modify the compiler options, which is shown in the following code "
"snippet."
msgstr ""

#: ../../development/ir_dump.rst:28
msgid "Compiler Options"
msgstr ""

#: ../../development/ir_dump.rst:59
msgid "The part of the above code related to dumping IR to DAG is as follows."
msgstr ""

#: ../../development/ir_dump.rst:61
msgid "Configurations related to dump IR"
msgstr ""

#: ../../development/ir_dump.rst:69
msgid ""
"In general, we require to focus on three variables to control the dump "
"behavior."
msgstr ""

#: ../../development/ir_dump.rst:71
msgid ""
"**enable_pretty_print** is a *bool* value, which denotes whether to dump "
"the IR or not."
msgstr ""

#: ../../development/ir_dump.rst:72
msgid ""
"**pretty_print_dump_dir** is a *string* value, which denotes the dump "
"path (should be a directory)."
msgstr ""

#: ../../development/ir_dump.rst:73
msgid ""
"**xla_pp_kind** is a *int* value, of which the range is [0, 1, 2], with "
"each one representing one dump format. To date, we support three kinds of"
" formats: TEXT, DOT and HTML. If you want to obtain the DAG, you should "
"use DOT or HTML."
msgstr ""

#: ../../development/ir_dump.rst:76
msgid ""
"For **DOT** files, you should use `GraphViz <https://graphviz.org/>`_ to "
"convert them to PDF or PNG to visualize the DAG."
msgstr ""

#: ../../development/ir_dump.rst:78
msgid ""
"While for **HTML** files, you can directly open the them in your Web "
"Browser, which shall render the DAG."
msgstr ""

#: ../../development/ir_dump.rst:80
msgid "XLA Pretty Print Kind"
msgstr ""

#: ../../development/ir_dump.rst:91
msgid "Pass custom compiler options"
msgstr ""

#: ../../development/ir_dump.rst:92
msgid ""
"We hereby describe how to manually pass the custom compiler options to "
"dump the IR of executed code."
msgstr ""

#: ../../development/ir_dump.rst:94
msgid ""
"First of all, we declare an CompilerOptions object. Note that the "
"**pretty_print_dump_dir** is better to be an absolute path."
msgstr ""

#: ../../development/ir_dump.rst:96
msgid "Declare CompilerOptions object"
msgstr ""

#: ../../development/ir_dump.rst:105
msgid "Then we pass the CompilerOptions to the executed SPU code."
msgstr ""

#: ../../development/ir_dump.rst:108
msgid "The code shall be modified from"
msgstr ""

#: ../../development/ir_dump.rst:110
msgid "SPU execution without customized compiler options"
msgstr ""

#: ../../development/ir_dump.rst:115
msgid "to"
msgstr ""

#: ../../development/ir_dump.rst:117
msgid "SPU execution with customized compiler options"
msgstr ""

#: ../../development/ir_dump.rst:123
msgid ""
"Here, `func` is a Python function. Please refer to the "
":spu_code_host:`demo <spu/blob/main/examples/python/ir_dump/ir_dump.py>` "
"for the context."
msgstr ""

#: ../../development/ir_dump.rst:125
msgid ""
"In the end, you can just run the target code and the output (e.g., DOT) "
"can be found in **your custom path**."
msgstr ""

#: ../../development/ir_dump.rst:128
msgid "Example"
msgstr ""

#: ../../development/ir_dump.rst:129
msgid ""
"We here provide the code snippet for dumping IR to HTML files. The DAG "
"for the executed function is illustrated in the end."
msgstr ""

#: ../../development/ir_dump.rst:131
msgid "Code snippet for dumping the IR of func"
msgstr ""

#: ../../development/ir_dump.rst:165
msgid ""
"You may find multiple files in the output directory since XLA has "
"multiple compile passes and generates multiple IRs, with each "
"corresponding to one DAG."
msgstr ""

#: ../../development/ir_dump.rst:168
msgid "The **HTML** output is rendered as follows."
msgstr ""

#: ../../development/ir_dump.rst:173
msgid "DAG for executed demo function"
msgstr ""

#: ../../development/pipeline.rst:2
msgid "SPU Pipeline"
msgstr ""

#: ../../development/pipeline.rst:4
msgid ""
"Recall that SPU could be treated as a :ref:`virtual device "
"<development/basic_concepts:Machine model>`. When working with a (virtual"
" or physical) device, we need several steps."
msgstr ""

#: ../../development/pipeline.rst:6
msgid "infeed code to it"
msgstr ""

#: ../../development/pipeline.rst:7
msgid "infeed data to it"
msgstr ""

#: ../../development/pipeline.rst:8
msgid "trigger it to run"
msgstr ""

#: ../../development/pipeline.rst:9
msgid "get result from it"
msgstr ""

#: ../../development/pipeline.rst:11
msgid "This page describes details of each step."
msgstr ""

#: ../../development/pipeline.rst:16
msgid ""
"Before diving into the details, let's first take a closer look of SPU "
"pipeline, it's something like this:"
msgstr ""

#: ../../development/pipeline.rst:21
msgid "code and data pipeline"
msgstr ""

#: ../../development/pipeline.rst:24
msgid "Compilation"
msgstr ""

#: ../../development/pipeline.rst:26
msgid "The vertical part depicts the compilation pipeline, from top to bottom."
msgstr ""

#: ../../development/pipeline.rst:28
msgid "Programmer writes code in AI frameworks(like TensorFlow/JAX)."
msgstr ""

#: ../../development/pipeline.rst:29
msgid "AI frontend traces the DAG, and emits as XLA IR."
msgstr ""

#: ../../development/pipeline.rst:30
msgid ""
"SPU compiler takes XLA IR, and compiles it to SPU IR, the format that SPU"
" runtime understands."
msgstr ""

#: ../../development/pipeline.rst:32
msgid "For more details, please see :doc:`compiler` for details."
msgstr ""

#: ../../development/pipeline.rst:35
msgid "Data pipeline"
msgstr ""

#: ../../development/pipeline.rst:37
msgid "The horizontal part depicts the data pipeline, from left to right."
msgstr ""

#: ../../development/pipeline.rst:39
msgid ""
"Data providers use :ref:`SPU io <reference/py_api:Runtime IO>` module to "
"encrypt input data."
msgstr ""

#: ../../development/pipeline.rst:41
msgid "For SPU MPC backend, *encrypt* means to split plaintext data into shares."
msgstr ""

#: ../../development/pipeline.rst:42
msgid "For floating-point data, encoding to fixed-point may be also required."
msgstr ""

#: ../../development/pipeline.rst:44
msgid ""
"The encrypted data is sent to :ref:`SPU runtime <reference/py_api:Runtime"
" Setup>`."
msgstr ""

#: ../../development/pipeline.rst:45
msgid ""
"The output data is fetched by *result owner*, and decrypted by the "
":ref:`SPU io <reference/py_api:Runtime IO>` module."
msgstr ""

#: ../../development/pipeline.rst:49
msgid "Just in time"
msgstr ""

#: ../../development/pipeline.rst:51
msgid ""
"JIT is short for `Just-in-time compilation <https://en.wikipedia.org/wiki"
"/Just-in-time_compilation>`_, with this approach, the compiler can get "
"more information, such as input shapes, than in `AOT mode "
"<https://en.wikipedia.org/wiki/Ahead-of-time_compilation>`_. JIT may "
"introduce more evaluation overhead, but it's really trivial in secure "
"computation setting."
msgstr ""

#: ../../development/pipeline.rst:53
msgid ""
"In SPU, JIT has more benefits since the backend engine may be orders of "
"magnitude faster if it knows the *visibility* of data. For example, when "
"multiplying two secrets, the backend MPC engine may involve expensive "
"*beaver triple* progress, but when one of the inputs (of multiply) is "
"public known to all parties, the operation will be much faster. So we "
"should *mark* as much data as possible to be *public* (if it doesn't need"
" to be protected), and tell the compiler these information."
msgstr ""

#: ../../development/pipeline.rst:55
msgid ""
"So, SPU compilation normally happens after all data infeed is done, and "
"`just in time` before the real evaluation."
msgstr ""

#: ../../development/policy_sgd_insight.rst:2
msgid "Background: SGD in MPC-ML"
msgstr ""

#: ../../development/policy_sgd_insight.rst:4
msgid ""
"SGD(Stochastic Gradient Descent) is a famous optimization algorithm, it "
"updates weights using gradient direction. However, it suffers that user "
"should choose hyper-parameters very carefully. Of course, grid-search is "
"a potential treatment for this problem, but it becomes impractical when "
"training cost is large. As an example, When running LR with SGD in "
"`credit card dataset <https://www.kaggle.com/datasets/uciml/default-of-"
"credit-card-clients-dataset>`_ (for 4096-0.1, 4096 is batch_size, 0.1 is "
"learning_rate), we can find that it seems safer to use small batch_size "
"and learning_rate, else we get some loss or very strong vibration of auc "
"within 10 epochs(we leave 10000 samples as test dataset randomly)."
msgstr ""

#: ../../development/policy_sgd_insight.rst:12
msgid ""
"Unfortunately, when under MPC, even simple algorithm like SSLR, small "
"batch_size leads to huge training time under limited network resources. "
"Besides, even you have high bandwidth, small batch_size can not utilize "
"it!"
msgstr ""

#: ../../development/policy_sgd_insight.rst:16
msgid "How to improve SGD"
msgstr ""

#: ../../development/policy_sgd_insight.rst:17
msgid ""
"Indeed, after our elaborated experiments, we can find two drawbacks of "
"naive SGD:"
msgstr ""

#: ../../development/policy_sgd_insight.rst:19
msgid "slow update(because of small learning_rate) at the beginning."
msgstr ""

#: ../../development/policy_sgd_insight.rst:21
msgid "vibration happens when near to optimal point."
msgstr ""

#: ../../development/policy_sgd_insight.rst:23
msgid ""
"So, it's a straight strategy to use \"large\" learning_rate at the "
"beginning, and \"slow down\" as training goes on. But the ensuing "
"question is how to determine specific \"large\" and \"slow down\" for "
"different datasets."
msgstr ""

#: ../../development/policy_sgd_insight.rst:27
msgid "What's Policy sgd"
msgstr ""

#: ../../development/policy_sgd_insight.rst:28
msgid ""
"For SSLR, we provide an answer to the above question: policy-sgd(already "
"implemented on `SSRegression` in Secretflow when setting "
"`strategy=policy_sgd`)."
msgstr ""

#: ../../development/policy_sgd_insight.rst:33
msgid "The core of this optimizer consists of two parts:"
msgstr ""

#: ../../development/policy_sgd_insight.rst:35
#, python-brace-format
msgid ""
"1. Adaptive learning rate scaling mechanism: in first epoch, we force the"
" weight move unit-norm in gradient direction and record "
":math:`\\frac{1}{||grad||_2}` as scale factor for this batch."
msgstr ""

#: ../../development/policy_sgd_insight.rst:38
msgid ""
"2. Learning rate decay and early stop: we use step-decay strategy for "
"learning_rate decay. As for early stop, we compare two strategies, loss "
"based(use Taylor expansion to avoid invoking time-consuming op like "
"`exp`, `log`) and weight based, and choose the latter in our final "
"implementation."
msgstr ""

#: ../../development/policy_sgd_insight.rst:44
msgid "Experiments"
msgstr ""

#: ../../development/policy_sgd_insight.rst:45
#, python-brace-format
msgid ""
"We use 4 dataset for experiments, containing 3 open source dataset "
"(`credit_card <https://www.kaggle.com/datasets/uciml/default-of-credit-"
"card-clients-dataset>`_, `Bank Marketing "
"<https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#>`_, `Aps "
"<https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks>`_)"
" and 1 business dataset(wzdata). For open source dataset, we just do some"
" basic one-hot and min-max normalization like normal LR needs. We leave "
"out about :math:`\\frac{1}{3}` data for test data and evaluate auc on it."
" The baseline auc is computed when using sklearn for model training."
msgstr ""

#: ../../development/policy_sgd_insight.rst:53
#: ../../development/policy_sgd_insight.rst:107
msgid "Dataset"
msgstr ""

#: ../../development/policy_sgd_insight.rst:53
msgid "Training shape"
msgstr ""

#: ../../development/policy_sgd_insight.rst:53
msgid "baseline auc"
msgstr ""

#: ../../development/policy_sgd_insight.rst:55
#: ../../development/policy_sgd_insight.rst:109
msgid "business dataset"
msgstr ""

#: ../../development/policy_sgd_insight.rst:55
msgid "111618，23"
msgstr ""

#: ../../development/policy_sgd_insight.rst:55
msgid "0.8175"
msgstr ""

#: ../../development/policy_sgd_insight.rst:57
#: ../../development/policy_sgd_insight.rst:111
msgid "Bank Marketing"
msgstr ""

#: ../../development/policy_sgd_insight.rst:57
msgid "40787，48"
msgstr ""

#: ../../development/policy_sgd_insight.rst:57
msgid "0.93"
msgstr ""

#: ../../development/policy_sgd_insight.rst:59
#: ../../development/policy_sgd_insight.rst:113
msgid "credit_card"
msgstr ""

#: ../../development/policy_sgd_insight.rst:59
msgid "20000, 23"
msgstr ""

#: ../../development/policy_sgd_insight.rst:59
msgid "0.718"
msgstr ""

#: ../../development/policy_sgd_insight.rst:61
#: ../../development/policy_sgd_insight.rst:115
msgid "Aps"
msgstr ""

#: ../../development/policy_sgd_insight.rst:61
msgid "60000，170"
msgstr ""

#: ../../development/policy_sgd_insight.rst:61
msgid "0.9666"
msgstr ""

#: ../../development/policy_sgd_insight.rst:65
msgid "Precision"
msgstr ""

#: ../../development/policy_sgd_insight.rst:67
msgid ""
"We first test how precision of fixed point influence SSLR and test three "
"settings:"
msgstr ""

#: ../../development/policy_sgd_insight.rst:69
msgid "low precision: `FM64` + 18 fxp"
msgstr ""

#: ../../development/policy_sgd_insight.rst:71
msgid "medium precision: `FM128` + 28 fxp"
msgstr ""

#: ../../development/policy_sgd_insight.rst:73
msgid "high precision: `FM128` + 42 fxp"
msgstr ""

#: ../../development/policy_sgd_insight.rst:81
msgid ""
"We can find that for both optimizer, precision has little influence on "
"final auc, so it's safe for user to choose low precision when training "
"LR."
msgstr ""

#: ../../development/policy_sgd_insight.rst:85
msgid "Naive v.s Policy"
msgstr ""

#: ../../development/policy_sgd_insight.rst:87
msgid ""
"Then, we compare the totally runtime of naive_sgd(v1) and policy_sgd(v2)."
" For naive-sgd, we follow the \"safe strategy\"(mostly used in plaintext "
"ML): small learning_rate like 0.1, and small batch_size like 1024(If "
"using 2048, then some data does not converge). Also, it's hard to decide "
"a good default value for naive_sgd to early stop well(even worse, you may"
" get huge auc drop if setting bad values). To avoid tedious grid-search, "
"so for naive_sgd, it runs without any learning_rate decay(recommended way"
" for naive_sgd). But for policy_sgd, it's often harmless to use larger "
"batch_size(2048 for these experiments),and we set learning_rate decay a "
"half every 2 epochs."
msgstr ""

#: ../../development/policy_sgd_insight.rst:93
msgid ""
"As for other hyper-parameters, we set total running epochs to 20, "
"learning_rate to 0.1 and use low precision, CHEETAH protocol. And we test"
" in WAN, providing 20Mbps and 20ms RTT, which is a typical setting in "
"real world project."
msgstr ""

#: ../../development/policy_sgd_insight.rst:99
msgid ""
"First, we find for naive_sgd(v1), none of them meets any early stop "
"criterion during 20 epochs(so we omit the early stop line in figure). "
"However, for policy_sgd(v2), it can always \"stop well\"(red dot line "
"means policy_sgd meets the stop criterion based on loss, similar for "
"purple line) after the model converges. Besides, checking the auc of "
"stopping time, it has very low gap(<0.01) between baseline."
msgstr ""

#: ../../development/policy_sgd_insight.rst:103
msgid ""
"The following table shows the total running time of policy_sgd and "
"naive_sgd(based on weight early stop). Policy_sgd can reduce the time by "
"2-5 times compared to naive_sgd."
msgstr ""

#: ../../development/policy_sgd_insight.rst:107
msgid "naive_sgd(s)"
msgstr ""

#: ../../development/policy_sgd_insight.rst:107
msgid "policy_sgd(s)"
msgstr ""

#: ../../development/policy_sgd_insight.rst:107
msgid "naive/policy"
msgstr ""

#: ../../development/policy_sgd_insight.rst:109
msgid "~8000"
msgstr ""

#: ../../development/policy_sgd_insight.rst:109
#: ../../development/policy_sgd_insight.rst:113
msgid "~1600"
msgstr ""

#: ../../development/policy_sgd_insight.rst:109
msgid "5x"
msgstr ""

#: ../../development/policy_sgd_insight.rst:111
msgid "~3000"
msgstr ""

#: ../../development/policy_sgd_insight.rst:111
msgid "~800"
msgstr ""

#: ../../development/policy_sgd_insight.rst:111
msgid "3.75x"
msgstr ""

#: ../../development/policy_sgd_insight.rst:113
msgid "~350"
msgstr ""

#: ../../development/policy_sgd_insight.rst:113
msgid "4.57x"
msgstr ""

#: ../../development/policy_sgd_insight.rst:115
msgid "~10000"
msgstr ""

#: ../../development/policy_sgd_insight.rst:115
msgid "~4200"
msgstr ""

#: ../../development/policy_sgd_insight.rst:115
msgid "2.38x"
msgstr ""

#: ../../development/runtime.rst:2
msgid "SPU Runtime"
msgstr ""

#: ../../development/runtime.rst:5
msgid "Architecture"
msgstr ""

#: ../../development/runtime.rst:7
msgid "Here is the big picture of SPU VM."
msgstr ""

#: ../../development/runtime.rst:11
msgid ""
"The top 3 blocks above *SPU VM* are applications, we could ignore them "
"for now."
msgstr ""

#: ../../development/runtime.rst:12
msgid "The bottom left block is the scheduling component."
msgstr ""

#: ../../development/runtime.rst:13
msgid ""
"The main block is the SPU Architecture, which is the core for secure "
"evaluation."
msgstr ""

#: ../../development/runtime.rst:15
msgid "Inside SPU, there are multiple layers, from bottom to up:"
msgstr ""

#: ../../development/runtime.rst:17
msgid ""
"**System layer** provides the basic computation and communication ability"
" for the upper layers."
msgstr ""

#: ../../development/runtime.rst:18
msgid ""
"**Crypto layer** is the key for secure computation, it's composed by 3 "
"sub layers."
msgstr ""

#: ../../development/runtime.rst:20
msgid ""
"**Basic** or classic layer, provides classic cryptography, OT, HE also "
"lives in this layer."
msgstr ""

#: ../../development/runtime.rst:21
msgid ""
"**Correlation** or the offline protocol layer, provides correlation like "
"beaver triple and randbit."
msgstr ""

#: ../../development/runtime.rst:22
msgid ""
"**Protocol** or the online protocol layer, applies random correlation and"
" runs the secure evaluation."
msgstr ""

#: ../../development/runtime.rst:24
msgid ""
"**ALU layer** converts MPC protocols into a programmable machine, which "
"has two sub layers."
msgstr ""

#: ../../development/runtime.rst:26
msgid ""
"**Ring 2^k** layer, just like normal CPU, hides cryptography layer's "
"details and provides standard ring2k arithmetic."
msgstr ""

#: ../../development/runtime.rst:27
msgid ""
"**Fixed point** layer uses fixed point encoding to represent a fractional"
" number and provides basic arithmetic operations over them."
msgstr ""

#: ../../development/runtime.rst:29
msgid ""
"**OPS layer** is designed to be extensible, in this layer we can define "
"multiple modules based on *ALU layer* and finally exposed to VM clients "
"via bindings or SPU IR."
msgstr ""

#: ../../development/runtime.rst:32
msgid "Homogeneous and Heterogeneous"
msgstr ""

#: ../../development/runtime.rst:34
msgid ""
"Recall that SPU VM is composed of multiple physical engines, the "
"definitions of *homogeneous* and *heterogeneous* come from an *engines*' "
"perspective."
msgstr ""

#: ../../development/runtime.rst:36
msgid ""
"**Homogeneous**: a layer is *homogeneous* means that all engines run "
"exactly the same code in this layer. The user of this layer doesn't have "
"to distinguish between engines, they cannot and should not send/recv "
"messages between engines, in other words, they can treat all engines the "
"same, and program them as one machine."
msgstr ""

#: ../../development/runtime.rst:37
msgid ""
"**Heterogeneous**: in contrast, a layer is *heterogeneous* means that "
"engines in this layer behave differently (following some protocols). The "
"author of this layer should take care of the behavior of each engine to "
"make things correct."
msgstr ""

#: ../../development/runtime.rst:39
msgid ""
"We want SPU VM to be *homogeneous*, so we can treat it as a normal "
"virtual device when applying secure evaluation. For example, in the "
"following computation graph, given `x`, `y`, we want to compute `f(x, "
"y)`, the big circle represents a computing node which can evaluate f."
msgstr ""

#: ../../development/runtime.rst:43
msgid ""
"In secure computation mode, we have a group of servers working together "
"to provide the functionality of `f`, as shown blow."
msgstr ""

#: ../../development/runtime.rst:47
msgid ""
"The secure protocol (MPC protocol) itself is **heterogeneous**, three "
"servers inside the big circle may behave differently, in this pic, the "
"lower part is blue, which means three servers act and interact "
"differently."
msgstr ""

#: ../../development/runtime.rst:49
msgid ""
"But they together provide a **homogeneous** interface to the upper layer,"
" in this pic, the upper half is orange, three servers behave exactly the "
"same, so in the whole computation DAG, the big circle could be treated as"
" one (virtual) node."
msgstr ""

#: ../../development/runtime.rst:51
msgid ""
"Another reason to use **homogeneous** IR is to hide the number of "
"parties, so the application can switch to an m-PC protocol from an n-PC "
"protocol without code change."
msgstr ""

#: ../../development/runtime.rst:53
msgid ""
"One of *SPU*'s goal is to hide the heterogeneous part and expose "
"homogeneous API."
msgstr ""

#: ../../development/runtime.rst:56
msgid "VM Layout"
msgstr ""

#: ../../development/runtime.rst:58
msgid ""
"SPU, as a virtual device, is hosted by multiple physical devices. The "
"relationship between physical devices and SPU is very flexible. Now let's"
" use some examples to illustrate the possible layouts."
msgstr ""

#: ../../development/runtime.rst:61
msgid ""
"Programmers coding toward the virtual layout, the underline physical is "
"**transparent** from the programmer's perspective. It's free to use "
"different physical layouts, without changing a single line of code."
msgstr ""

#: ../../development/runtime.rst:64
msgid "Outsourcing"
msgstr ""

#: ../../development/runtime.rst:66
msgid ""
"In this mode, data providers send data shares to a group of non-colluding"
" computation providers who cooperate to evaluate secure computations."
msgstr ""

#: ../../development/runtime.rst:70
msgid ""
"The figure to left depicts the physical layout, there are 6 physical "
"nodes, mutually connected but untrusted to each other."
msgstr ""

#: ../../development/runtime.rst:72
msgid "The circle stands for data provider."
msgstr ""

#: ../../development/runtime.rst:73
msgid ""
"The triangle stands for computing provider, three triangle nodes agree on"
" some MPC protocol."
msgstr ""

#: ../../development/runtime.rst:75
msgid "The figure to the right depicts the virtual layout."
msgstr ""

#: ../../development/runtime.rst:77
msgid "The circle has one-to-one relation to the physical nodes."
msgstr ""

#: ../../development/runtime.rst:78
msgid "3 triangle nodes are treated as a single virtual device."
msgstr ""

#: ../../development/runtime.rst:81
msgid "Colocated"
msgstr ""

#: ../../development/runtime.rst:83
msgid ""
"In this mode, data providers also participate in the computation "
"progress, that is, data providers are **colocated** with computing "
"providers."
msgstr ""

#: ../../development/runtime.rst:87
msgid ""
"On the left side, there are 3 physical nodes, each of which acts as data "
"provider as well as computing provider."
msgstr ""

#: ../../development/runtime.rst:88
msgid ""
"On the right side, **SPU is a pure virtual node, constructed by physical "
"nodes**."
msgstr ""

#: ../../development/runtime.rst:91
msgid ""
"The number of computing nodes could be larger than that of data nodes in "
"this mode, for example, a computing node without data source could act as"
" a *random correlation generator*, for example:"
msgstr ""

#: ../../development/runtime.rst:97
msgid "There are two notable optimizations in this mode."
msgstr ""

#: ../../development/runtime.rst:99
msgid ""
"The **private semantic**, a computing node may have private data "
"manipulations to accelerate MPC computation, for example, in *HESS "
"protocol*, we can do :code:`HShare x Private` without online "
"communication."
msgstr ""

#: ../../development/runtime.rst:100
msgid ""
"The **zero share data infeed**, when a data provider tries to share data "
"cross nodes, it can use :code:`ZeroShare + Private` trick to avoid online"
" communication."
msgstr ""

#: ../../development/runtime.rst:103
msgid "Hybrid"
msgstr ""

#: ../../development/runtime.rst:105
msgid ""
"This is the most general form, some data providers participate in the "
"secure computation while others do not."
msgstr ""

#: ../../development/runtime.rst:110
msgid ""
"the **private semantic** and **zero share data infeed** also apply to "
"data providers that participate in the computation."
msgstr ""

#: ../../development/type_system.rst:2
msgid "Type System"
msgstr ""

#: ../../development/type_system.rst:7
msgid "This document is for VM developers."
msgstr ""

#: ../../development/type_system.rst:9
msgid "Everything in SPU could be treated as an object, each object has a type."
msgstr ""

#: ../../development/type_system.rst:11
msgid ""
"There are only two types of objects, *value* or *operator*, which means "
"if a symbol is not a *value*, it's an *operator*."
msgstr ""

#: ../../development/type_system.rst:13
msgid ""
"**value**: an object that is managed by SPU runtime, representing a "
"public/secret data."
msgstr ""

#: ../../development/type_system.rst:14
msgid ""
"**operator**: an object that takes one or more values and outputs a "
"return value, i.e. `multiply` is an operator."
msgstr ""

#: ../../development/type_system.rst:17
msgid "Value type"
msgstr ""

#: ../../development/type_system.rst:19
msgid "A value type is a tuple (**V**, **D**, **S**), where:"
msgstr ""

#: ../../development/type_system.rst:21
#, python-brace-format
msgid "**V** is *visibility*, could be one of *{public, secret}*"
msgstr ""

#: ../../development/type_system.rst:22
#, python-brace-format
msgid "**D** is *data type*, could be one of *{int, fxp}*"
msgstr ""

#: ../../development/type_system.rst:23
msgid "**S** is *shape*, which makes the value a tensor."
msgstr ""

#: ../../development/type_system.rst:25
msgid ""
"We can define a hyper type function, which takes three parameters and "
"return a concrete value type."
msgstr ""

#: ../../development/type_system.rst:31
msgid ""
"To simplify things a little bit, we can ignore *shape* for now and assume"
" that runtime will handle it correctly."
msgstr ""

#: ../../development/type_system.rst:37
msgid ""
"With this type function, we can define a list of types in the SPU type "
"system."
msgstr ""

#: ../../development/type_system.rst:47
msgid "Operator type"
msgstr ""

#: ../../development/type_system.rst:49
msgid ""
"*Operators* takes a list of values as parameters and returns exactly one "
"value as result, operator's type is determined by the types of input "
"parameters and return values."
msgstr ""

#: ../../development/type_system.rst:51
msgid ""
"In SPU IR, an operator could take a polymorphic typed parameter and the "
"return type could be deduced from the parameters. For example:"
msgstr ""

#: ../../development/type_system.rst:62
msgid ""
"The `add` operator takes a pair of `type(V, D)` as parameter, which has "
"2x2x2x2 = 16 different kinds of combinations. To support this type of "
"operators, we introduce the following *type functor*."
msgstr ""

#: ../../development/type_system.rst:64
msgid ""
"**dtype promotion**, which promotes two dtypes to a more relaxed type, in"
" SPU system, *int* is always promoted to *fxp*."
msgstr ""

#: ../../development/type_system.rst:72
msgid ""
"**visibility narrow**, which narrows the visibility when two or more "
"operands have different visibility properties, this is the key to "
"maintain the \"secure semantic\" of SPU VM, since the resulting "
"visibility of ops will always be more strict. i.e. if one of operands is "
"*secret*, the result is a *secret*."
msgstr ""

#: ../../development/type_system.rst:82
msgid "Now we can represent the polymorphic mul op as:"
msgstr ""

#: ../../development/type_system.rst:88
msgid ""
"the op takes two parameters, first type is :code:`type(V0, D0)`, second "
"type is :code:`type(V1, D1)`."
msgstr ""

#: ../../development/type_system.rst:89
msgid "the op returns :code:`type(narrow(V0, V1), promote(D0, D1))` as a result."
msgstr ""

#: ../../development/type_system.rst:90
msgid ""
"when applying the op to two arbitrary arguments, the result could be "
"deduced from the above type expressions."
msgstr ""

#: ../../development/type_system.rst:94
msgid "Use of type"
msgstr ""

#: ../../development/type_system.rst:96
msgid "There are many uses for types."
msgstr ""

#: ../../development/type_system.rst:98
msgid ""
"First, the most important one, type is self descriptive, with an accurate"
" defined type system, we can describe *SPU IR* more accurately."
msgstr ""

#: ../../development/type_system.rst:99
msgid ""
"Second, runtime type information is used to do runtime dispatch, which is"
" important for polymorphic operators."
msgstr ""

#: ../../development/type_system.rst:100
msgid ""
"Third, the type system could be used by static type checker, and could be"
" used to double check runtime implementation."
msgstr ""

#: ../../development/type_system.rst:104
msgid "Ops dispatch"
msgstr ""

#: ../../development/type_system.rst:106
msgid ""
"As described above, type helps for dispatching, here we use `MUL` "
"instruction as an example."
msgstr ""

#: ../../development/type_system.rst:113
msgid ""
"The above `MUL` instruction does element-wise multiplication, `%1` and "
"`%2` are parameters and `%3` is the return value."
msgstr ""

#: ../../development/type_system.rst:116
msgid "The dispatch problem"
msgstr ""

#: ../../development/type_system.rst:118
#, python-brace-format
msgid ""
"In this example, `%1` and `%2` are SPU values, each of them belongs one "
"of four types `{sint, pint, sfxp, pfxp}`, the type of `MUL` is:"
msgstr ""

#: ../../development/type_system.rst:120
#, python-brace-format
msgid ""
"\\begin{Bmatrix} sint \\\\ pint \\\\ sfxp \\\\ pfxp \\end{Bmatrix}\n"
"\\times\n"
"\\begin{Bmatrix} sint \\\\ pint \\\\ sfxp \\\\ pfxp \\end{Bmatrix}"
msgstr ""

#: ../../development/type_system.rst:126
msgid ""
"**The problem is how to dispatch operations to correct kernel according "
"to the arguments' type information**."
msgstr ""

#: ../../development/type_system.rst:128
msgid ""
"A simple idea is to pattern match all these type combinations and "
"dispatch to different kernels accordingly, with this way we got 4x4=16 "
"different kernels."
msgstr ""

#: ../../development/type_system.rst:146
msgid "Layered dispatch"
msgstr ""

#: ../../development/type_system.rst:148
msgid ""
"A better way is to dispatch layer by layer, for example, first dispatch "
"by dtype, then dispatch by vtype."
msgstr ""

#: ../../development/type_system.rst:172
msgid "In the above diagram:"
msgstr ""

#: ../../development/type_system.rst:174
msgid "**mul** is general *multiplication* method."
msgstr ""

#: ../../development/type_system.rst:175
msgid "**imul** is integer multiplication method."
msgstr ""

#: ../../development/type_system.rst:176
msgid "**fmul** is fixedpoint multiplication method."
msgstr ""

#: ../../development/type_system.rst:177
msgid "**rmul** is untyped multiplication method over ring 2k."
msgstr ""

#: ../../development/type_system.rst:178
msgid ""
"**mulss** multiplies two secrets, the domain and behavior are secure "
"protocol dependent."
msgstr ""

#: ../../development/type_system.rst:180
msgid "The above idea can be expressed in code like:"
msgstr ""

#: ../../development/type_system.rst:215
msgid "Fast dispatch"
msgstr ""

#: ../../development/type_system.rst:217
msgid ""
"In the above example, we observe that `i2f` and `truncation` could be "
"optimized, the intuition is that when a value is converted from `int` to "
"`fxp` and later convert back, these two conversion introduce non-trivial "
"computation overhead in MPC setting."
msgstr ""

#: ../../development/type_system.rst:219
msgid ""
"We use the so called *fast dispatch* to optimize it, when doing cross "
"`int` and `fxp` multiplication, we could directly do `imul` without type "
"lift and truncation."
msgstr ""

#: ../../development/type_system.rst:239 ../../development/type_system.rst:274
msgid "Note:"
msgstr ""

#: ../../development/type_system.rst:241
msgid "in the above implementation we didn't maintain the type correctness."
msgstr ""

#: ../../development/type_system.rst:242
msgid ""
"this pattern match based *fast dispatch* is exactly the same as compile-"
"time *peephole optimization*."
msgstr ""

#: ../../development/type_system.rst:243
msgid ""
"dispatch inside a protocol is also complicated and beyond the scope of "
"this article."
msgstr ""

#: ../../development/type_system.rst:247
msgid "Implementation"
msgstr ""

#: ../../development/type_system.rst:249
msgid ""
"With *type functor*, we have the following op definitions in `mul` "
"dispatch chain."
msgstr ""

#: ../../development/type_system.rst:258
msgid ""
"In dispatch phrase, SPU runtime uses type information to select next "
"dispatch op. In this example, `(x:sfxp, y:sfxp)` is applied op `mul`, via"
" pattern matching we got `(V0=SECRET,D0=FXP), (V1=SECRET,D1=FXP)`, and "
"the dispatch stack looks like:"
msgstr ""

#: ../../development/type_system.rst:276
msgid ""
"We use C++-like template type notation to represent polymorphic type "
"constraints."
msgstr ""

#: ../../development/type_system.rst:279
msgid "Partial type"
msgstr ""

#: ../../development/type_system.rst:281
msgid ""
"In the type dispatch step, type information is used to select next op, "
"and when partial of type information is used, it's *erased*. For example,"
" when `dtype` is used to select `fmul` in the above example, dtype is "
"useless in the future and could be erased, the lower level op does not "
"distinguish dtype (via a generic type parameter). In a real "
"implementation, we don't erase the type explicitly, just leave it there "
"without further use."
msgstr ""

#: ../../development/type_system.rst:283
msgid ""
"The return value takes the `reverse progress` of dispatch. The return "
"type is filled from bottom to up. For example, in the above progress, "
"when :code:`z=rmul(x,y)` is called, `rmul` knows `z`'s visibility type is"
" `SECRET` but does not know its dtype yet, so here `z` has a partial type"
" `type(SECRET, $UNKNOWN)`. The type will be filled step by step during "
"stack popup, and eventually be completed as a full type when the whole "
"dispatch progress is done."
msgstr ""

#: ../../development/visibility_inference_rule.rst:2
msgid "Visibility Inference"
msgstr ""

#: ../../development/visibility_inference_rule.rst:7
msgid "This document is for SPU compiler developers."
msgstr ""

#: ../../development/visibility_inference_rule.rst:9
msgid ""
"In SPU compiler stack, visibility is part of type qualifier. During "
"legalize stablehlo to pphlo, every SSA value and BlockArg need to assign "
"with a proper visibility. This procedure is referred as **Visibility "
"Inference**"
msgstr ""

#: ../../development/visibility_inference_rule.rst:13
msgid "Common Visibility"
msgstr ""

#: ../../development/visibility_inference_rule.rst:15
msgid ""
"When an operation inputs have different visibilities, the way of compute "
"common visibility is defined as:"
msgstr ""

#: ../../development/visibility_inference_rule.rst:25
msgid "Nullary Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:27
msgid ""
"Nullary ops in stablehlo are `ConstantOp "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#constant>`_ "
"and `IotaOp "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#iota>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:30
msgid "All nullary ops follows the following inference rule:"
msgstr ""

#: ../../development/visibility_inference_rule.rst:38
msgid "Unary Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:40
msgid ""
"Most unary ops in **stablehlo** cannot change visibility of input "
"argument and follows the following inference rule:"
msgstr ""

#: ../../development/visibility_inference_rule.rst:49
msgid "Binary Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:51
msgid ""
"Most binary ops in **stablehlo** yield a result with common visibility of"
" **lhs** and **rhs** and follows the following inference rule:"
msgstr ""

#: ../../development/visibility_inference_rule.rst:60
msgid "Control Flow Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:62
msgid ""
"`If <https://github.com/openxla/stablehlo/blob/main/docs/spec.md#if>`_ "
"and `Case "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#case>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:63
msgid ""
"In short, each result of an if statement is common visibility of results "
"from different branches and predicate."
msgstr ""

#: ../../development/visibility_inference_rule.rst:65
msgid ""
"If different branches yield results of different visibilities, cast to "
"common visibility will be inserted before relative return."
msgstr ""

#: ../../development/visibility_inference_rule.rst:90
msgid ""
"`While "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#while>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:91
msgid ""
"For while body, consider result visibility might be different from input "
"visibility, multi-rounds of visibility inference is applied on body "
"region. The final result will be all input visibility matches result "
"visibility."
msgstr ""

#: ../../development/visibility_inference_rule.rst:94
msgid ""
"**Attention**: Although no protocol supports **while** with a non-public "
"cond region at this point, compiler in general does not error out here."
msgstr ""

#: ../../development/visibility_inference_rule.rst:108
msgid "Reduce Related Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:110
msgid ""
"`Reduce "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#reduce>`_ "
"and `ReduceWindow "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#reduce_window>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:120
msgid ""
"`SelectAndScatter "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#select_and_scatter>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:121
msgid "In general the rule is"
msgstr ""

#: ../../development/visibility_inference_rule.rst:122
msgid "visibility(opernad) == visibility(init)"
msgstr ""

#: ../../development/visibility_inference_rule.rst:123
msgid "visibility(result) == common_visibility(operand, source, init)"
msgstr ""

