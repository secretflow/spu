# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021 Ant Group Co., Ltd.
# This file is distributed under the same license as the SPU package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: SPU \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-13 15:14+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../development/add_protocols.rst:2
msgid "Adding New MPC Protocols"
msgstr ""

#: ../../development/add_protocols.rst:5
msgid ""
"SecretFlow SPU currently is under active development and the APIs "
"provided to protocol developers may be unstable at this moment."
msgstr ""

#: ../../development/add_protocols.rst:8 ../../development/ir_dump.rst:8
msgid "Introduction"
msgstr ""

#: ../../development/add_protocols.rst:9
msgid ""
"This document is mainly for developers who want to add custom MPC "
"protocols in SPU. Before reading this document, we recommend that "
"developers have a basic understanding of the SPU system architecture "
"(i.e., :ref:`/development/compiler.rst`, "
":ref:`/development/type_system.rst` and :ref:`/development/runtime.rst`) "
"and the `layout "
"<https://github.com/secretflow/spu/blob/main/REPO_LAYOUT.md>`_ of the SPU"
" code repository. In short, SPU translates the high-level applications "
"(such as machine learning model training) written in JAX to an MPC-"
"specific intermediate representation named PPHLO and then dispatches "
"PPHLO operations to the low-level MPC protocols. In theory, protocol "
"developers only need to implement a basic set of MPC operation APIs to "
"fully use the SPU infrastructure to run machine learning or data analysis"
" programs. That is to say, for most MPC protocol development, it only "
"needs to add some source code files into the libspu/mpc folder. At "
"present, SPU has integrated several protocols such as ABY3 and Cheetah, "
"which can be regarded as a guide for protocol implementation."
msgstr ""

#: ../../development/add_protocols.rst:22
msgid "A walk-through guide"
msgstr ""

#: ../../development/add_protocols.rst:23
msgid ""
"We further illustrate the procedures of adding protocols step by step in "
"a **top-down** manner."
msgstr ""

#: ../../development/add_protocols.rst:26
msgid "Add a new protocol kind"
msgstr ""

#: ../../development/add_protocols.rst:27
msgid ""
"When users launch the SPU backend runtime, they will specify the running "
"MPC protocol kind through the runtime config. The protocol kinds "
"supported by SPU are enumerations defined in `spu.proto "
"<https://github.com/secretflow/spu/blob/main/libspu/spu.proto>`_. Thus, "
"developers must add their protocol kinds in this protobuf file to enable "
"SPU to be aware of the new protocols."
msgstr ""

#: ../../development/add_protocols.rst:33
msgid "ProtocolKind enumerations"
msgstr ""

#: ../../development/add_protocols.rst:49
msgid "Register protocol"
msgstr ""

#: ../../development/add_protocols.rst:50
msgid ""
"Each MPC protocol execution environment is abstracted as a C++ instance "
"of an `Object "
"<https://github.com/secretflow/spu/blob/main/libspu/core/object.h>`_ "
"class in SPU. SPU constructs an MPC object when creating an "
"**SPUContext**. Then, SPU registers a concrete protocol implementation "
"through a factory function named `RegisterProtocol "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/factory.cc>`_ "
"according to the runtime config. Therefore, protocol developers need to "
"add their functions in **RegisterProtocol** to implement protocols."
msgstr ""

#: ../../development/add_protocols.rst:55
msgid "RegisterProtocol function"
msgstr ""

#: ../../development/add_protocols.rst:77
msgid "Implement protocol IO interface"
msgstr ""

#: ../../development/add_protocols.rst:78
msgid ""
"Another function called by the factory class is the **CreateIO** "
"function. As different protocols use different secret sharing schemas, "
"which means SPU has to use different ways to input/output secret data "
"from plaintext data. As a results, developers have to implement these "
"protocol-specific APIs defined in `io_interface.h "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/io_interface.h>`_."
" Developers can check the `ABY3 implementation "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/io.cc>`_ as "
"a reference."
msgstr ""

#: ../../development/add_protocols.rst:84
msgid "Understand protocol object"
msgstr ""

#: ../../development/add_protocols.rst:85
msgid ""
"SPU protocol `Object "
"<https://github.com/secretflow/spu/blob/main/libspu/core/object.h>`_ may "
"be the key concept for adding new protocols. Let's take a closer look at "
"its design. The goal of **Object** class is to realize the generalization"
" and flexibility of developing MPC protocols through dynamic binding. An "
"Object instance has a series of kernels and states. A kernel and a state "
"can be regarded as a member function and a member variable of an Object, "
"respectively."
msgstr ""

#: ../../development/add_protocols.rst:91
msgid "SPU protocol Object class"
msgstr ""

#: ../../development/add_protocols.rst:127
msgid "Construct protocol object"
msgstr ""

#: ../../development/add_protocols.rst:128
msgid ""
"We take the ABY3 implementation as a specific example to further explain "
"the description above."
msgstr ""

#: ../../development/add_protocols.rst:130
msgid ""
"First of all, we can see that there is an independent aby3 directory "
"under the `libspu/mpc "
"<https://github.com/secretflow/spu/tree/main/libspu/mpc>`_ directory in "
"SPU's repository layout. The aby3 directory includes the C++ source files"
" and header files required by the ABY3 protocol implementation. These "
"files may be confusing at first glance. The key to know its code "
"organization is to open the `protocol "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/protocol.cc>`_"
" file, which defines the **regAby3Protocol** function for registering "
"kernels and states. This function will be called by the factory class "
"described in previous step."
msgstr ""

#: ../../development/add_protocols.rst:137
msgid "ABY3 protocol registration"
msgstr ""

#: ../../development/add_protocols.rst:164
msgid "Inside the **regAby3Protocol** function, it does three things."
msgstr ""

#: ../../development/add_protocols.rst:166
msgid ""
"The first is to register the protocol types. These types are defined in "
"the `type.h "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/type.h>`_ "
"header file, \\ representing an arithmetic secret share and a boolean "
"secret share, respectively."
msgstr ""

#: ../../development/add_protocols.rst:169
msgid ""
"The second is to register protocol states (variables), specifically "
"including the three states of Z2kState, \\ Communicator, and PrgState, "
"which are used to store the ring information, communication facilities, "
"and \\ pseudorandom number generator for protocol implementation."
msgstr ""

#: ../../development/add_protocols.rst:173
msgid ""
"The third is to register the protocol kernels (functions). We can see "
"that two types of kernels are registered. \\ The first type is the common"
" kernels implemented in the `pv2k.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/common/pv2k.cc>`_"
" \\ file. The second type is implemented in `arithmetic.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/arithmetic.cc>`_,"
" \\ `boolean.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/boolean.cc>`_"
" and other files under the aby3 directory."
msgstr ""

#: ../../development/add_protocols.rst:179
msgid "Implement protocol kernels"
msgstr ""

#: ../../development/add_protocols.rst:180
msgid ""
"In this section, we further explain why the ABY3 developer registers "
"these two types of kernels. In SPU, the interfaces between MPC and HAL "
"layers are defined in the `api.h "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/api.h>`_ file, "
"which consists of a set of operations with public or secret operands "
"(referred as **basic APIs** for the rest of this document). As long as a "
"protocol developer implements basic APIs, he/she can use the SPU full-"
"stack infrastructure to run high-level applications, e.g., training "
"complex neural network models."
msgstr ""

#: ../../development/add_protocols.rst:186
msgid "Some SPU MPC basic APIs"
msgstr ""

#: ../../development/add_protocols.rst:198
msgid ""
"Among the basic APIs, some protocols working on Rings share the same "
"logic on some operations processing public operands, so SPU developers "
"pre-implement these APIs as kernels and place them in the common "
"directory. As a result, the ABY3 developer can directly register these "
"kernels through the **regPV2kKernels** function."
msgstr ""

#: ../../development/add_protocols.rst:202
msgid "Pre-implemented *and_pp* kernel"
msgstr ""

#: ../../development/add_protocols.rst:224
msgid "Register *and_pp* kernel in regPV2kKernels function"
msgstr ""

#: ../../development/add_protocols.rst:235
msgid ""
"Besides, ABY3 protocol-specific operations need to be implemented by "
"developers as kernels to register. For example, the multiplication of two"
" arithmetic secret shares of ABY3 is implemented as the **MulAA** kernel "
"located in the `arithmetic.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/arithmetic.cc>`_"
" source file. When kernels are implemented and registered, a new protocol"
" is finally added."
msgstr ""

#: ../../development/add_protocols.rst:240
msgid "ABY3 *mul_aa* kernel for arithmetic share multiplication"
msgstr ""

#: ../../development/add_protocols.rst:258
msgid "Testing"
msgstr ""

#: ../../development/add_protocols.rst:259
msgid ""
"After a protocol is added, the developer usually wants to test whether "
"the protocol works as expected. There are two ways to test the protocol "
"functionality in SPU. The first way is to run python examples. SPU has "
"provided users with a series of application `examples "
"<https://github.com/secretflow/spu/tree/main/examples/python>`_. If a "
"protocol fully implements SPU's basic APIs, the developer can run these "
"high-level examples to verify whether the low-level protocol development "
"is correct."
msgstr ""

#: ../../development/add_protocols.rst:265
msgid ""
"The second way is to write and run unittest. Some protocols do not cover "
"all the basic APIs and cannot run examples, or developers only want to "
"test the functionalities of some specific MPC operations (such as "
"addition and multiplication). In these cases it is more practical to run "
"unittest. SPU developers have construct a general test frameworks in "
"`api_test.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/api_test.cc>`_ "
"and `ab_api_test.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/ab_api_test.cc>`_."
" Developers of new protocols need to instantiate these frameworks to test"
" their own protocol functionalities. Developers can refer to the "
"`protocol_test.cc "
"<https://github.com/secretflow/spu/blob/main/libspu/mpc/aby3/protocol_test.cc>`_"
" file in the aby3 directory to learn how to write their own protocol test"
" files."
msgstr ""

#: ../../development/basic_concepts.rst:2
msgid "Basic concepts"
msgstr "基本概念"

#: ../../development/basic_concepts.rst:4
msgid ""
"SPU has quite a different programming model than CPU/GPU, this guide "
"introduces the basic concepts."
msgstr "本文档旨在阐述 SPU 的核心概念，SPU 的编程模型与 CPU/GPU 存在显著差异。"

#: ../../development/basic_concepts.rst:7
msgid "Machine model"
msgstr "机器模型"

#: ../../development/basic_concepts.rst:9
msgid ""
"In normal CPU model, we could treat the machine as an *arithmetic "
"blackbox*, which accepts user's *code* and *data*, runs the computation, "
"and returns result *data* to user. If we draw a picture to show the "
"relationship between user and machine, it's something like this."
msgstr "在传统 CPU 模型中，机器可视为一个算术黑箱，其接收用户的代码与数据，执行计算后返回结果数据。用户与机器的关系可示意如下。"

#: ../../development/basic_concepts.rst:13
msgid "user and CPU"
msgstr "CPU 模型"

#: ../../development/basic_concepts.rst:16
msgid ""
"In SPU, the first notable difference is that, *input* is not provided by "
"a single user, it's from **multiple parties**, and the *code* could be "
"provided by a separate party, finally, the output could be received by "
"another party. So **SPU is born to be used in a distributed context**. It"
" looks like:"
msgstr ""
"SPU 的显著特征在于：输入数据来源于多方，代码可能由独立参与方提供，计算结果亦可由不同参与方接收。因此，SPU "
"专为分布式场景设计，其交互模型如下。"

#: ../../development/basic_concepts.rst:20
msgid "multi-user and SPU"
msgstr "SPU 模型"

#: ../../development/basic_concepts.rst:23
msgid ""
"If we take a closer look, SPU itself is not a physical machine, it is "
"hosted by multiple parties that don't trust on each other. For example, "
"in the following picture, we have three parties (red, blue and green) "
"that work together with some MPC protocols, and provide computation "
"service as a **virtual machine**."
msgstr ""
"进一步观察，SPU 并非物理实体机器，而是由互不信任的多个参与方共同托管。例如，下图展示三个参与方（红、蓝、绿）通过 MPC "
"协议协作，共同构建虚拟机服务："

#: ../../development/basic_concepts.rst:27
msgid "inside SPU"
msgstr "SPU 内部架构"

#: ../../development/basic_concepts.rst:30
msgid ""
"So we have treated SPU as a (multi-party visualized) **secure arithmetic "
"blackbox**, which can evaluate computations securely."
msgstr "综上，SPU 可抽象为多方协同的安全算术黑箱，提供安全计算能力。"

#: ../../development/basic_concepts.rst:33
msgid "Programming model"
msgstr "编程模型"

#: ../../development/basic_concepts.rst:35
msgid "With the above VM model, the next question is **how to program on it**?"
msgstr "基于上述虚拟机模型，SPU 的编程需解决以下问题：如何为多方协同计算编写程序？"

#: ../../development/basic_concepts.rst:37
msgid ""
"Inside SPU, each physical node behaves differently for the same progress,"
" i.e. some nodes act as senders, while others act as receivers."
msgstr "SPU 中，各物理节点在同一计算流程中执行不同操作（如发送方与接收方）。"

#: ../../development/basic_concepts.rst:39
msgid ""
"But from the users' (of SPU) perspective, SPU behaves as one single VM. "
"One important responsibility of SPU compiler/runtime pipeline is to "
"translate **homogeneous** program to another for **heterogeneous** "
"runtime engines."
msgstr "但对用户而言，SPU 表现为单一虚拟机。SPU 编译器/运行时的核心职责是将同构程序转换为适配异构运行时引擎的指令。"

#: ../../development/basic_concepts.rst:41
msgid ""
"For example, in the following computation graph, given `x`, `y`, we want "
"to compute `f(x, y)`, and the big circle represent a compute node which "
"can evaluate f."
msgstr "例如，在下面的计算图中，给定 `x`，`y`，我们想要计算 `f（x，y）`，大圆圈表示可以评估 f 的计算节点。"

#: ../../development/basic_concepts.rst:45
msgid ""
"In SPU, a group of nodes work together to provide functionality of `f`, "
"as shown blow."
msgstr "而在 SPU 中，多个节点通过协议协作实现等效功能："

#: ../../development/basic_concepts.rst:49
msgid "With the above abstraction, SPU can:"
msgstr "通过此抽象，SPU 具备以下特性："

#: ../../development/basic_concepts.rst:51
msgid "Hide the underline protocols, *write once, run on all protocols*."
msgstr "协议透明化，一次编码，支持多种底层协议。"

#: ../../development/basic_concepts.rst:52
msgid ""
"Hide the number of parties, *write once, run for a variable number of "
"parties*."
msgstr "规模弹性化，一次编码，适配可变参与方数量。"

#: ../../development/basic_concepts.rst:56
msgid "API level"
msgstr "API 层级"

#: ../../development/basic_concepts.rst:58
msgid ""
"With the above programming model, the next question is **which language "
"is supported**? SPU provides multi-level API, from upper to lower:"
msgstr "基于上述编程模型，接下来支持哪些语言呢？SPU 提供多层 API，从高阶到低阶依次为："

#: ../../development/basic_concepts.rst:60
msgid ""
"**Frontend API** (like TensorFlow/JAX), SPU compiles them into SPU IR "
"before running."
msgstr "Frontend API（如 TensorFlow/JAX），通过 SPU 编译转换为 SPU IR。"

#: ../../development/basic_concepts.rst:61
msgid ""
"**SPU IR**, an Intermediate Representation format defined by SPU, which "
"is not quite readable but easier for computers to understand."
msgstr "SPU IR，一种由 SPU 定义的中间表示格式，其可读性不强，但更易于计算机理解。"

#: ../../development/basic_concepts.rst:62
msgid "**C++ API**, which could directly access the underline MPC protocols."
msgstr "C++ API，可以直接访问底层MPC协议。"

#: ../../development/basic_concepts.rst:64
msgid "The API hierarchy looks like:"
msgstr "API 层次结构如下："

#: ../../development/basic_concepts.rst:69
msgid "SPU API hierarchy"
msgstr "SPU API 层次结构"

#: ../../development/basic_concepts.rst:72
msgid ""
"An important goal of SPU is to allow people to write secure programs with"
" their familiar frameworks they are familiar with, so it's recommended to"
" use Frontend API."
msgstr "SPU 的核心设计目标是让用户使用他们熟悉的框架编写安全程序，推荐优先使用 Frontend API。"

#: ../../development/basic_concepts.rst:74
msgid ""
"Currently, only JAX frontend is supported for now. Please check :doc:`JAX"
" on SPU <../tutorials/quick_start>`."
msgstr "当前仅支持 JAX 前端，详见 :doc:`JAX on SPU <../tutorials/quick_start>`。"

#: ../../development/compiler.rst:2
msgid "SPU Compiler"
msgstr "SPU 编译器"

#: ../../development/compiler.rst:4
msgid ""
"The SPU compiler aims to provide first-party compiler support from the "
"different ML frameworks to SPU runtime."
msgstr "SPU 编译器旨在为 SPU 运行时提供来自不同 ML 框架的原生编译器支持。"

#: ../../development/compiler.rst:7
msgid ""
"`MLIR <https://mlir.llvm.org/>`_ The MLIR project is a novel approach to "
"building reusable and extensible compiler infrastructure. MLIR aims to "
"address software fragmentation, improve compilation for heterogeneous "
"hardware, significantly reduce the cost of building domain specific "
"compilers, and aid in connecting existing compilers together."
msgstr ""
"MLIR：MLIR 项目是一种构建可重复使用、可扩展的编译器基础架构的新方法。MLIR "
"旨在解决软件碎片化问题、改进异构硬件的编译、大幅降低构建特定领域编译器的成本，并帮助将现有编译器连接在一起。"

#: ../../development/compiler.rst:9
msgid ""
"`XLA <https://www.tensorflow.org/xla/architecture>`_ Multiple Vendors use"
" XLA as the middle layer, mapping from platform frameworks like PyTorch, "
"JAX, and TensorFlow into XLA and then progressively lowering down to "
"their target hardware."
msgstr "XLA：多家供应商使用 XLA 作为中间层，从 PyTorch、JAX 和 TensorFlow 等平台框架映射到 XLA，然后逐步翻译到目标硬件。"

#: ../../development/compiler.rst:11
msgid ""
"`MLIR-HLO <https://github.com/tensorflow/mlir-hlo>`_ MLIR-HLO project "
"connects XLA into MLIR world."
msgstr "MLIR-HLO：MLIR-HLO 项目将 XLA 连接到 MLIR。"

#: ../../development/compiler.rst:13
msgid ""
"Having canonical lowerings from different frontend frameworks to the MLIR"
" ecosystem would provide much needed relief to hardware vendors to focus "
"on their unique value rather than implementing yet another frontend for "
"SPU. For current hardware vendors, they just need to add LLVM target "
"support instead of implementing separate Clang/C++ frontends. MLIR-HLO is"
" achieving similar goal."
msgstr ""
"将不同前端框架的规范翻译到 MLIR 生态系统，将为硬件供应商提供有效的帮助，使他们能够专注于其独特价值，而不是为 SPU "
"实现另一个前端。对于当前的硬件供应商，他们只需添加 LLVM 支持，而不是实现单独的 Clang/C++ 前端。MLIR-HLO "
"正在实现类似的目标。"

#: ../../development/compiler.rst:17
msgid "All the roads from ML frameworks to SPU"
msgstr "ML 框架到 SPU 的层次结构"

#: ../../development/design_device.rst:2
msgid "Design: generic device"
msgstr ""

#: ../../development/design_device.rst:5
msgid ""
"This is a design draft for using SPU from SecretFlow, not an accurate "
"document for SPU itself. It could be treated as a reference to integrate "
"SPU from other systems."
msgstr ""

#: ../../development/design_device.rst:8 ../../development/pipeline.rst:14
#: ../../development/type_system.rst:5
#: ../../development/visibility_inference_rule.rst:5
msgid "Overview"
msgstr "概述"

#: ../../development/design_device.rst:10
msgid ""
"This document discusses the design of a trust chain under an universal "
"device concept."
msgstr ""

#: ../../development/design_device.rst:13
msgid "Concept"
msgstr ""

#: ../../development/design_device.rst:15
msgid ""
"**Device**, a virtual concept which can evaluate a piece of code, "
"normally a specific device provides some specific abilities, i.e. CPU is "
"a device for general computation, GPU is a device for parallel "
"computation, HE/MPC evaluator are devices for security computation. "
"Formally, a device is a set of ops :math:`\\left \\{  OP_{i} \\right "
"\\}`."
msgstr ""

#: ../../development/design_device.rst:17
msgid ""
"*DeviceObject* an object which could be operated by the device, formally,"
" it's a set of data :math:`\\left \\{  D_{i} \\right \\}`."
msgstr ""

#: ../../development/design_device.rst:18
msgid ""
"*Consistency property* is `if type(Di) == type(Dj) and OP works for Di, "
"it also works for Dj`"
msgstr ""

#: ../../development/design_device.rst:19
msgid ""
"*Complete property* is that :math:`\\left \\{  OP_{i} \\right \\}` is "
"*turing complete*"
msgstr ""

#: ../../development/design_device.rst:21
msgid ""
"**Node**, a physical node which provides general computing environment, "
"it could host devices."
msgstr ""

#: ../../development/design_device.rst:23
msgid ""
"**Computation** or DAG, is a form to represent logic function, with "
"*node* as operator and *edge* as data."
msgstr ""

#: ../../development/design_device.rst:25
msgid ""
"**SecretFlow**, is a framework that could schedule a *Computation* to a "
"list of *Device*, with respect that:"
msgstr ""

#: ../../development/design_device.rst:27
msgid ""
"**Securely data transferred** across devices, unless the client "
"explicitly makes an unsafe transfer."
msgstr ""

#: ../../development/design_device.rst:28
msgid ""
"Each op runs on exactly on one device, **there is no cross-device "
"function**."
msgstr ""

#: ../../development/design_device.rst:32
msgid "Notations"
msgstr ""

#: ../../development/design_device.rst:38
msgid "*empty shape* stands for **Node**"
msgstr ""

#: ../../development/design_device.rst:39
msgid "*colored shape* stands for **Device**"
msgstr ""

#: ../../development/design_device.rst:40
msgid "*dotted line* stands for **no trust** relation between devices."
msgstr ""

#: ../../development/design_device.rst:41
msgid ""
"*dotted line with arrow* stands for **weak trust** relation, one device "
"could send its encrypted data to another without data loss."
msgstr ""

#: ../../development/design_device.rst:42
msgid ""
"*solid line with arrow* stands for **strong trust** relation, one device "
"could send its raw data to another without data loss."
msgstr ""

#: ../../development/design_device.rst:47
msgid "Device layout"
msgstr ""

#: ../../development/design_device.rst:50
msgid "Outsourcing (MPC)"
msgstr ""

#: ../../development/design_device.rst:54
msgid ""
"In above deployment, we use 6 nodes to construct 4 devices, where circle "
"devices have weak trust to the triangle device."
msgstr ""

#: ../../development/design_device.rst:57
msgid "Colocated (MPC)"
msgstr ""

#: ../../development/design_device.rst:61
msgid ""
"In above deployment, we use 3 nodes to construct 4 devices, where circle "
"devices have weak trust to the triangle device."
msgstr ""

#: ../../development/design_device.rst:63
msgid ""
"Note, in this configuration, we use 3 nodes to build exactly the same "
"device layout as the 6 node out-sourcing mode, the client code could run "
"exactly the same without any changes. That is **write once, run "
"anywhere**."
msgstr ""

#: ../../development/design_device.rst:66
msgid "Server-aided (MPC)"
msgstr ""

#: ../../development/design_device.rst:70
msgid ""
"In this configuration, one server does not provide data but participates "
"in the computation, it's so called a `server-aided`."
msgstr ""

#: ../../development/design_device.rst:73
msgid "HE device"
msgstr ""

#: ../../development/design_device.rst:77
msgid "In this mode, we use 2 nodes to virtualize 3 devices, with that:"
msgstr ""

#: ../../development/design_device.rst:79
msgid ""
"The *magenta device* colocated with *yellow CPU device*, with a *strong "
"trust* relationship."
msgstr ""

#: ../../development/design_device.rst:80
msgid ""
"The *red CPU device* and the *magenta HE device* forms a *weak trust* "
"relationship."
msgstr ""

#: ../../development/design_device.rst:84
msgid "In this configuration, we use 2 nodes to virtualize 4 devices, with that:"
msgstr ""

#: ../../development/design_device.rst:86
msgid ""
"each *circle device* has one *strong trust* with one *diamond device* "
"while a *weak trust* to another *diamond device*."
msgstr ""

#: ../../development/design_device.rst:90
msgid ""
"In this configuration, we have 3 nodes. For clarity, we name upper one as"
" Alice, lower-left as Bob, lower-right as Charlie."
msgstr ""

#: ../../development/design_device.rst:92
#, python-brace-format
msgid ""
"Both {Bob, Charlie} would encrypt their data and send it to Alice, we "
"have to do possible device abstractions."
msgstr ""

#: ../../development/design_device.rst:94
msgid ""
"In the middle, there is only one *HE device*, which could be used to "
"compute all cipher-texts."
msgstr ""

#: ../../development/design_device.rst:96
msgid ""
"pros: there is only one HE device per-node, which means if we have N "
"parties, we have at most N HE-devices."
msgstr ""

#: ../../development/design_device.rst:97
msgid ""
"cons: it breaks the *Consistency property*, i.e. `add::([x], [y])` add "
"two cipher-texts could not be done if two cipher-texts come from "
"different parties. Another example: when doing output, Bob may get a "
"cipher-text from the *HE-device*, but he can not decrypt it, since he "
"does not have the right key. @jint, IMHO, *Consistency* is the key-point "
"to guide programmers, **it's confusing if an op sometime work, sometimes "
"not**."
msgstr ""

#: ../../development/design_device.rst:99
msgid ""
"In the right configuration, there are 2 *HE device*, both reside on "
"Alice, but one for Bob and one for Charlie."
msgstr ""

#: ../../development/design_device.rst:101
msgid "pros: Consistency, the device concept is exactly the same as MPC/TEE."
msgstr ""

#: ../../development/design_device.rst:102
msgid ""
"cons: there will be at most :math:`N^2` HE devices for N nodes. This "
"might not be a problem since it depicts the 2PC property of HE (@jint)."
msgstr ""

#: ../../development/design_device.rst:106
msgid "Device and Node"
msgstr ""

#: ../../development/design_device.rst:108
msgid ""
"A device is composed by one or more nodes, this section covers the common"
" used device/node pattern in SecretFlow."
msgstr ""

#: ../../development/design_device.rst:110
msgid "For CPU and MPC, it's easy."
msgstr ""

#: ../../development/design_device.rst:112
msgid "A CPU device is composed by only one node."
msgstr ""

#: ../../development/design_device.rst:113
msgid "An MPC device is composed by a list of nodes (unordered)."
msgstr ""

#: ../../development/design_device.rst:115
msgid ""
"For HE device, it's a bit of complicated, it's composed by a pair of "
"nodes `(location, key-owner)`"
msgstr ""

#: ../../development/design_device.rst:117
msgid "**Location node** is the node that the evaluator located on."
msgstr ""

#: ../../development/design_device.rst:118
#, python-brace-format
msgid "**KeyOwner node** is the node that provides `{PK, SK}`"
msgstr ""

#: ../../development/design_device.rst:120
msgid "Formally, we can define devices via a configuration file."
msgstr ""

#: ../../development/design_device.rst:131
msgid "For example:"
msgstr ""

#: ../../development/design_device.rst:156
msgid "Let's ignore the SPU device for a moment, the CPU and HEU looks like this:"
msgstr ""

#: ../../development/design_device.rst:160
msgid ""
"In this example, `HEU` computation part is strait-forward, the non-"
"trivial part is the IO (device-to-device transfer). Let's consider "
"several IO cases."
msgstr ""

#: ../../development/design_device.rst:162
msgid ""
"First, transfer data from `P1` to `HEU`, in this case, from device "
"concept level, `P1` **strong trust** on `HEU`, so it can send plaintext "
"directly to `HEU`. In implementation, `P1` is colocated with `HEU`, so it"
" makes sense for a plaintext transfer."
msgstr ""

#: ../../development/design_device.rst:163
msgid ""
"Second, transfer data from `P2` to `HEU`, in device concept, `P2` **weak "
"trust** `HEU`, so it has to encrypt the data with SK, then sends it to "
"`HEU`. From implementation point of view, `P2` has the private key, so it"
" can do the encryption."
msgstr ""

#: ../../development/design_device.rst:164
msgid ""
"Third case, transfer data devices other than `P1` and `P2` to `HEU`, in "
"this case, it's neither colocated with `HEU` nor key-provider of `HEU`, "
"it's just a participant, which has a `weak trust` relationship with "
"`HEU`, and will request `PK` from the `HEU`."
msgstr ""

#: ../../development/design_device.rst:190
msgid "As said before, when the IO is ready, it's trivial to fire jobs on it."
msgstr ""

#: ../../development/design_device.rst:192
msgid ""
"For output, a notable part of `HEU` is that, it could only reveal the "
"result to the `key-owner` node. If you want to output to a node other "
"than `key-owner node`, you have to ask key-owner node for help. This "
"depicts the fact that HE is indeed a 2PC device, so more than 2PC cases "
"should be handled specially."
msgstr ""

#: ../../development/design_workflow.rst:2
msgid "Design: workflow"
msgstr ""

#: ../../development/design_workflow.rst:5
msgid ""
"This is an early stage design document, the concepts may not match the "
"implementation."
msgstr ""

#: ../../development/design_workflow.rst:8
msgid "Concepts"
msgstr ""

#: ../../development/design_workflow.rst:11
msgid "Components"
msgstr ""

#: ../../development/design_workflow.rst:13
msgid ""
"Before formal definition of SPU components, we define kinds of entities "
"first."
msgstr ""

#: ../../development/design_workflow.rst:15
msgid ""
"*Entity*: an entity is a lib/process/service which could be deployed to "
"provide some functionalities."
msgstr ""

#: ../../development/design_workflow.rst:16
msgid ""
"*Virtual entity*: a virtual entity is a group of entities which "
"cooperates to provide some functionalities."
msgstr ""

#: ../../development/design_workflow.rst:18
msgid "SPU component is an entity or virtual entity."
msgstr ""

#: ../../development/design_workflow.rst:20
msgid ""
"**Compiler**: is an entity which translates/optimizes a XLA DAG to a SPU "
"DAG."
msgstr ""

#: ../../development/design_workflow.rst:21
msgid ""
"**(Compute) Engine**: is an entity that cooperates with other engines to "
"do secure evaluation."
msgstr ""

#: ../../development/design_workflow.rst:22
msgid ""
"**Virtual Machine**: is a virtual entity which consists of a group of "
"engines, and can launch a SPU computation."
msgstr ""

#: ../../development/design_workflow.rst:23
msgid ""
"**Storage Engine**: is an entity which provides input data (data "
"provider) or receives output data (data sink)."
msgstr ""

#: ../../development/design_workflow.rst:24
msgid ""
"**Virtual Storage**: is a virtual entity which contains a group of "
"storage engines."
msgstr ""

#: ../../development/design_workflow.rst:25
msgid ""
"**Driver**: is an entity which drives all entities/virtual engines to "
"jointly complete a secure evaluation."
msgstr ""

#: ../../development/design_workflow.rst:28
msgid ""
"SPU components are typically hosted by several parties which do not trust"
" each other. We usually assign different roles to these parties."
msgstr ""

#: ../../development/design_workflow.rst:30
msgid "Kind of roles:"
msgstr ""

#: ../../development/design_workflow.rst:32
msgid "**Data provider**: which hosts storage engine."
msgstr ""

#: ../../development/design_workflow.rst:33
msgid "**Algorithm provider**: which provides the algorithm."
msgstr ""

#: ../../development/design_workflow.rst:34
msgid "**Computing provider**: which hosts one or more compute engines."
msgstr ""

#: ../../development/design_workflow.rst:36
msgid "Note, one party may have multiple roles, for example:"
msgstr ""

#: ../../development/design_workflow.rst:38
msgid "one party could provide data while also participate in the computation."
msgstr ""

#: ../../development/design_workflow.rst:39
msgid ""
"one party could host all compute engines and claim that engines do not "
"collude with each other, that is the 'out-sourcing mode'."
msgstr ""

#: ../../development/design_workflow.rst:42
msgid "Compare to classic architecture"
msgstr ""

#: ../../development/design_workflow.rst:44
msgid "comparison to classic architecture."
msgstr ""

#: ../../development/design_workflow.rst:48
msgid "SPU"
msgstr ""

#: ../../development/design_workflow.rst:49
msgid "Classic"
msgstr ""

#: ../../development/design_workflow.rst:50
msgid "Difference"
msgstr ""

#: ../../development/design_workflow.rst:51
msgid "SPU VM"
msgstr ""

#: ../../development/design_workflow.rst:52
msgid "CPU"
msgstr ""

#: ../../development/design_workflow.rst:53
msgid "SPU VM composed by multiple engines who follows MPC protocol"
msgstr ""

#: ../../development/design_workflow.rst:54
msgid "SPU VS"
msgstr ""

#: ../../development/design_workflow.rst:55
msgid "Disks"
msgstr ""

#: ../../development/design_workflow.rst:56
msgid "SPU storage composed by multiple participants who do not trust each other"
msgstr ""

#: ../../development/design_workflow.rst:57
#: ../../development/design_workflow.rst:228
msgid "Data infeed"
msgstr ""

#: ../../development/design_workflow.rst:58
msgid "Disk read"
msgstr ""

#: ../../development/design_workflow.rst:59
msgid "SPU data infeed will make data invisible to engines."
msgstr ""

#: ../../development/design_workflow.rst:60
#: ../../development/design_workflow.rst:309
msgid "Data outfeed"
msgstr ""

#: ../../development/design_workflow.rst:61
msgid "Disk write"
msgstr ""

#: ../../development/design_workflow.rst:62
msgid "SPU data output will reveal value from engines."
msgstr ""

#: ../../development/design_workflow.rst:66
msgid "Deployment"
msgstr ""

#: ../../development/design_workflow.rst:68
msgid "A SPU component can be deployed:"
msgstr ""

#: ../../development/design_workflow.rst:70
msgid "**As a lib**: used by other applications, (i.e. python runtime)"
msgstr ""

#: ../../development/design_workflow.rst:71
msgid "**As a binary**: that could be used as a standalone program."
msgstr ""

#: ../../development/design_workflow.rst:72
msgid "**As a service**: that could be called remotely."
msgstr ""

#: ../../development/design_workflow.rst:74
msgid "Component deployment method."
msgstr ""

#: ../../development/design_workflow.rst:78
msgid "Component"
msgstr ""

#: ../../development/design_workflow.rst:79
msgid "As a lib"
msgstr ""

#: ../../development/design_workflow.rst:80
msgid "As a binary"
msgstr ""

#: ../../development/design_workflow.rst:81
msgid "As a service"
msgstr ""

#: ../../development/design_workflow.rst:82
msgid "Compiler/C++"
msgstr ""

#: ../../development/design_workflow.rst:83
#: ../../development/design_workflow.rst:95
msgid "expose pybind"
msgstr ""

#: ../../development/design_workflow.rst:84
msgid "standalone compiler"
msgstr ""

#: ../../development/design_workflow.rst:85
msgid "close-source, focus on optimization"
msgstr ""

#: ../../development/design_workflow.rst:86
msgid "Engine/C++"
msgstr ""

#: ../../development/design_workflow.rst:87
#: ../../development/design_workflow.rst:88
#: ../../development/design_workflow.rst:91
#: ../../development/design_workflow.rst:92
#: ../../development/design_workflow.rst:96
#: ../../development/design_workflow.rst:97
msgid "N/A"
msgstr ""

#: ../../development/design_workflow.rst:89
#: ../../development/design_workflow.rst:93
msgid "standalone service program"
msgstr ""

#: ../../development/design_workflow.rst:90
msgid "Storage Engine/C++"
msgstr ""

#: ../../development/design_workflow.rst:94
msgid "Driver/python"
msgstr ""

#: ../../development/design_workflow.rst:100
msgid "Deployment unit."
msgstr ""

#: ../../development/design_workflow.rst:102
msgid ""
"**SPU Daemon**: is a program that serves *compute engine* or *storage "
"engine*"
msgstr ""

#: ../../development/design_workflow.rst:103
msgid "**SPU Compiler**: is a program that translates/optimizes XLA IR to SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:104
msgid "**driver**: is a lib which drives compile/data-placement/run pipeline."
msgstr ""

#: ../../development/design_workflow.rst:108
msgid "Workflow"
msgstr ""

#: ../../development/design_workflow.rst:110
msgid "The following diagram shows a typical control flow of SPU computation."
msgstr ""

#: ../../development/design_workflow.rst:115
msgid "The whole control flow is driven by the driver/controller."
msgstr ""

#: ../../development/design_workflow.rst:117
msgid "Ask ML framework to compile a model into XLA IR."
msgstr ""

#: ../../development/design_workflow.rst:118
msgid "Ask SPU Compiler to compile XLA IR into SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:119
msgid "Ask storage engines to infeed data to engine's symbol table."
msgstr ""

#: ../../development/design_workflow.rst:120
msgid "Ask compute engines to run SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:121
msgid "Ask storage engine to outfeed from engine's symbol table."
msgstr ""

#: ../../development/design_workflow.rst:126
msgid "Simple workflow"
msgstr ""

#: ../../development/design_workflow.rst:128
msgid "The following diagram shows detailed steps:"
msgstr ""

#: ../../development/design_workflow.rst:181
msgid ""
"**step 1**, driver writes a normal tensorflow program that could be "
"decorated with `tf.function`."
msgstr ""

#: ../../development/design_workflow.rst:182
msgid "**step 2-3** driver asks virtual storage to instantiate dataset."
msgstr ""

#: ../../development/design_workflow.rst:183
msgid ""
"**step 4-5** driver asks virtual storage to load next batch, get a "
"reference to remote tensor."
msgstr ""

#: ../../development/design_workflow.rst:184
msgid ""
"**step 6-7** driver asks tensorflow engine to compile the program into "
"XLA.HLO, with reference tensor."
msgstr ""

#: ../../development/design_workflow.rst:185
msgid "**step 8-9** driver asks SPU Compiler to compile the XLA.HLO into SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:186
msgid ""
"**step 10-13** driver asks virtual storage to infeed data into VM's "
"symbol table."
msgstr ""

#: ../../development/design_workflow.rst:187
msgid "**step 14-15** driver asks VM to run compiled SPU IR."
msgstr ""

#: ../../development/design_workflow.rst:188
msgid ""
"**step 16-19** driver asks virtual storage to outfeed data from VM's "
"symbol table."
msgstr ""

#: ../../development/design_workflow.rst:190
msgid ""
"In the above steps, **step 4-5**, **step 10-19** are virtual steps, since"
" both virtual machine and virtual storage are *virtual object* that can "
"not be interacted directly."
msgstr ""

#: ../../development/design_workflow.rst:192
msgid ""
"The concrete steps is defined by the virtual machine and storage layout. "
"For example:"
msgstr ""

#: ../../development/design_workflow.rst:194
msgid ""
"suppose we have 2 data sources *Alice* and *Bob*, where *Alice* also acts"
" as a data sink."
msgstr ""

#: ../../development/design_workflow.rst:195
msgid "suppose we have 3 compute engines, which compose a 3-PC virtual machine."
msgstr ""

#: ../../development/design_workflow.rst:196
msgid ""
"suppose input `x` comes from *Alice*, `y` comes from *Bob*, and the "
"output `z` is revealed to *Alice*."
msgstr ""

#: ../../development/design_workflow.rst:199
msgid "Data load"
msgstr ""

#: ../../development/design_workflow.rst:223
msgid "**step 1-2** *Alice* loads symbol 'x' into it's local symbol table."
msgstr ""

#: ../../development/design_workflow.rst:224
msgid "**step 3-4** *Bob* loads symbol 'y' into it's local symbol table."
msgstr ""

#: ../../development/design_workflow.rst:230
msgid "The above **step 9-12** does data infeed, the concrete steps look like:"
msgstr ""

#: ../../development/design_workflow.rst:269
msgid ""
"**step 1-5** and **step 6-10** ask *Alice* and *Bob* to do infeed "
"simultaneously, and could be done in parallel."
msgstr ""

#: ../../development/design_workflow.rst:270
msgid ""
"**step 2**, *Alice* splits `x` into shares `(x1, x2, x3)`, note: this "
"progress is mpc-protocol dependent."
msgstr ""

#: ../../development/design_workflow.rst:271
msgid ""
"**step 3-5**, *Alice* sends slices of `xi` to each of the engines, could "
"be done in parallel."
msgstr ""

#: ../../development/design_workflow.rst:272
msgid "**step 6-10**, *Bob* does the same thing as *Alice*."
msgstr ""

#: ../../development/design_workflow.rst:276
msgid "Run"
msgstr ""

#: ../../development/design_workflow.rst:304
msgid ""
"**step 1-2**, driver asks Engine-0 to run the compiled program, note, the"
" input data is feed at this time."
msgstr ""

#: ../../development/design_workflow.rst:305
msgid "**step 3-4, 5-6** driver asks Engine-1 & 2 to do the same thing."
msgstr ""

#: ../../development/design_workflow.rst:311
msgid ""
"Note in this example, *Alice* also acts as the data sink, the output is "
"revealed to *Alice*."
msgstr ""

#: ../../development/design_workflow.rst:338
msgid ""
"**step 2-7** *Alice* gathers sharings of `z` from engines, note: this "
"progress is mpc-protocol dependent."
msgstr ""

#: ../../development/design_workflow.rst:339
msgid "**step 8** *Alice* reconstructs the result locally."
msgstr ""

#: ../../development/design_workflow.rst:343
msgid "Full workflow"
msgstr ""

#: ../../development/design_workflow.rst:345
msgid "The following diagram shows workflow with local VS local processing."
msgstr ""

#: ../../development/design_workflow.rst:405
msgid ""
"In the above picture, we can do local computation on *VS* side, which "
"makes it suitable for FL like application."
msgstr ""

#: ../../development/fxp.ipynb:9
msgid "Pitfalls - Fxp Arithmetic"
msgstr ""

#: ../../development/fxp.ipynb:11
msgid ""
"We have confirmed the precision issues or input limitations with the "
"following ops."
msgstr ""

#: ../../development/fxp.ipynb:13
msgid "We will update this part promptly."
msgstr ""

#: ../../development/fxp.ipynb:25
msgid "Simulation"
msgstr ""

#: ../../development/fxp.ipynb:27
msgid ""
"We will use SPU **simulation** tool to simulate multi-parties with "
"threads."
msgstr ""

#: ../../development/fxp.ipynb:57
msgid "Default Runtime Config Parameters"
msgstr ""

#: ../../development/fxp.ipynb:59
msgid ""
"We will use the following common settings in SPU Runtime config. Other "
"parameters may be modified however."
msgstr ""

#: ../../development/fxp.ipynb:83
msgid "Unary Operator"
msgstr ""

#: ../../development/fxp.ipynb:95
msgid "Reciprocal"
msgstr ""

#: ../../development/fxp.ipynb:97
msgid ""
"SPU uses Goldschmidt's method to calculate Reciprocal. Please refer to "
"`Secure Computation With Fixed-Point Numbers "
"<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.1305&rep=rep1&type=pdf>`__"
" for details."
msgstr ""

#: ../../development/fxp.ipynb:99
msgid ""
"Reciprocal is only correct if input belongs to **(-2**fxp_fraction_bits, "
"2**fxp_fraction_bits)**."
msgstr ""

#: ../../development/fxp.ipynb:101
msgid "First, let's have a look at the figure."
msgstr ""

#: ../../development/fxp.ipynb:191
msgid "Actually the precision is quite high."
msgstr ""

#: ../../development/fxp.ipynb:220
msgid ""
"Let's have an idea about what happens if input is not within the valid "
"range."
msgstr ""

#: ../../development/fxp.ipynb:282
msgid "Natural Logarithm"
msgstr ""

#: ../../development/fxp.ipynb:284
msgid ""
"SPU uses Pade approximation by default. Please check `Benchmarking "
"Privacy Preserving Scientific Operations "
"<https://www.esat.kuleuven.be/cosic/publications/article-3013.pdf>`__ for"
" details."
msgstr ""

#: ../../development/fxp.ipynb:286
msgid ""
"Logarithm is only correct if input belongs to **(0, "
"2**fxp_fraction_bits)**."
msgstr ""

#: ../../development/fxp.ipynb:288
msgid "**NOTE:** Similar conclusion also applies to **log1p**, **log2**."
msgstr ""

#: ../../development/fxp.ipynb:344
msgid "Again, let's see what happens if input is out of valid range."
msgstr ""

#: ../../development/fxp.ipynb:387
msgid "Another Choice: Newton Approximation"
msgstr ""

#: ../../development/fxp.ipynb:389
msgid ""
"If you would like to compute faster, you may switch to Newton "
"Approximation. But the precision is lower and valid input range is around"
" **(0, 250)**."
msgstr ""

#: ../../development/fxp.ipynb:436
msgid "While, if out of valid input..."
msgstr ""

#: ../../development/fxp.ipynb:475
msgid "Natural Exponential"
msgstr ""

#: ../../development/fxp.ipynb:477
msgid ""
"The current implementation is based on Taylor approximation. The valid "
"input range is around **(0, 10)**."
msgstr ""

#: ../../development/fxp.ipynb:479
msgid "**NOTE:** Similar conclusion also applies to **exp2**."
msgstr ""

#: ../../development/fxp.ipynb:525
msgid "If input not in valid range, then..."
msgstr ""

#: ../../development/fxp.ipynb:564
msgid "Another Choice: Pade Approximation"
msgstr ""

#: ../../development/fxp.ipynb:566
msgid ""
"SPU also implements Pade Approximation which has a larger valid input "
"range - **(0, 20)** but with slower computation speed."
msgstr ""

#: ../../development/fxp.ipynb:613
msgid "Let's check if input is larger than 20:"
msgstr ""

#: ../../development/fxp.ipynb:652
msgid "Hyperbolic Tangent"
msgstr ""

#: ../../development/fxp.ipynb:654
#, python-format
msgid ""
"SPU uses Pade Approximation for implementation. The parameters refer to "
"`Wolfram "
"<https://www.wolframalpha.com/input?i=Pade+approximation+tanh%28x%29+order+5%2C5>`__."
" The valid input range is about **(-5,5)**."
msgstr ""

#: ../../development/fxp.ipynb:701
msgid "Binary Operator"
msgstr ""

#: ../../development/fxp.ipynb:704
msgid "Div"
msgstr ""

#: ../../development/fxp.ipynb:706
msgid ""
"SPU uses Goldschmidt's method to calculate division. Please refer to "
"`Secure Computation With Fixed-Point Numbers "
"<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.1305&rep=rep1&type=pdf>`__"
" for details."
msgstr ""

#: ../../development/fxp.ipynb:708
msgid ""
"So we have a similar valid input range to **b**, which is "
"**(-2**fxp_fraction_bits, 2**fxp_fraction_bits)**. Please check details "
"at **reciprocal** part."
msgstr ""

#: ../../development/fxp.ipynb:719
msgid "Besides, We do find some subtle pitfalls in real applications:"
msgstr ""

#: ../../development/fxp.ipynb:721
msgid "Overflow when numerator is large."
msgstr ""

#: ../../development/fxp.ipynb:723
msgid "Some gap between numpy output."
msgstr ""

#: ../../development/fxp.ipynb:725
msgid "**Rule of thumb**"
msgstr ""

#: ../../development/fxp.ipynb:727
msgid ""
"We recommend users to try some actions if you come across \"strange\" "
"outputs:"
msgstr ""

#: ../../development/fxp.ipynb:729
msgid "If **huge error** occurs(maybe even **opposite sign**):"
msgstr ""

#: ../../development/fxp.ipynb:731
msgid "It's common that numerator is **too large**, which leads to overflow."
msgstr ""

#: ../../development/fxp.ipynb:732
msgid ""
"Try **Larger** field(``FM128``) first. Larger field can accommodate "
"larger number when fxp is fixed, so overflow can be avoided. But it will "
"drag down the efficiency of **nearly all op** dramatically."
msgstr ""

#: ../../development/fxp.ipynb:734
msgid ""
"Else, if the gap is not very significant, you can try to modify another "
"two parameters:"
msgstr ""

#: ../../development/fxp.ipynb:736
msgid ""
"Enlarging ``fxp_fraction_bits``: it is an essential parameters for fixed-"
"point arithmetic and will influence all the op associated with float-"
"point. For fixed field, larger fxp can support more bits for fraction "
"part which may give more precision. However, larger fxp will occupy the "
"bits for integer part, and makes **overflow** easier."
msgstr ""

#: ../../development/fxp.ipynb:738
msgid ""
"Enlarging ``fxp_div_goldschmidt_iters``: the precision of Goldschmidt's "
"method depends on iter numbers. So if you eager to more precise output, "
"you can enlarge this parameter. But it's worthy to note that:"
msgstr ""

#: ../../development/fxp.ipynb:740
msgid ""
"Larger this parameter, larger the cost of ``Div`` and all op containing "
"it(like ``Log`` and ``Tanh``)."
msgstr ""

#: ../../development/fxp.ipynb:741
msgid ""
"The final precision is also influenced by field, fxp and even method for "
"truncation. We only recommend to adjust this when you really care about "
"the **high precision**\\ (low absolute error) and other methods not work."
msgstr ""

#: ../../development/fxp.ipynb:803
#, python-brace-format
msgid ""
"When numerator is very large(:math:`>2^{28}` for ``FM64`` and "
"``fxp=18``), then the integer part may overflow under large probability, "
"and this brings huge error."
msgstr ""

#: ../../development/fxp.ipynb:873
msgid ""
"In this situation, **enlarging** field to ``FM128`` may be the only "
"remedy."
msgstr ""

#: ../../development/fxp.ipynb:943
msgid "Now, we try larger fxp."
msgstr ""

#: ../../development/fxp.ipynb:1012
msgid ""
"As we have mentioned at **reciprocal** part, SPU implements reciprocal "
"with Goldschmidt's method, so the final precision depends heavily on the "
"**iter numbers**."
msgstr ""

#: ../../development/fxp.ipynb:1014
msgid ""
"We first go through the algorithm quickly. let :math:`r_i` denote the "
"approximation of reciprocal, :math:`e_i` be the relative error, then in "
"one iter:"
msgstr ""

#: ../../development/fxp.ipynb:1016
#, python-brace-format
msgid ""
"r_i = r_{i-1}(1+e_i) \\\\\n"
"   e_{i+1} = e_i^2"
msgstr ""

#: ../../development/fxp.ipynb:1021
msgid "It's easy to prove that:"
msgstr ""

#: ../../development/fxp.ipynb:1023
msgid ""
"To compute ``Div(a, b)``, if we need :math:`|\\frac{a}{b} - r_i| \\le "
"2^{-l}`, then :math:`\\lceil {log(\\frac{l +log(a)}{\\tau})} \\rceil` "
"iterations should be done(we assume :math:`|\\frac{1}{b} - r_0| \\le "
"2^{-\\tau}`).In current implementation, we choose polynomial of degree 1 "
"as the initial guess of reciprocal, which leads to :math:`\\tau \\approx "
"3.5`."
msgstr ""

#: ../../development/fxp.ipynb:1025
#, python-brace-format
msgid "The relative error :math:`e_i = e_0^{2^i}`\\ (same as ``Div(a,b)``)."
msgstr ""

#: ../../development/fxp.ipynb:1027
msgid ""
"Although some other factors like fxp and truncation will also bring into "
"some errors, the above error analysis can still give readers some "
"recommendations when deciding ``fxp_div_goldschmidt_iters``."
msgstr ""

#: ../../development/index.rst:8
msgid "Pipeline"
msgstr ""

#: ../../development/index.rst:8
msgid "Compiler"
msgstr ""

#: ../../development/index.rst:8
msgid "Runtime"
msgstr ""

#: ../../development/index.rst:8
msgid "Design of SPU"
msgstr ""

#: ../../development/index.rst:18
msgid "Advanced Topics"
msgstr ""

#: ../../development/index.rst:26
msgid "Extending SPU"
msgstr ""

#: ../../development/index.rst:4
msgid "Development"
msgstr ""

#: ../../development/index.rst:6
msgid "This part contains design principles of SPU."
msgstr ""

#: ../../development/ir_dump.rst:2
msgid "Dump IR to DAG"
msgstr ""

#: ../../development/ir_dump.rst:5
msgid ""
"The configuration for dump IR to DAG maybe unstable. Please refer to the "
":spu_code_host:`spu.proto <spu/blob/main/libspu/spu.proto>` for latest "
"configurations."
msgstr ""

#: ../../development/ir_dump.rst:9
msgid ""
"This document provides the demo for how to dump the IR (Intermediate "
"Representation, generated by `XLA "
"<https://www.tensorflow.org/xla/architecture>`_) to a DAG. With the aid "
"of visualized DAG, the execution logic and required operators will be "
"more explicit."
msgstr ""

#: ../../development/ir_dump.rst:14
msgid ""
"Please refer to :ref:`/development/compiler.rst` for description of the "
"role of XLA in SPU."
msgstr ""

#: ../../development/ir_dump.rst:18
msgid "TL;DR"
msgstr ""

#: ../../development/ir_dump.rst:19
msgid ""
"In case you just want to have a try on obtaining the DAG for executed "
"code, we provide a :spu_code_host:`demo "
"<spu/blob/main/examples/python/ir_dump/ir_dump.py>` that demonstrates the"
" required code modifications to enable dumping the IR of executed code to"
" a custom path."
msgstr ""

#: ../../development/ir_dump.rst:21
msgid ""
"For those users who have designated requirements (e.g., dump to txt, dot,"
" html), we recommend to read the following detailed step-by-step "
"elaborations."
msgstr ""

#: ../../development/ir_dump.rst:25
msgid "Configuration"
msgstr ""

#: ../../development/ir_dump.rst:26
msgid ""
"Please first have a look at the :spu_code_host:`spu.proto "
"<spu/blob/main/libspu/spu.proto>` for SPU. To dump the IR, we should "
"modify the compiler options, which is shown in the following code "
"snippet."
msgstr ""

#: ../../development/ir_dump.rst:28
msgid "Compiler Options"
msgstr ""

#: ../../development/ir_dump.rst:59
msgid "The part of the above code related to dumping IR to DAG is as follows."
msgstr ""

#: ../../development/ir_dump.rst:61
msgid "Configurations related to dump IR"
msgstr ""

#: ../../development/ir_dump.rst:69
msgid ""
"In general, we require to focus on three variables to control the dump "
"behavior."
msgstr ""

#: ../../development/ir_dump.rst:71
msgid ""
"**enable_pretty_print** is a *bool* value, which denotes whether to dump "
"the IR or not."
msgstr ""

#: ../../development/ir_dump.rst:72
msgid ""
"**pretty_print_dump_dir** is a *string* value, which denotes the dump "
"path (should be a directory)."
msgstr ""

#: ../../development/ir_dump.rst:73
msgid ""
"**xla_pp_kind** is a *int* value, of which the range is [0, 1, 2], with "
"each one representing one dump format. To date, we support three kinds of"
" formats: TEXT, DOT and HTML. If you want to obtain the DAG, you should "
"use DOT or HTML."
msgstr ""

#: ../../development/ir_dump.rst:76
msgid ""
"For **DOT** files, you should use `GraphViz <https://graphviz.org/>`_ to "
"convert them to PDF or PNG to visualize the DAG."
msgstr ""

#: ../../development/ir_dump.rst:78
msgid ""
"While for **HTML** files, you can directly open the them in your Web "
"Browser, which shall render the DAG."
msgstr ""

#: ../../development/ir_dump.rst:80
msgid "XLA Pretty Print Kind"
msgstr ""

#: ../../development/ir_dump.rst:91
msgid "Pass custom compiler options"
msgstr ""

#: ../../development/ir_dump.rst:92
msgid ""
"We hereby describe how to manually pass the custom compiler options to "
"dump the IR of executed code."
msgstr ""

#: ../../development/ir_dump.rst:94
msgid ""
"First of all, we declare an CompilerOptions object. Note that the "
"**pretty_print_dump_dir** is better to be an absolute path."
msgstr ""

#: ../../development/ir_dump.rst:96
msgid "Declare CompilerOptions object"
msgstr ""

#: ../../development/ir_dump.rst:105
msgid "Then we pass the CompilerOptions to the executed SPU code."
msgstr ""

#: ../../development/ir_dump.rst:108
msgid "The code shall be modified from"
msgstr ""

#: ../../development/ir_dump.rst:110
msgid "SPU execution without customized compiler options"
msgstr ""

#: ../../development/ir_dump.rst:115
msgid "to"
msgstr ""

#: ../../development/ir_dump.rst:117
msgid "SPU execution with customized compiler options"
msgstr ""

#: ../../development/ir_dump.rst:123
msgid ""
"Here, `func` is a Python function. Please refer to the "
":spu_code_host:`demo <spu/blob/main/examples/python/ir_dump/ir_dump.py>` "
"for the context."
msgstr ""

#: ../../development/ir_dump.rst:125
msgid ""
"In the end, you can just run the target code and the output (e.g., DOT) "
"can be found in **your custom path**."
msgstr ""

#: ../../development/ir_dump.rst:128
msgid "Example"
msgstr ""

#: ../../development/ir_dump.rst:129
msgid ""
"We here provide the code snippet for dumping IR to HTML files. The DAG "
"for the executed function is illustrated in the end."
msgstr ""

#: ../../development/ir_dump.rst:131
msgid "Code snippet for dumping the IR of func"
msgstr ""

#: ../../development/ir_dump.rst:165
msgid ""
"You may find multiple files in the output directory since XLA has "
"multiple compile passes and generates multiple IRs, with each "
"corresponding to one DAG."
msgstr ""

#: ../../development/ir_dump.rst:168
msgid "The **HTML** output is rendered as follows."
msgstr ""

#: ../../development/ir_dump.rst:173
msgid "DAG for executed demo function"
msgstr ""

#: ../../development/pipeline.rst:2
msgid "SPU Pipeline"
msgstr "SPU 管道"

#: ../../development/pipeline.rst:4
msgid ""
"Recall that SPU could be treated as a :ref:`virtual device "
"<development/basic_concepts:Machine model>`. When working with a (virtual"
" or physical) device, we need several steps."
msgstr "前面提到，SPU 可以被视为虚拟设备。使用（虚拟或物理）设备时，我们需要几个步骤。"

#: ../../development/pipeline.rst:6
msgid "infeed code to it"
msgstr "输入代码"

#: ../../development/pipeline.rst:7
msgid "infeed data to it"
msgstr "输入数据"

#: ../../development/pipeline.rst:8
msgid "trigger it to run"
msgstr "触发运行"

#: ../../development/pipeline.rst:9
msgid "get result from it"
msgstr "获取结果"

#: ../../development/pipeline.rst:11
msgid "This page describes details of each step."
msgstr "本页将描述每个步骤的详细信息。"

#: ../../development/pipeline.rst:16
msgid ""
"Before diving into the details, let's first take a closer look of SPU "
"pipeline, it's something like this:"
msgstr "在深入了解细节之前，让我们先仔细看看 SPU 管道，它是这样的："

#: ../../development/pipeline.rst:21
msgid "code and data pipeline"
msgstr "代码和数据管道"

#: ../../development/pipeline.rst:24
msgid "Compilation"
msgstr "编译"

#: ../../development/pipeline.rst:26
msgid "The vertical part depicts the compilation pipeline, from top to bottom."
msgstr "垂直部分从上到下描绘了编译管道。"

#: ../../development/pipeline.rst:28
msgid "Programmer writes code in AI frameworks(like TensorFlow/JAX)."
msgstr "程序员在 AI 框架（如 TensorFlow/JAX）中编写代码。"

#: ../../development/pipeline.rst:29
msgid "AI frontend traces the DAG, and emits as XLA IR."
msgstr "AI frontend 跟踪 DAG，并以 XLA IR 形式发出。"

#: ../../development/pipeline.rst:30
msgid ""
"SPU compiler takes XLA IR, and compiles it to SPU IR, the format that SPU"
" runtime understands."
msgstr "SPU 编译器接收 XLA IR，并将其编译为 SPU IR，即 SPU 运行时可以理解的格式。"

#: ../../development/pipeline.rst:32
msgid "For more details, please see :doc:`compiler` for details."
msgstr "更多详细信息请参见 SPU 编译器详情。"

#: ../../development/pipeline.rst:35
msgid "Data pipeline"
msgstr "数据管道"

#: ../../development/pipeline.rst:37
msgid "The horizontal part depicts the data pipeline, from left to right."
msgstr "水平部分从左到右描绘数据管道。"

#: ../../development/pipeline.rst:39
msgid ""
"Data providers use :ref:`SPU io <reference/py_api:Runtime IO>` module to "
"encrypt input data."
msgstr "数据提供者使用 SPU io 模块来加密输入数据。"

#: ../../development/pipeline.rst:41
msgid "For SPU MPC backend, *encrypt* means to split plaintext data into shares."
msgstr "对于 SPU MPC 后端，加密意味着将明文数据分成几部分。"

#: ../../development/pipeline.rst:42
msgid "For floating-point data, encoding to fixed-point may be also required."
msgstr "对于浮点数据，可能还需要编码为定点。"

#: ../../development/pipeline.rst:44
msgid ""
"The encrypted data is sent to :ref:`SPU runtime <reference/py_api:Runtime"
" Setup>`."
msgstr "加密数据被发送到 SPU 运行时。"

#: ../../development/pipeline.rst:45
msgid ""
"The output data is fetched by *result owner*, and decrypted by the "
":ref:`SPU io <reference/py_api:Runtime IO>` module."
msgstr "输出数据由SPU io 模块解密后提供给数据获取者。"

#: ../../development/pipeline.rst:49
msgid "Just in time"
msgstr "即时编译"

#: ../../development/pipeline.rst:51
msgid ""
"JIT is short for `Just-in-time compilation <https://en.wikipedia.org/wiki"
"/Just-in-time_compilation>`_, with this approach, the compiler can get "
"more information, such as input shapes, than in `AOT mode "
"<https://en.wikipedia.org/wiki/Ahead-of-time_compilation>`_. JIT may "
"introduce more evaluation overhead, but it's really trivial in secure "
"computation setting."
msgstr ""
"JIT 是即时编译 (Just-in-time compilation) 的缩写，通过这种方式，编译器可以比 AOT "
"模式获取更多信息，例如输入形状。JIT 可能会引入更多的评估开销，但在安全计算场景中这是微不足道的。"

#: ../../development/pipeline.rst:53
msgid ""
"In SPU, JIT has more benefits since the backend engine may be orders of "
"magnitude faster if it knows the *visibility* of data. For example, when "
"multiplying two secrets, the backend MPC engine may involve expensive "
"*beaver triple* progress, but when one of the inputs (of multiply) is "
"public known to all parties, the operation will be much faster. So we "
"should *mark* as much data as possible to be *public* (if it doesn't need"
" to be protected), and tell the compiler these information."
msgstr ""
"在 SPU 中，JIT 具有更多优势，因为如果后端引擎知道数据是可见的，那么它的速度可能会快几个数量级。例如，在将两方秘密数据相乘时，后端 MPC"
" "
"运算可能涉及昂贵的三重运算，但当其中一方数据是所有各方都知道的公共数据时，运算会快得多。因此，我们应该将尽可能多的数据标记为公开（如果数据不需要保护），并告诉编译器这些信息。"

#: ../../development/pipeline.rst:55
msgid ""
"So, SPU compilation normally happens after all data infeed is done, and "
"`just in time` before the real evaluation."
msgstr "因此，SPU 编译通常在所有数据输入完成后进行，并且在实际评估之前进行即时编译。"

#: ../../development/policy_sgd_insight.rst:2
msgid "Background: SGD in MPC-ML"
msgstr "背景：随机梯度下降法在MPC-ML"

#: ../../development/policy_sgd_insight.rst:4
msgid ""
"SGD(Stochastic Gradient Descent) is a famous optimization algorithm, it "
"updates weights using gradient direction. However, it suffers that user "
"should choose hyper-parameters very carefully. Of course, grid-search is "
"a potential treatment for this problem, but it becomes impractical when "
"training cost is large. As an example, When running LR with SGD in "
"`credit card dataset <https://www.kaggle.com/datasets/uciml/default-of-"
"credit-card-clients-dataset>`_ (for 4096-0.1, 4096 is batch_size, 0.1 is "
"learning_rate), we can find that it seems safer to use small batch_size "
"and learning_rate, else we get some loss or very strong vibration of auc "
"within 10 epochs(we leave 10000 samples as test dataset randomly)."
msgstr ""
"随机梯度下降法（SGD）是一个著名的优化算法，它沿着负梯度方向来更新模型的权重。然而，这种方法要求使用者仔细地选择超参数。网格搜索虽然可以解决此问题，但在实际应用中训练耗时过长，因此并不实用。例如，在"
" credit card 数据集上使用随机梯度下降法训练线性回归模型时（批量大小为 4096，学习率为 "
"0.1），我们发现，若批量大小和学习率设置不当，在 10 个轮次内损失值会偏大，且 AUC 值波动剧烈。（随机选择 10000 "
"个样本作为测试数据集）。"

#: ../../development/policy_sgd_insight.rst:12
msgid ""
"Unfortunately, when under MPC, even simple algorithm like SSLR, small "
"batch_size leads to huge training time under limited network resources. "
"Besides, even you have high bandwidth, small batch_size can not utilize "
"it!"
msgstr "但是，但处于MPC模式下，即使简单的算法，例如SSLR，小的批量大小在网络资源有限的环境下也会导致训练时间的大幅增加。而且，即使你拥有较高的网络带宽，小的批量也无法充分利用带宽资源。"

#: ../../development/policy_sgd_insight.rst:16
msgid "How to improve SGD"
msgstr "如何优化 SGD 方法"

#: ../../development/policy_sgd_insight.rst:17
msgid ""
"Indeed, after our elaborated experiments, we can find two drawbacks of "
"naive SGD:"
msgstr "在我们的全面的实验下，我们发现朴素 SGD 方法的两个缺点"

#: ../../development/policy_sgd_insight.rst:19
msgid "slow update(because of small learning_rate) at the beginning."
msgstr "起始阶段，模型权重更新缓慢是由于学习率较小造成的。"

#: ../../development/policy_sgd_insight.rst:21
msgid "vibration happens when near to optimal point."
msgstr "当模型权重接近最优点时，模型的表现开始波动。"

#: ../../development/policy_sgd_insight.rst:23
msgid ""
"So, it's a straight strategy to use \"large\" learning_rate at the "
"beginning, and \"slow down\" as training goes on. But the ensuing "
"question is how to determine specific \"large\" and \"slow down\" for "
"different datasets."
msgstr "所以，应该在起步阶段使用较大的学习率，随着训练的进行，逐渐减小学习率。问题是，对于不同的数据集，如何确定“较大的”和“逐渐减小”的具体情况。"

#: ../../development/policy_sgd_insight.rst:27
msgid "What's Policy sgd"
msgstr "什么是Policy sgd"

#: ../../development/policy_sgd_insight.rst:28
msgid ""
"For SSLR, we provide an answer to the above question: policy-sgd(already "
"implemented on `SSRegression` in Secretflow when setting "
"`strategy=policy_sgd`)."
msgstr ""
"对于 SSLR 算法，我们已经在隐语 Secretflow 中实现了 policy-sgd 方法。（在 SSRegression 中设置 "
"strategy=policy_sgd）"

#: ../../development/policy_sgd_insight.rst:33
msgid "The core of this optimizer consists of two parts:"
msgstr "policy-sgd 优化算法的核心包含两部分"

#: ../../development/policy_sgd_insight.rst:35
#, python-brace-format
msgid ""
"1. Adaptive learning rate scaling mechanism: in first epoch, we force the"
" weight move unit-norm in gradient direction and record "
":math:`\\frac{1}{||grad||_2}` as scale factor for this batch."
msgstr ""
"自适应学习率缩放机制：在第一个轮次（epoch）中，我们强制权重在梯度方向上移动单位范数，并将 "
":math:`\\frac{1}{||grad||_2}` 记录为该批次的缩放因子。"

#: ../../development/policy_sgd_insight.rst:38
msgid ""
"2. Learning rate decay and early stop: we use step-decay strategy for "
"learning_rate decay. As for early stop, we compare two strategies, loss "
"based(use Taylor expansion to avoid invoking time-consuming op like "
"`exp`, `log`) and weight based, and choose the latter in our final "
"implementation."
msgstr ""
"学习率衰减与早停策略：我们采用步长衰减（step-"
"decay）策略进行学习率衰减。关于早停，我们比较了基于损失（利用泰勒展开避免指数、对数等耗时运算）和基于权重的两种策略，最终选择了后者。"

#: ../../development/policy_sgd_insight.rst:44
msgid "Experiments"
msgstr "实验"

#: ../../development/policy_sgd_insight.rst:45
#, python-brace-format
msgid ""
"We use 4 dataset for experiments, containing 3 open source dataset "
"(`credit_card <https://www.kaggle.com/datasets/uciml/default-of-credit-"
"card-clients-dataset>`_, `Bank Marketing "
"<https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#>`_, `Aps "
"<https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks>`_)"
" and 1 business dataset(wzdata). For open source dataset, we just do some"
" basic one-hot and min-max normalization like normal LR needs. We leave "
"out about :math:`\\frac{1}{3}` data for test data and evaluate auc on it."
" The baseline auc is computed when using sklearn for model training."
msgstr ""
"我们使用四个数据集进行实验，包含三个开源数据集（credit_card, Bank Marketing, "
"Aps）和一个工业界数据集（wzdata）。对于开源数据集，我们仅仅做一些基本的 one-hot 和 min-max "
"的归一化操作，以此来满足线性回归模型的需要。我们留出三分之一的数据作为测试数据集，并在其上评估了 auc 指标作为基线。我们使用 sklearn "
"进行模型训练，并计算 auc。"

#: ../../development/policy_sgd_insight.rst:53
#: ../../development/policy_sgd_insight.rst:107
msgid "Dataset"
msgstr "数据集"

#: ../../development/policy_sgd_insight.rst:53
msgid "Training shape"
msgstr "训练集的维度"

#: ../../development/policy_sgd_insight.rst:53
msgid "baseline auc"
msgstr "基线 auc"

#: ../../development/policy_sgd_insight.rst:55
#: ../../development/policy_sgd_insight.rst:109
msgid "business dataset"
msgstr "wzdata"

#: ../../development/policy_sgd_insight.rst:55
msgid "111618，23"
msgstr "111618，23"

#: ../../development/policy_sgd_insight.rst:55
msgid "0.8175"
msgstr "0.8175"

#: ../../development/policy_sgd_insight.rst:57
#: ../../development/policy_sgd_insight.rst:111
msgid "Bank Marketing"
msgstr "Bank Marketing"

#: ../../development/policy_sgd_insight.rst:57
msgid "40787，48"
msgstr "40787，48"

#: ../../development/policy_sgd_insight.rst:57
msgid "0.93"
msgstr "0.93"

#: ../../development/policy_sgd_insight.rst:59
#: ../../development/policy_sgd_insight.rst:113
msgid "credit_card"
msgstr "credit_card"

#: ../../development/policy_sgd_insight.rst:59
msgid "20000, 23"
msgstr "20000, 23"

#: ../../development/policy_sgd_insight.rst:59
msgid "0.718"
msgstr "0.718"

#: ../../development/policy_sgd_insight.rst:61
#: ../../development/policy_sgd_insight.rst:115
msgid "Aps"
msgstr "Aps"

#: ../../development/policy_sgd_insight.rst:61
msgid "60000，170"
msgstr "60000，170"

#: ../../development/policy_sgd_insight.rst:61
msgid "0.9666"
msgstr "0.9666"

#: ../../development/policy_sgd_insight.rst:65
msgid "Precision"
msgstr "精确度"

#: ../../development/policy_sgd_insight.rst:67
msgid ""
"We first test how precision of fixed point influence SSLR and test three "
"settings:"
msgstr "我们首先测试定点精度如何影响 SSLR，并测试了三种设置："

#: ../../development/policy_sgd_insight.rst:69
msgid "low precision: `FM64` + 18 fxp"
msgstr "低精度：64 位定点数格式（FM64）加上 18 位小数部分（fxp）"

#: ../../development/policy_sgd_insight.rst:71
msgid "medium precision: `FM128` + 28 fxp"
msgstr "中精度：128 位定点数格式（FM128）加上 28 位小数部分（fxp）"

#: ../../development/policy_sgd_insight.rst:73
msgid "high precision: `FM128` + 42 fxp"
msgstr "高精度：128 位定点数格式（FM128）加上 42 位小数部分（fxp）"

#: ../../development/policy_sgd_insight.rst:81
msgid ""
"We can find that for both optimizer, precision has little influence on "
"final auc, so it's safe for user to choose low precision when training "
"LR."
msgstr "我们可以发现，对于这两种优化器而言，精度对 auc 影响很小，因此用户在训练线性回归（LR）模型时选择低精度是安全的。"

#: ../../development/policy_sgd_insight.rst:85
msgid "Naive v.s Policy"
msgstr "Naive sgd 与 Policy sgd 对比"

#: ../../development/policy_sgd_insight.rst:87
msgid ""
"Then, we compare the totally runtime of naive_sgd(v1) and policy_sgd(v2)."
" For naive-sgd, we follow the \"safe strategy\"(mostly used in plaintext "
"ML): small learning_rate like 0.1, and small batch_size like 1024(If "
"using 2048, then some data does not converge). Also, it's hard to decide "
"a good default value for naive_sgd to early stop well(even worse, you may"
" get huge auc drop if setting bad values). To avoid tedious grid-search, "
"so for naive_sgd, it runs without any learning_rate decay(recommended way"
" for naive_sgd). But for policy_sgd, it's often harmless to use larger "
"batch_size(2048 for these experiments),and we set learning_rate decay a "
"half every 2 epochs."
msgstr ""
"我们对比了 naive-sgd (v1) 和 policy-sgd (v2) 的总运行时间。对于 naive-"
"sgd，我们遵循“稳妥策略”（常用于明文机器学习）：采用较小的学习率（如 0.1）和较小的批量大小（如 1024，若使用 2048 "
"则部分数据无法收敛）。此外，naive-sgd 难以确定合适的默认早停值（设置不当可能导致 AUC 大幅下降）。为避免繁琐的网格搜索，naive-"
"sgd 运行时不采用任何学习率衰减（推荐做法）。但对于 policy-sgd，使用较大的批量大小通常无害（本实验中为 2048），且每 2 "
"个轮次学习率减半。"

#: ../../development/policy_sgd_insight.rst:93
msgid ""
"As for other hyper-parameters, we set total running epochs to 20, "
"learning_rate to 0.1 and use low precision, CHEETAH protocol. And we test"
" in WAN, providing 20Mbps and 20ms RTT, which is a typical setting in "
"real world project."
msgstr ""
"至于其他超参数，我们将总运行轮次设置为 20，学习率设置为 0.1，并使用低精度、CHEETAH协议。我们在广域网中进行测试，提供 20Mbps "
"的带宽以及 20 毫秒的往返时间（RTT），这是现实世界项目中的一种典型设置。"

#: ../../development/policy_sgd_insight.rst:99
msgid ""
"First, we find for naive_sgd(v1), none of them meets any early stop "
"criterion during 20 epochs(so we omit the early stop line in figure). "
"However, for policy_sgd(v2), it can always \"stop well\"(red dot line "
"means policy_sgd meets the stop criterion based on loss, similar for "
"purple line) after the model converges. Besides, checking the auc of "
"stopping time, it has very low gap(<0.01) between baseline."
msgstr ""
"首先，我们发现 naive-sgd (v1) 在四个数据集上均未能在 20 轮内满足早停条件（因此图中未标出）。而 policy-sgd (v2)"
" 在所有四个数据集上均能在模型收敛后实现“早停”（红色点划线表示满足基于损失的早停标准，紫色表示基于权重的早停标准）。此外，早停时的 AUC "
"值与基线差距极小（<0.01）。"

#: ../../development/policy_sgd_insight.rst:103
msgid ""
"The following table shows the total running time of policy_sgd and "
"naive_sgd(based on weight early stop). Policy_sgd can reduce the time by "
"2-5 times compared to naive_sgd."
msgstr ""
"下方的表格展示了两种方法的运行时间，其中 policy-sgd 是基于模型权重进行早停判断的。 policy-sgd 相比 naive-sgd "
"在时间上缩短了 2-5 倍。"

#: ../../development/policy_sgd_insight.rst:107
msgid "naive_sgd(s)"
msgstr "naive_sgd(s)"

#: ../../development/policy_sgd_insight.rst:107
msgid "policy_sgd(s)"
msgstr "policy_sgd(s)"

#: ../../development/policy_sgd_insight.rst:107
msgid "naive/policy"
msgstr "naive/policy"

#: ../../development/policy_sgd_insight.rst:109
msgid "~8000"
msgstr "~8000"

#: ../../development/policy_sgd_insight.rst:109
#: ../../development/policy_sgd_insight.rst:113
msgid "~1600"
msgstr "~1600"

#: ../../development/policy_sgd_insight.rst:109
msgid "5x"
msgstr "5x"

#: ../../development/policy_sgd_insight.rst:111
msgid "~3000"
msgstr "~3000"

#: ../../development/policy_sgd_insight.rst:111
msgid "~800"
msgstr "~800"

#: ../../development/policy_sgd_insight.rst:111
msgid "3.75x"
msgstr "3.75x"

#: ../../development/policy_sgd_insight.rst:113
msgid "~350"
msgstr "~350"

#: ../../development/policy_sgd_insight.rst:113
msgid "4.57x"
msgstr "4.57x"

#: ../../development/policy_sgd_insight.rst:115
msgid "~10000"
msgstr "~10000"

#: ../../development/policy_sgd_insight.rst:115
msgid "~4200"
msgstr "~4200"

#: ../../development/policy_sgd_insight.rst:115
msgid "2.38x"
msgstr "2.38x"

#: ../../development/runtime.rst:2
msgid "SPU Runtime"
msgstr ""

#: ../../development/runtime.rst:5
msgid "Architecture"
msgstr ""

#: ../../development/runtime.rst:7
msgid "Here is the big picture of SPU VM."
msgstr ""

#: ../../development/runtime.rst:11
msgid ""
"The top 3 blocks above *SPU VM* are applications, we could ignore them "
"for now."
msgstr ""

#: ../../development/runtime.rst:12
msgid "The bottom left block is the scheduling component."
msgstr ""

#: ../../development/runtime.rst:13
msgid ""
"The main block is the SPU Architecture, which is the core for secure "
"evaluation."
msgstr ""

#: ../../development/runtime.rst:15
msgid "Inside SPU, there are multiple layers, from bottom to up:"
msgstr ""

#: ../../development/runtime.rst:17
msgid ""
"**System layer** provides the basic computation and communication ability"
" for the upper layers."
msgstr ""

#: ../../development/runtime.rst:18
msgid ""
"**Crypto layer** is the key for secure computation, it's composed by 3 "
"sub layers."
msgstr ""

#: ../../development/runtime.rst:20
msgid ""
"**Basic** or classic layer, provides classic cryptography, OT, HE also "
"lives in this layer."
msgstr ""

#: ../../development/runtime.rst:21
msgid ""
"**Correlation** or the offline protocol layer, provides correlation like "
"beaver triple and randbit."
msgstr ""

#: ../../development/runtime.rst:22
msgid ""
"**Protocol** or the online protocol layer, applies random correlation and"
" runs the secure evaluation."
msgstr ""

#: ../../development/runtime.rst:24
msgid ""
"**ALU layer** converts MPC protocols into a programmable machine, which "
"has two sub layers."
msgstr ""

#: ../../development/runtime.rst:26
msgid ""
"**Ring 2^k** layer, just like normal CPU, hides cryptography layer's "
"details and provides standard ring2k arithmetic."
msgstr ""

#: ../../development/runtime.rst:27
msgid ""
"**Fixed point** layer uses fixed point encoding to represent a fractional"
" number and provides basic arithmetic operations over them."
msgstr ""

#: ../../development/runtime.rst:29
msgid ""
"**OPS layer** is designed to be extensible, in this layer we can define "
"multiple modules based on *ALU layer* and finally exposed to VM clients "
"via bindings or SPU IR."
msgstr ""

#: ../../development/runtime.rst:32
msgid "Homogeneous and Heterogeneous"
msgstr ""

#: ../../development/runtime.rst:34
msgid ""
"Recall that SPU VM is composed of multiple physical engines, the "
"definitions of *homogeneous* and *heterogeneous* come from an *engines*' "
"perspective."
msgstr ""

#: ../../development/runtime.rst:36
msgid ""
"**Homogeneous**: a layer is *homogeneous* means that all engines run "
"exactly the same code in this layer. The user of this layer doesn't have "
"to distinguish between engines, they cannot and should not send/recv "
"messages between engines, in other words, they can treat all engines the "
"same, and program them as one machine."
msgstr ""

#: ../../development/runtime.rst:37
msgid ""
"**Heterogeneous**: in contrast, a layer is *heterogeneous* means that "
"engines in this layer behave differently (following some protocols). The "
"author of this layer should take care of the behavior of each engine to "
"make things correct."
msgstr ""

#: ../../development/runtime.rst:39
msgid ""
"We want SPU VM to be *homogeneous*, so we can treat it as a normal "
"virtual device when applying secure evaluation. For example, in the "
"following computation graph, given `x`, `y`, we want to compute `f(x, "
"y)`, the big circle represents a computing node which can evaluate f."
msgstr ""

#: ../../development/runtime.rst:43
msgid ""
"In secure computation mode, we have a group of servers working together "
"to provide the functionality of `f`, as shown blow."
msgstr ""

#: ../../development/runtime.rst:47
msgid ""
"The secure protocol (MPC protocol) itself is **heterogeneous**, three "
"servers inside the big circle may behave differently, in this pic, the "
"lower part is blue, which means three servers act and interact "
"differently."
msgstr ""

#: ../../development/runtime.rst:49
msgid ""
"But they together provide a **homogeneous** interface to the upper layer,"
" in this pic, the upper half is orange, three servers behave exactly the "
"same, so in the whole computation DAG, the big circle could be treated as"
" one (virtual) node."
msgstr ""

#: ../../development/runtime.rst:51
msgid ""
"Another reason to use **homogeneous** IR is to hide the number of "
"parties, so the application can switch to an m-PC protocol from an n-PC "
"protocol without code change."
msgstr ""

#: ../../development/runtime.rst:53
msgid ""
"One of *SPU*'s goal is to hide the heterogeneous part and expose "
"homogeneous API."
msgstr ""

#: ../../development/runtime.rst:56
msgid "VM Layout"
msgstr ""

#: ../../development/runtime.rst:58
msgid ""
"SPU, as a virtual device, is hosted by multiple physical devices. The "
"relationship between physical devices and SPU is very flexible. Now let's"
" use some examples to illustrate the possible layouts."
msgstr ""

#: ../../development/runtime.rst:61
msgid ""
"Programmers coding toward the virtual layout, the underline physical is "
"**transparent** from the programmer's perspective. It's free to use "
"different physical layouts, without changing a single line of code."
msgstr ""

#: ../../development/runtime.rst:64
msgid "Outsourcing"
msgstr ""

#: ../../development/runtime.rst:66
msgid ""
"In this mode, data providers send data shares to a group of non-colluding"
" computation providers who cooperate to evaluate secure computations."
msgstr ""

#: ../../development/runtime.rst:70
msgid ""
"The figure to left depicts the physical layout, there are 6 physical "
"nodes, mutually connected but untrusted to each other."
msgstr ""

#: ../../development/runtime.rst:72
msgid "The circle stands for data provider."
msgstr ""

#: ../../development/runtime.rst:73
msgid ""
"The triangle stands for computing provider, three triangle nodes agree on"
" some MPC protocol."
msgstr ""

#: ../../development/runtime.rst:75
msgid "The figure to the right depicts the virtual layout."
msgstr ""

#: ../../development/runtime.rst:77
msgid "The circle has one-to-one relation to the physical nodes."
msgstr ""

#: ../../development/runtime.rst:78
msgid "3 triangle nodes are treated as a single virtual device."
msgstr ""

#: ../../development/runtime.rst:81
msgid "Colocated"
msgstr ""

#: ../../development/runtime.rst:83
msgid ""
"In this mode, data providers also participate in the computation "
"progress, that is, data providers are **colocated** with computing "
"providers."
msgstr ""

#: ../../development/runtime.rst:87
msgid ""
"On the left side, there are 3 physical nodes, each of which acts as data "
"provider as well as computing provider."
msgstr ""

#: ../../development/runtime.rst:88
msgid ""
"On the right side, **SPU is a pure virtual node, constructed by physical "
"nodes**."
msgstr ""

#: ../../development/runtime.rst:91
msgid ""
"The number of computing nodes could be larger than that of data nodes in "
"this mode, for example, a computing node without data source could act as"
" a *random correlation generator*, for example:"
msgstr ""

#: ../../development/runtime.rst:97
msgid "There are two notable optimizations in this mode."
msgstr ""

#: ../../development/runtime.rst:99
msgid ""
"The **private semantic**, a computing node may have private data "
"manipulations to accelerate MPC computation, for example, in *HESS "
"protocol*, we can do :code:`HShare x Private` without online "
"communication."
msgstr ""

#: ../../development/runtime.rst:100
msgid ""
"The **zero share data infeed**, when a data provider tries to share data "
"cross nodes, it can use :code:`ZeroShare + Private` trick to avoid online"
" communication."
msgstr ""

#: ../../development/runtime.rst:103
msgid "Hybrid"
msgstr ""

#: ../../development/runtime.rst:105
msgid ""
"This is the most general form, some data providers participate in the "
"secure computation while others do not."
msgstr ""

#: ../../development/runtime.rst:110
msgid ""
"the **private semantic** and **zero share data infeed** also apply to "
"data providers that participate in the computation."
msgstr ""

#: ../../development/type_system.rst:2
msgid "Type System"
msgstr "类型系统"

#: ../../development/type_system.rst:7
msgid "This document is for VM developers."
msgstr "本文档面向虚拟机开发者。"

#: ../../development/type_system.rst:9
msgid "Everything in SPU could be treated as an object, each object has a type."
msgstr "在 SPU 中的一切都是一个对象，每个对象都有一个类型。"

#: ../../development/type_system.rst:11
msgid ""
"There are only two types of objects, *value* or *operator*, which means "
"if a symbol is not a *value*, it's an *operator*."
msgstr "对象只有两种类型：值或操作符，也就是说如果一个符号不是值，那么它就是操作符。"

#: ../../development/type_system.rst:13
msgid ""
"**value**: an object that is managed by SPU runtime, representing a "
"public/secret data."
msgstr "值：由 SPU 运行时管理的对象，表示公开/秘密数据。"

#: ../../development/type_system.rst:14
msgid ""
"**operator**: an object that takes one or more values and outputs a "
"return value, i.e. `multiply` is an operator."
msgstr "操作符：接受一个或多个值并给出一个返回值的对象，例如 `multiply` 就是一个操作符。"

#: ../../development/type_system.rst:17
msgid "Value type"
msgstr "值类型"

#: ../../development/type_system.rst:19
msgid "A value type is a tuple (**V**, **D**, **S**), where:"
msgstr "值类型是一个元组 (V, D, S)，其含义如下："

#: ../../development/type_system.rst:21
#, python-brace-format
msgid "**V** is *visibility*, could be one of *{public, secret}*"
msgstr "V 为可见性（visibility），可以是 {public, secret} 之一。"

#: ../../development/type_system.rst:22
#, python-brace-format
msgid "**D** is *data type*, could be one of *{int, fxp}*"
msgstr "D 为数据类型（data type），可以是 {int, fxp} 之一。"

#: ../../development/type_system.rst:23
msgid "**S** is *shape*, which makes the value a tensor."
msgstr "S 为形状（shape），它将值构建为张量。"

#: ../../development/type_system.rst:25
msgid ""
"We can define a hyper type function, which takes three parameters and "
"return a concrete value type."
msgstr "我们可以定义一个超类型函数，它接受三个参数并返回一个具体的值类型。"

#: ../../development/type_system.rst:31
msgid ""
"To simplify things a little bit, we can ignore *shape* for now and assume"
" that runtime will handle it correctly."
msgstr "为了简化问题，我们可以暂时忽略形状，并假设运行时会正确处理它。"

#: ../../development/type_system.rst:37
msgid ""
"With this type function, we can define a list of types in the SPU type "
"system."
msgstr "通过这个类型函数，我们可以在SPU类型系统中定义一系列类型。"

#: ../../development/type_system.rst:47
msgid "Operator type"
msgstr "操作符类型"

#: ../../development/type_system.rst:49
msgid ""
"*Operators* takes a list of values as parameters and returns exactly one "
"value as result, operator's type is determined by the types of input "
"parameters and return values."
msgstr "操作符以值列表作为参数，并返回一个具体的值作为结果，操作符类型由输入参数和返回值的类型决定。"

#: ../../development/type_system.rst:51
msgid ""
"In SPU IR, an operator could take a polymorphic typed parameter and the "
"return type could be deduced from the parameters. For example:"
msgstr "在 SPU IR 中，操作符可以接受多种类型的参数，并且从中推导出返回的类型。例如："

#: ../../development/type_system.rst:62
msgid ""
"The `add` operator takes a pair of `type(V, D)` as parameter, which has "
"2x2x2x2 = 16 different kinds of combinations. To support this type of "
"operators, we introduce the following *type functor*."
msgstr ""
"`add` 操作符接受一对 `type(V, D)` 作为参数，共有 2x2x2x2 = 16 "
"种不同的组合。为了支持这种类型的操作符，我们引入了以下类型函子。"

#: ../../development/type_system.rst:64
msgid ""
"**dtype promotion**, which promotes two dtypes to a more relaxed type, in"
" SPU system, *int* is always promoted to *fxp*."
msgstr "数据类型提升（dtype promotion）：将两个 dtype 提升为更宽松的类型，在 SPU 系统中，int 总是被提升为 fxp。"

#: ../../development/type_system.rst:72
msgid ""
"**visibility narrow**, which narrows the visibility when two or more "
"operands have different visibility properties, this is the key to "
"maintain the \"secure semantic\" of SPU VM, since the resulting "
"visibility of ops will always be more strict. i.e. if one of operands is "
"*secret*, the result is a *secret*."
msgstr ""
"可见性收窄（visibility narrow）：当两个或多个操作数具有不同的可见性属性时窄化可见性。这是保持 SPU VM "
"“语义安全”的关键，因为操作的结果可见性总是更严格。例如，如果其中一个操作数是 secret，则结果是 secret。"

#: ../../development/type_system.rst:82
msgid "Now we can represent the polymorphic mul op as:"
msgstr "现在我们可以将多态的 mul 操作符表示为："

#: ../../development/type_system.rst:88
msgid ""
"the op takes two parameters, first type is :code:`type(V0, D0)`, second "
"type is :code:`type(V1, D1)`."
msgstr "该操作符接受两个参数，第一个类型是 :code:`type(V0, D0)`，第二个类型是 :code:`type(V1, D1)`。"

#: ../../development/type_system.rst:89
msgid "the op returns :code:`type(narrow(V0, V1), promote(D0, D1))` as a result."
msgstr "该操作符返回 :code:`type(narrow(V0, V1), promote(D0, D1))` 作为结果。"

#: ../../development/type_system.rst:90
msgid ""
"when applying the op to two arbitrary arguments, the result could be "
"deduced from the above type expressions."
msgstr "当将操作符应用于两个任意参数时，结果都可以从上述类型表达式中推导出来\""

#: ../../development/type_system.rst:94
msgid "Use of type"
msgstr "类型的用途"

#: ../../development/type_system.rst:96
msgid "There are many uses for types."
msgstr "类型有许多用途。"

#: ../../development/type_system.rst:98
msgid ""
"First, the most important one, type is self descriptive, with an accurate"
" defined type system, we can describe *SPU IR* more accurately."
msgstr "首先，最重要的是类型是自描述的，通过准确定义的类型系统，我们可以更准确地描述 SPU IR。"

#: ../../development/type_system.rst:99
msgid ""
"Second, runtime type information is used to do runtime dispatch, which is"
" important for polymorphic operators."
msgstr "其次，在进行运行时调度会使用运行时类型信息，这对于多态操作符非常重要。"

#: ../../development/type_system.rst:100
msgid ""
"Third, the type system could be used by static type checker, and could be"
" used to double check runtime implementation."
msgstr "第三，类型系统可以用于静态类型检查，并可以用于双重检查运行时的实现。"

#: ../../development/type_system.rst:104
msgid "Ops dispatch"
msgstr "操作调度"

#: ../../development/type_system.rst:106
msgid ""
"As described above, type helps for dispatching, here we use `MUL` "
"instruction as an example."
msgstr "如上所述，类型有助于调度，这里我们以 `MUL` 指令为例。"

#: ../../development/type_system.rst:113
msgid ""
"The above `MUL` instruction does element-wise multiplication, `%1` and "
"`%2` are parameters and `%3` is the return value."
msgstr "上面的 `MUL` 指令执行逐元素乘法，`%1` 和 `%2` 是参数，`%3` 是返回值。"

#: ../../development/type_system.rst:116
msgid "The dispatch problem"
msgstr "调度问题"

#: ../../development/type_system.rst:118
#, python-brace-format
msgid ""
"In this example, `%1` and `%2` are SPU values, each of them belongs one "
"of four types `{sint, pint, sfxp, pfxp}`, the type of `MUL` is:"
msgstr ""
"在这个例子中，`%1` 和 `%2` 是 SPU 值，每个值都属于四种类型 `{sint, pint, sfxp, pfxp}` 之一，`MUL`"
" 的类型是："

#: ../../development/type_system.rst:120
#, python-brace-format
msgid ""
"\\begin{Bmatrix} sint \\\\ pint \\\\ sfxp \\\\ pfxp \\end{Bmatrix}\n"
"\\times\n"
"\\begin{Bmatrix} sint \\\\ pint \\\\ sfxp \\\\ pfxp \\end{Bmatrix}"
msgstr ""
"\\begin{Bmatrix} sint \\\\ pint \\\\ sfxp \\\\ pfxp \\end{Bmatrix}\n"
"\\times\n"
"\\begin{Bmatrix} sint \\\\ pint \\\\ sfxp \\\\ pfxp \\end{Bmatrix}"

#: ../../development/type_system.rst:126
msgid ""
"**The problem is how to dispatch operations to correct kernel according "
"to the arguments' type information**."
msgstr "问题是如何根据参数的类型信息将操作调度到正确的内核。"

#: ../../development/type_system.rst:128
msgid ""
"A simple idea is to pattern match all these type combinations and "
"dispatch to different kernels accordingly, with this way we got 4x4=16 "
"different kernels."
msgstr "一个简单的想法是使用模式匹配所有这些类型组合，并相应地调度到不同的内核，这样我们就有 4x4=16 个不同的内核了。"

#: ../../development/type_system.rst:146
msgid "Layered dispatch"
msgstr "分层调度"

#: ../../development/type_system.rst:148
msgid ""
"A better way is to dispatch layer by layer, for example, first dispatch "
"by dtype, then dispatch by vtype."
msgstr "更好的方法是逐层调度，例如，首先按 dtype 调度，然后按 vtype 调度。"

#: ../../development/type_system.rst:172
msgid "In the above diagram:"
msgstr "在上图中："

#: ../../development/type_system.rst:174
msgid "**mul** is general *multiplication* method."
msgstr "mul 是通用的乘法方法。"

#: ../../development/type_system.rst:175
msgid "**imul** is integer multiplication method."
msgstr "imul 是整数乘法方法。"

#: ../../development/type_system.rst:176
msgid "**fmul** is fixedpoint multiplication method."
msgstr "fmul 是定点乘法方法。"

#: ../../development/type_system.rst:177
msgid "**rmul** is untyped multiplication method over ring 2k."
msgstr "rmul 是在环2k上的无类型乘法方法。"

#: ../../development/type_system.rst:178
msgid ""
"**mulss** multiplies two secrets, the domain and behavior are secure "
"protocol dependent."
msgstr "mulss 是两个秘密值的乘法，其域和行为依赖于安全协议。"

#: ../../development/type_system.rst:180
msgid "The above idea can be expressed in code like:"
msgstr "上述思想用代码可以表示为："

#: ../../development/type_system.rst:215
msgid "Fast dispatch"
msgstr "快速调度"

#: ../../development/type_system.rst:217
msgid ""
"In the above example, we observe that `i2f` and `truncation` could be "
"optimized, the intuition is that when a value is converted from `int` to "
"`fxp` and later convert back, these two conversion introduce non-trivial "
"computation overhead in MPC setting."
msgstr ""
"在上面的例子中，我们观察到 `i2f` 和 `truncation` 可以被优化，直觉是当一个值从 `int` 转换为 `fxp` "
"然后再转换回来时，这两个转换在 MPC 设置中引入了不小的计算开销。"

#: ../../development/type_system.rst:219
msgid ""
"We use the so called *fast dispatch* to optimize it, when doing cross "
"`int` and `fxp` multiplication, we could directly do `imul` without type "
"lift and truncation."
msgstr "我们使用所谓的快速调度来优化它，当进行跨 `int` 和 `fxp` 乘法时，我们可以直接进行 `imul` 而不需要类型提升和截断。"

#: ../../development/type_system.rst:239 ../../development/type_system.rst:274
msgid "Note:"
msgstr "注意："

#: ../../development/type_system.rst:241
msgid "in the above implementation we didn't maintain the type correctness."
msgstr "在上述实现中，我们没有维护类型的正确性。"

#: ../../development/type_system.rst:242
msgid ""
"this pattern match based *fast dispatch* is exactly the same as compile-"
"time *peephole optimization*."
msgstr "这种基于模式匹配的快速调度与编译时的窥孔优化完全相同。"

#: ../../development/type_system.rst:243
msgid ""
"dispatch inside a protocol is also complicated and beyond the scope of "
"this article."
msgstr "协议内部的调度也很复杂，超出了本文的范围。"

#: ../../development/type_system.rst:247
msgid "Implementation"
msgstr "实现"

#: ../../development/type_system.rst:249
msgid ""
"With *type functor*, we have the following op definitions in `mul` "
"dispatch chain."
msgstr "通过类型函子，我们在 `mul` 调度链中有以下操作定义。"

#: ../../development/type_system.rst:258
msgid ""
"In dispatch phrase, SPU runtime uses type information to select next "
"dispatch op. In this example, `(x:sfxp, y:sfxp)` is applied op `mul`, via"
" pattern matching we got `(V0=SECRET,D0=FXP), (V1=SECRET,D1=FXP)`, and "
"the dispatch stack looks like:"
msgstr ""
"在调度阶段，SPU运行时使用类型信息来选择下一个调度操作。在这个例子中，`(x:sfxp, y:sfxp)` 被应用于操作 "
"`mul`，通过模式匹配我们得到 `(V0=SECRET,D0=FXP), (V1=SECRET,D1=FXP)`，调度栈如下所示："

#: ../../development/type_system.rst:276
msgid ""
"We use C++-like template type notation to represent polymorphic type "
"constraints."
msgstr "我们使用类似 C++ 模板类型的符号来表示多态类型约束。"

#: ../../development/type_system.rst:279
msgid "Partial type"
msgstr "部分类型"

#: ../../development/type_system.rst:281
msgid ""
"In the type dispatch step, type information is used to select next op, "
"and when partial of type information is used, it's *erased*. For example,"
" when `dtype` is used to select `fmul` in the above example, dtype is "
"useless in the future and could be erased, the lower level op does not "
"distinguish dtype (via a generic type parameter). In a real "
"implementation, we don't erase the type explicitly, just leave it there "
"without further use."
msgstr ""
"在类型调度步骤中类型信息用于选择下一个操作，当使用部分类型信息时它会被擦除。在上面的例子中，当使用 `dtype` 选择 `fmul` "
"时，dtype 在之后是无用的，可以被擦除，"

#: ../../development/type_system.rst:283
msgid ""
"The return value takes the `reverse progress` of dispatch. The return "
"type is filled from bottom to up. For example, in the above progress, "
"when :code:`z=rmul(x,y)` is called, `rmul` knows `z`'s visibility type is"
" `SECRET` but does not know its dtype yet, so here `z` has a partial type"
" `type(SECRET, $UNKNOWN)`. The type will be filled step by step during "
"stack popup, and eventually be completed as a full type when the whole "
"dispatch progress is done."
msgstr ""
"返回值采用调度的反向处理。返回类型从下到上填充。例如，在上述的过程中，当调用 :code:`z=rmul(x,y)` 时，`rmul` 知道 "
"`z` 的可见性类型是 `SECRET`，但还不知道其 `dtype`，所以这里 `z` 有一个部分类型 `type(SECRET, "
"$UNKNOWN)`。类型将在栈弹出过程中逐步填充，最终在整个调度过程完成时作为一个完整类型完成。"

#: ../../development/visibility_inference_rule.rst:2
msgid "Visibility Inference"
msgstr ""

#: ../../development/visibility_inference_rule.rst:7
msgid "This document is for SPU compiler developers."
msgstr ""

#: ../../development/visibility_inference_rule.rst:9
msgid ""
"In SPU compiler stack, visibility is part of type qualifier. During "
"legalize stablehlo to pphlo, every SSA value and BlockArg need to assign "
"with a proper visibility. This procedure is referred as **Visibility "
"Inference**"
msgstr ""

#: ../../development/visibility_inference_rule.rst:13
msgid "Common Visibility"
msgstr ""

#: ../../development/visibility_inference_rule.rst:15
msgid ""
"When an operation inputs have different visibilities, the way of compute "
"common visibility is defined as:"
msgstr ""

#: ../../development/visibility_inference_rule.rst:25
msgid "Nullary Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:27
msgid ""
"Nullary ops in stablehlo are `ConstantOp "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#constant>`_ "
"and `IotaOp "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#iota>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:30
msgid "All nullary ops follows the following inference rule:"
msgstr ""

#: ../../development/visibility_inference_rule.rst:38
msgid "Unary Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:40
msgid ""
"Most unary ops in **stablehlo** cannot change visibility of input "
"argument and follows the following inference rule:"
msgstr ""

#: ../../development/visibility_inference_rule.rst:49
msgid "Binary Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:51
msgid ""
"Most binary ops in **stablehlo** yield a result with common visibility of"
" **lhs** and **rhs** and follows the following inference rule:"
msgstr ""

#: ../../development/visibility_inference_rule.rst:60
msgid "Control Flow Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:62
msgid ""
"`If <https://github.com/openxla/stablehlo/blob/main/docs/spec.md#if>`_ "
"and `Case "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#case>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:63
msgid ""
"In short, each result of an if statement is common visibility of results "
"from different branches and predicate."
msgstr ""

#: ../../development/visibility_inference_rule.rst:65
msgid ""
"If different branches yield results of different visibilities, cast to "
"common visibility will be inserted before relative return."
msgstr ""

#: ../../development/visibility_inference_rule.rst:90
msgid ""
"`While "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#while>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:91
msgid ""
"For while body, consider result visibility might be different from input "
"visibility, multi-rounds of visibility inference is applied on body "
"region. The final result will be all input visibility matches result "
"visibility."
msgstr ""

#: ../../development/visibility_inference_rule.rst:94
msgid ""
"**Attention**: Although no protocol supports **while** with a non-public "
"cond region at this point, compiler in general does not error out here."
msgstr ""

#: ../../development/visibility_inference_rule.rst:108
msgid "Reduce Related Op"
msgstr ""

#: ../../development/visibility_inference_rule.rst:110
msgid ""
"`Reduce "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#reduce>`_ "
"and `ReduceWindow "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#reduce_window>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:120
msgid ""
"`SelectAndScatter "
"<https://github.com/openxla/stablehlo/blob/main/docs/spec.md#select_and_scatter>`_"
msgstr ""

#: ../../development/visibility_inference_rule.rst:121
msgid "In general the rule is"
msgstr ""

#: ../../development/visibility_inference_rule.rst:122
msgid "visibility(opernad) == visibility(init)"
msgstr ""

#: ../../development/visibility_inference_rule.rst:123
msgid "visibility(result) == common_visibility(operand, source, init)"
msgstr ""

#~ msgid ""
#~ "Try **Larger** field(``FM128``) first. Larger"
#~ " field can accommodate larger number "
#~ "when fxp is fixed, so overflow can"
#~ " be avoided. But it will drag "
#~ "down the efficiency of **nearly all "
#~ "op** dramatically."
#~ msgstr ""

#~ msgid ""
#~ "When numerator is very large(:math:`>2^{28}`"
#~ " for ``FM64`` and ``fxp=18``), then "
#~ "the integer part may overflow under "
#~ "large probability, and this brings huge"
#~ " error."
#~ msgstr ""

#~ msgid ""
#~ "Try **Larger** field(\\ ``FM128``) first. "
#~ "Larger field can accommodate larger "
#~ "number when fxp is fixed, so "
#~ "overflow can be avoided. But it "
#~ "will drag down the efficiency of "
#~ "**nearly all op** dramatically."
#~ msgstr ""

#~ msgid ""
#~ "When numerator is very large(\\ "
#~ ":math:`>2^{28}` for ``FM64`` and ``fxp=18``),"
#~ " then the integer part may overflow"
#~ " under large probability, and this "
#~ "brings huge error."
#~ msgstr ""

